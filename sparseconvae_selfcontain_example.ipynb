{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoF0nOoy8GaK"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu7Ls8xDSbmv"
      },
      "outputs": [],
      "source": [
        "# High-quality figure settings\n",
        "import matplotlib as mpl\n",
        "#mpl.rcParams['figure.dpi'] = 300\n",
        "#mpl.rcParams['savefig.dpi'] = 300\n",
        "#mpl.rcParams['font.size'] = 12\n",
        "#mpl.rcParams['figure.figsize'] = [8.0, 6.0]\n",
        "#mpl.rcParams['axes.labelsize'] = 'medium'\n",
        "#mpl.rcParams['axes.titlesize'] = 'medium'\n",
        "#mpl.rcParams['legend.fontsize'] = 'medium'\n",
        "#mpl.rcParams['axes.linewidth'] = 0.8\n",
        "#mpl.rcParams['lines.linewidth'] = 1.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cen5DyzrZtP"
      },
      "source": [
        "## Aux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FakRgc0B9Tkz"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khZ96A9prcbV"
      },
      "outputs": [],
      "source": [
        "def visualize_results(*images_and_titles):\n",
        "    num_images = len(images_and_titles) // 2\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(5 * num_images, 5))\n",
        "\n",
        "    if num_images == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i, (image, title) in enumerate(zip(images_and_titles[::2], images_and_titles[1::2])):\n",
        "        if image.dim() == 3:\n",
        "            # For RGB images\n",
        "            axes[i].imshow(image.permute(1, 2, 0).cpu().detach().numpy())\n",
        "        elif image.dim() == 2:\n",
        "            # For grayscale images or masks\n",
        "            axes[i].imshow(image.cpu().detach().numpy(), cmap='gray')\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported image dimension: {image.dim()}\")\n",
        "\n",
        "        axes[i].set_title(title)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlrLN7J2n404"
      },
      "source": [
        "## Synthetic Dataset Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIzbOAPVPSCU"
      },
      "outputs": [],
      "source": [
        "module_name='mpslib'\n",
        "try:\n",
        "    __import__(module_name)\n",
        "    print('%s allready installed. skipping installation.' % module_name)\n",
        "    exe_folder = ''\n",
        "\n",
        "except ImportError:\n",
        "    import sys\n",
        "    is_colab = 'google.colab' in sys.modules\n",
        "    print (is_colab)\n",
        "    if is_colab:\n",
        "        print('%s cannot be loaded. trying to install it.' % module_name)\n",
        "        !pip install scikit-mps pyvista panel\n",
        "\n",
        "        # Recompile from src on Colab\n",
        "        import pathlib\n",
        "        import mpslib as mps\n",
        "\n",
        "        O=mps.mpslib()\n",
        "        O.compile_mpslib()\n",
        "        # Next line is needed in GoogleColabe\n",
        "        !bash mpslib_download_and_install.sh\n",
        "\n",
        "    else:\n",
        "        print('Please install MPSlib and scikit-mps from http://github.com/ergosimulation/mpslib/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HME0ETnNcKg9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.spatial.distance import cdist\n",
        "from numpy.linalg import inv\n",
        "from scipy.interpolate import interp1d\n",
        "import numpy as np\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "# Utility Functions\n",
        "\n",
        "def create_grid(size):\n",
        "    y, x = torch.meshgrid(torch.arange(size[0], dtype=torch.float32),\n",
        "                          torch.arange(size[1], dtype=torch.float32),\n",
        "                          indexing='ij')\n",
        "    return torch.stack((y.flatten(), x.flatten()), dim=1).unsqueeze(0)\n",
        "\n",
        "def create_param_grid(size, params):\n",
        "    num_params, param_dims = params.shape\n",
        "    param_grid = torch.zeros(param_dims - 2, size[0], size[1])\n",
        "    param_mask = torch.zeros(1, size[0], size[1])\n",
        "\n",
        "    for param in params:\n",
        "        y, x = param[:2].long()\n",
        "        if 0 <= y < size[0] and 0 <= x < size[1]:\n",
        "            param_grid[:, y, x] = param[2:]\n",
        "            param_mask[0, y, x] = 1\n",
        "\n",
        "    return param_grid, param_mask\n",
        "\n",
        "def create_id_spatial_data(size, params, grid, exponent=2.0):\n",
        "    coords = params[:, :2]\n",
        "    values = params[:, 2]\n",
        "    distances = torch.cdist(grid, coords.unsqueeze(0)).squeeze(0)  # [size[0]*size[1], num_params]\n",
        "    weights = 1 / (distances ** exponent + 1e-6)\n",
        "    weighted_values = (weights * values).sum(dim=1)\n",
        "    weights_sum = weights.sum(dim=1)\n",
        "    interpolated_values = weighted_values / weights_sum\n",
        "\n",
        "    return interpolated_values.reshape(1, size[0], size[1])\n",
        "\n",
        "def create_stationary_spatial_data(size, params, grid):\n",
        "    mean = params[:, 2].mean().item()\n",
        "    variance = 0.1\n",
        "\n",
        "    # Ensure grid is a NumPy array with the correct shape\n",
        "    if isinstance(grid, torch.Tensor):\n",
        "        grid = grid.squeeze(0).cpu().numpy()\n",
        "\n",
        "    # Ensure params is also a NumPy array\n",
        "    if isinstance(params, torch.Tensor):\n",
        "        params = params.cpu().numpy()\n",
        "\n",
        "    # Extract coordinates and known values\n",
        "    coords = params[:, :2]\n",
        "    known_values = params[:, 2]\n",
        "\n",
        "    def exponential_covariance(h, range=3):\n",
        "        return np.exp(-h / range)\n",
        "\n",
        "    # Calculate pairwise distances within the entire grid for covariance\n",
        "    distances = pdist(grid)\n",
        "    cov_matrix = exponential_covariance(squareform(distances))\n",
        "\n",
        "    # Find closest grid points to known coordinates\n",
        "    distances_to_known = cdist(grid, coords)\n",
        "    closest_indices = np.argmin(distances_to_known, axis=0)\n",
        "\n",
        "    # Extract necessary sub-matrices from the covariance matrix\n",
        "    C_oo = cov_matrix[np.ix_(closest_indices, closest_indices)]\n",
        "    C_ou = cov_matrix[closest_indices, :]\n",
        "    C_uu = cov_matrix\n",
        "\n",
        "    # Conditional mean and covariance for Gaussian field\n",
        "    conditional_mean = mean + C_ou.T @ inv(C_oo) @ (known_values - mean)\n",
        "    conditional_cov = C_uu - C_ou.T @ inv(C_oo) @ C_ou\n",
        "\n",
        "    z_conditional = np.random.multivariate_normal(conditional_mean, variance * conditional_cov)\n",
        "    z_conditional = 1 / (1 + np.exp(-z_conditional))  # Logistic transformation\n",
        "    z_conditional = np.clip(z_conditional, 0, 1)  # Clipping to ensure [0, 1]\n",
        "\n",
        "    # Convert the result to a PyTorch tensor\n",
        "    return torch.from_numpy(z_conditional.reshape((1, size[0], size[1]))).float()\n",
        "\n",
        "def create_base_stationary_spatial_data(size, grid):\n",
        "    mean = 0.5\n",
        "    variance = 0.1\n",
        "    height, width = size\n",
        "\n",
        "    # Define the exponential covariance function\n",
        "    def exponential_covariance(h, range_param=3):\n",
        "        return np.exp(-h / range_param)\n",
        "\n",
        "    # Create distance grid\n",
        "    y = np.arange(-height//2, height//2)\n",
        "    x = np.arange(-width//2, width//2)\n",
        "    xx, yy = np.meshgrid(x, y)\n",
        "    distances = np.sqrt(xx**2 + yy**2)\n",
        "    cov = exponential_covariance(distances)\n",
        "\n",
        "    # Use FFT to generate the random field efficiently\n",
        "    fft_cov = np.fft.fft2(np.fft.fftshift(cov))\n",
        "    # Ensure that the covariance is real and non-negative\n",
        "    fft_cov = np.real(fft_cov)\n",
        "    fft_cov[fft_cov < 0] = 0\n",
        "\n",
        "    # Generate white noise\n",
        "    white_noise = np.random.normal(size=(height, width))\n",
        "\n",
        "    # Multiply in Fourier domain and invert\n",
        "    fft_noise = np.fft.fft2(white_noise)\n",
        "    field = np.real(np.fft.ifft2(fft_noise * np.sqrt(fft_cov)))\n",
        "\n",
        "    # Normalize the field to have the desired variance and mean\n",
        "    field = field - np.mean(field)\n",
        "    field = field / np.std(field)\n",
        "    field = field * np.sqrt(variance) + mean\n",
        "\n",
        "    # Apply logistic transformation and clip values between 0 and 1\n",
        "    field = 1 / (1 + np.exp(-field))\n",
        "    field = np.clip(field, 0, 1)\n",
        "\n",
        "    # Convert the result to a PyTorch tensor\n",
        "    return torch.from_numpy(field.reshape((1, height, width))).float()\n",
        "\n",
        "def create_vid_spatial_data(size, params, grid, exponent=2.0):\n",
        "    height, width = size\n",
        "\n",
        "    # Extract x and value from params\n",
        "    x_coords = params[:, 1].numpy()  # Use x-coordinate (column 1)\n",
        "    values = params[:, 2].numpy()    # Use the first value (column 2)\n",
        "\n",
        "    # Sort the points by x-coordinate\n",
        "    sort_idx = np.argsort(x_coords)\n",
        "    x_coords = x_coords[sort_idx]\n",
        "    values = values[sort_idx]\n",
        "\n",
        "    # Create interpolation function\n",
        "    f = interp1d(x_coords, values, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
        "\n",
        "    # Generate x values for interpolation\n",
        "    x_range = np.arange(width)\n",
        "\n",
        "    # Interpolate values\n",
        "    interpolated_values = f(x_range)\n",
        "\n",
        "    # Create 2D output by repeating the interpolated values vertically\n",
        "    output = np.tile(interpolated_values, (height, 1))\n",
        "\n",
        "    return torch.tensor(output, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "def create_cvid_spatial_data(size, params, grid, exponent=2.0):\n",
        "    height, width = size\n",
        "\n",
        "    # Extract x and value from params\n",
        "    x_coords = params[:, 1].numpy()  # Use x-coordinate (column 1)\n",
        "    values = params[:, 2].numpy()    # Use the first value (column 2)\n",
        "\n",
        "    # Sort the points by x-coordinate\n",
        "    sort_idx = np.argsort(x_coords)\n",
        "    x_coords = x_coords[sort_idx]\n",
        "    values = values[sort_idx]\n",
        "\n",
        "    # Create interpolation function\n",
        "    f = interp1d(x_coords, values, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
        "\n",
        "    # Generate x values for interpolation\n",
        "    x_range = np.arange(width)\n",
        "\n",
        "    # Interpolate values\n",
        "    interpolated_values = f(x_range)\n",
        "\n",
        "    # Create 2D output by repeating the interpolated values vertically\n",
        "    output = np.tile(interpolated_values, (height, 1))\n",
        "\n",
        "    # Round values to nearest 0.1\n",
        "    output = np.round(output * 10) / 10\n",
        "\n",
        "    return torch.tensor(output, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "def create_nn_spatial_data(size, params, grid):\n",
        "    distances = torch.cdist(grid, params[:, :2].unsqueeze(0)).squeeze(0)  # [size[0]*size[1], num_params]\n",
        "    nearest_idx = distances.argmin(dim=1)  # Get indices of the nearest parameters\n",
        "    values = params[nearest_idx, 2]  # Use the value of the nearest parameter\n",
        "    return values.reshape(1, size[0], size[1])\n",
        "\n",
        "def create_kriging_spatial_data(size, params, grid, range_param=100.0, nugget=1e-5):\n",
        "    # Extract coordinates and values\n",
        "    coords = params[:, :2].cpu().numpy()\n",
        "    values = params[:, 2].cpu().numpy()\n",
        "\n",
        "    # Calculate distance matrix\n",
        "    dist_matrix = cdist(coords, coords, metric='euclidean')\n",
        "\n",
        "    # Calculate covariance matrix (using an exponential model)\n",
        "    variogram_model = lambda h: np.exp(-h / range_param)\n",
        "    cov_matrix = variogram_model(dist_matrix)\n",
        "\n",
        "    # Add nugget effect\n",
        "    cov_matrix += np.eye(len(cov_matrix)) * nugget\n",
        "\n",
        "    # Calculate weights\n",
        "    weights = np.linalg.solve(cov_matrix, values)\n",
        "\n",
        "    # Calculate distances from grid points to known points\n",
        "    grid_coords = grid[0].cpu().numpy()\n",
        "    dist_to_grid = cdist(grid_coords, coords, metric='euclidean')\n",
        "\n",
        "    # Calculate covariance from grid points to known points\n",
        "    cov_to_grid = variogram_model(dist_to_grid)\n",
        "\n",
        "    # Interpolate values at grid points\n",
        "    interpolated_values = cov_to_grid @ weights\n",
        "\n",
        "    return torch.tensor(interpolated_values.reshape(size[0], size[1]), dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "\n",
        "def create_layered_spatial_data(size, params, grid):\n",
        "    height, width = size\n",
        "    output = torch.full((1, height, width), 0.0)  # Start with all zeros\n",
        "\n",
        "    # Group points by their integer value (layer)\n",
        "    layers = {}\n",
        "    for y, x, value in params:\n",
        "        layer = int(value*10)\n",
        "        if layer not in layers:\n",
        "            layers[layer] = []\n",
        "        layers[layer].append((x.item(), y.item(), value.item()))\n",
        "\n",
        "    # Sort layers by value (bottom to top)\n",
        "    sorted_layers = sorted(layers.items(), key=lambda x: x[0])\n",
        "\n",
        "    # Keep track of the highest point filled for each x-coordinate\n",
        "    highest_filled = torch.zeros(width, dtype=torch.long)\n",
        "\n",
        "    # Create splines for each layer\n",
        "    for layer_value, points in sorted_layers:\n",
        "        if len(points) < 2:\n",
        "            continue  # Need at least 2 points for interpolation\n",
        "        points.sort(key=lambda p: p[0])  # Sort points by x-coordinate\n",
        "        x_coords, y_coords, values = zip(*points)\n",
        "\n",
        "        # Create a linear interpolation\n",
        "        spline = interp1d(x_coords, y_coords, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
        "\n",
        "        # Evaluate each pixel for this layer\n",
        "        for x in range(width):\n",
        "            y_intersect = int(spline(x))\n",
        "            y_start = max(y_intersect, highest_filled[x])\n",
        "            if y_start < height:\n",
        "                output[0, y_start:, x] = layer_value / 10\n",
        "                highest_filled[x] = y_start\n",
        "\n",
        "    return output\n",
        "\n",
        "def create_mps_spatial_data(size, params, grid):\n",
        "    height, width = size\n",
        "\n",
        "    # Initialize MPSlib with GENESIM method\n",
        "    O = mps.mpslib(method='mps_genesim', simulation_grid_size=np.array([ height, width, 1]), verbose_level=0, debug_level=-1)\n",
        "\n",
        "    # Set up MPSlib parameters\n",
        "    O.parameter_filename = 'mps.txt'\n",
        "    O.par['n_real'] = 1\n",
        "    O.par['n_cond'] = 25\n",
        "    O.par['template_size'] = np.array([[10, 5], [10, 5], [1, 1]])\n",
        "\n",
        "    value =  (params[:, 2] < 0.5)\n",
        "    print(value)\n",
        "    # Prepare hard data\n",
        "    hard_data = np.column_stack((params[:, 0], params[:, 1], np.zeros(params.shape[0]), value))\n",
        "    O.d_hard = hard_data\n",
        "\n",
        "    # Generate or load a training image\n",
        "    TI, _ = mps.trainingimages.strebelle(di=2, coarse3d=1)\n",
        "    O.ti = TI\n",
        "\n",
        "    # Run the simulation\n",
        "    O.run()\n",
        "\n",
        "    # Get the simulated result\n",
        "    sim = O.sim[0].squeeze()\n",
        "\n",
        "    return torch.tensor(sim, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "def plot_sample(x: torch.Tensor, param_grid: torch.Tensor, param_mask: torch.Tensor, mask: Optional[torch.Tensor] = None):\n",
        "    num_channels = x.shape[0]\n",
        "    size = x.shape[1]\n",
        "    fig, axs = plt.subplots(num_channels, 3 if mask is None else 4, figsize=(15 if mask is None else 20, 5*num_channels))\n",
        "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
        "\n",
        "    if num_channels == 1:\n",
        "        axs = [axs]\n",
        "\n",
        "    x = x.cpu().numpy() if isinstance(x, torch.Tensor) else x\n",
        "    param_grid = param_grid.cpu().numpy() if isinstance(param_grid, torch.Tensor) else param_grid\n",
        "    param_mask = param_mask.cpu().numpy() if isinstance(param_mask, torch.Tensor) else param_mask\n",
        "\n",
        "    if mask is not None:\n",
        "        mask = mask.cpu().numpy() if isinstance(mask, torch.Tensor) else mask\n",
        "\n",
        "    for i in range(num_channels):\n",
        "        im = axs[i][0].imshow(x[i], cmap='viridis', interpolation='nearest')\n",
        "        axs[i][0].set_title('Spatial Data')\n",
        "        axs[i][0].axis('off')\n",
        "        #plt.colorbar(im, ax=axs[i][0], fraction=0.046, pad=0.04)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask_indices = np.argwhere(mask[0] > 0)\n",
        "            mask_values = x[i][mask[0] > 0]\n",
        "            axs[i][1].imshow(x[i], cmap='viridis', interpolation='nearest', alpha=0.5)\n",
        "            axs[i][1].scatter(mask_indices[:, 1], mask_indices[:, 0], c=mask_values, cmap='viridis', edgecolors='black', s=50)\n",
        "            axs[i][1].set_title('Sampling Mask')\n",
        "            axs[i][1].axis('off')\n",
        "            #plt.colorbar(im, ax=axs[i][1], fraction=0.046, pad=0.04)\n",
        "\n",
        "        im = axs[i][-2].imshow(param_grid[i], cmap='viridis', interpolation='nearest')\n",
        "        axs[i][-2].set_title('Parameter Grid')\n",
        "        axs[i][-2].axis('off')\n",
        "        #plt.colorbar(im, ax=axs[i][-2], fraction=0.046, pad=0.04)\n",
        "\n",
        "        param_indices = np.argwhere(param_mask[0] > 0)\n",
        "        param_values = param_grid[i][param_mask[0] > 0]\n",
        "        axs[i][-1].imshow(param_grid[i], cmap='viridis', interpolation='nearest', alpha=0.5)\n",
        "        axs[i][-1].scatter(param_indices[:, 1], param_indices[:, 0], c=param_values, cmap='viridis', edgecolors='black', s=50)\n",
        "        axs[i][-1].set_title('Parameter Mask')\n",
        "        axs[i][-1].axis('off')\n",
        "        #plt.colorbar(im, ax=axs[i][-1], fraction=0.046, pad=0.04)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Datasets\n",
        "class SpatialGenerator():\n",
        "    def __init__(self, size, param_generator, methods=['kriging']):\n",
        "        self.size = size\n",
        "        self.param_generator = param_generator\n",
        "        self.methods = methods if isinstance(methods, list) else [methods]\n",
        "        self.grid = create_grid(size)\n",
        "\n",
        "    def generate_item(self):\n",
        "        # Generate parameters using the provided lambda function\n",
        "        params = self.param_generator()\n",
        "\n",
        "        x = torch.zeros(params.shape[1] - 2, self.size[0], self.size[1])  # Assuming params has columns for x, y, and other values\n",
        "        for i in range(params.shape[1] - 2):\n",
        "            method_index = min(i, len(self.methods) - 1)\n",
        "            method = self.methods[method_index].lower().strip()\n",
        "            channel_params = params[:, [0, 1, i + 2]]\n",
        "            if method == 'id':\n",
        "                x[i] = create_id_spatial_data(self.size, channel_params, self.grid)\n",
        "            elif method == 'vid':\n",
        "                x[i] = create_vid_spatial_data(self.size, channel_params, self.grid)\n",
        "            elif method == 'cvid':\n",
        "                x[i] = create_cvid_spatial_data(self.size, channel_params, self.grid)\n",
        "            elif method == 'nn':\n",
        "                x[i] = create_nn_spatial_data(self.size, channel_params, self.grid)\n",
        "            elif method == 'kriging':\n",
        "                x[i] = create_kriging_spatial_data(self.size, channel_params, self.grid)\n",
        "            elif method == 'stationary':\n",
        "                x[i] = create_stationary_spatial_data(self.size, channel_params, self.grid)\n",
        "            elif method == 'bstationary':\n",
        "                x[i] = create_base_stationary_spatial_data(self.size, self.grid)\n",
        "            elif method == 'layers':\n",
        "                x[i] = create_layered_spatial_data(self.size, channel_params, self.grid)\n",
        "            elif method == 'mps':\n",
        "                x[i] = create_mps_spatial_data(self.size, channel_params, self.grid)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported interpolation method: {method}\")\n",
        "\n",
        "        param_grid, param_mask = create_param_grid(self.size, params)\n",
        "\n",
        "        return x, param_grid, param_mask\n",
        "\n",
        "class CategoricalSpatialGenerator():\n",
        "    def __init__(self, size, param_generator, num_categories, methods):\n",
        "        self.size = size\n",
        "        self.param_generator = param_generator\n",
        "        self.num_categories = num_categories\n",
        "        self.methods = methods\n",
        "        self.grid = create_grid(size)\n",
        "\n",
        "    def generate_item(self):\n",
        "        # Generate parameters using the provided lambda function\n",
        "        params = self.param_generator()\n",
        "        params = self.normalize_data(params)\n",
        "\n",
        "        x = torch.zeros(len(self.methods), self.size[0], self.size[1])\n",
        "        param_grid = torch.zeros(len(self.methods), self.size[0], self.size[1])\n",
        "        param_mask = torch.zeros(1, self.size[0], self.size[1])\n",
        "\n",
        "        # Generate categorical data using the first 3 columns of params\n",
        "        category_data = self.create_categorical_data(params)\n",
        "        x[0] = category_data.squeeze()  # Remove the channel dimension\n",
        "        param_grid[0] = category_data.squeeze()  # Remove the channel dimension\n",
        "\n",
        "        # Initialize category mask\n",
        "        for param in params:\n",
        "            y, x_coord = param[:2].long()\n",
        "            if 0 <= y < self.size[0] and 0 <= x_coord < self.size[1]:\n",
        "                param_mask[0, y, x_coord] = 1\n",
        "\n",
        "        category_params = [[] for _ in range(self.num_categories)]\n",
        "        for param in params:\n",
        "            category = self.continuous_to_categorical(param[2]).item()\n",
        "            category_params[category].append(param)\n",
        "\n",
        "        for category in range(self.num_categories):\n",
        "            if len(category_params[category]) > 0:\n",
        "                cat_params = torch.stack(category_params[category])\n",
        "                for i, method in enumerate(self.methods[1:], start=1):\n",
        "                    channel_params = cat_params[:, [0, 1, i + 2]]\n",
        "                    interpolated_values = self.interpolate(method, channel_params)\n",
        "                    x[i] = torch.where(category_data.squeeze() == category, interpolated_values, x[i])\n",
        "                    param_grid[i] = torch.where(category_data.squeeze() == category, interpolated_values, param_grid[i])\n",
        "\n",
        "        return x, param_grid, param_mask\n",
        "\n",
        "\n",
        "    def normalize_data(self, params):\n",
        "        values = params[:, 2:]\n",
        "        min_val = values.min(0, keepdim=True)[0]\n",
        "        max_val = values.max(0, keepdim=True)[0]\n",
        "        normalized_values = (values - min_val) / (max_val - min_val + 1e-6)  # Adding a small constant to avoid division by zero\n",
        "        params[:, 2:] = normalized_values\n",
        "        return params\n",
        "\n",
        "    def create_categorical_data(self, params):\n",
        "        first_method = self.methods[0]\n",
        "        continuous_data = self.interpolate_method(first_method, params[:, :3])\n",
        "        return self.continuous_to_categorical(continuous_data)\n",
        "\n",
        "    def continuous_to_categorical(self, x):\n",
        "        return torch.clamp((x * self.num_categories).long(), 0, self.num_categories - 1)\n",
        "\n",
        "    def interpolate(self, method, channel_params):\n",
        "        if method == 'id':\n",
        "            return create_id_spatial_data(self.size, channel_params, self.grid)[0]\n",
        "        elif method == 'vid':\n",
        "            return create_vid_spatial_data(self.size, channel_params, self.grid)[0]\n",
        "        elif method == 'cvid':\n",
        "            return create_cvid_spatial_data(self.size, channel_params, self.grid)[0]\n",
        "        elif method == 'nn':\n",
        "            return create_nn_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'kriging':\n",
        "            return create_kriging_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'mps':\n",
        "            return create_mps_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'stationary':\n",
        "            return create_stationary_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'layered':\n",
        "            return create_layered_spatial_data(self.size, channel_params, self.grid)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported interpolation method: {method}\")\n",
        "\n",
        "    def interpolate_method(self, method, channel_params):\n",
        "        if method == 'id':\n",
        "            return create_id_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'vid':\n",
        "            return create_vid_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'cvid':\n",
        "            return create_cvid_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'nn':\n",
        "            return create_nn_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'kriging':\n",
        "            return create_kriging_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'layered':\n",
        "            return create_layered_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'mps':\n",
        "            return create_mps_spatial_data(self.size, channel_params, self.grid)\n",
        "        elif method == 'stationary':\n",
        "            return create_stationary_spatial_data(self.size, channel_params, self.grid)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported interpolation method: {method}\")\n",
        "\n",
        "\n",
        "param_generator = lambda: torch.rand(10, 5) * torch.tensor([32, 64, 1, 1, 1])\n",
        "param_generator = lambda: torch.cat([\n",
        "    torch.rand(10, 2) * torch.tensor([32, 64]),\n",
        "    torch.rand(10, 1).repeat(1, 3)\n",
        "], dim=1)\n",
        "size = (32, 64)\n",
        "\n",
        "#x, param_grid, param_mask = SpatialGenerator(size, param_generator, methods=['stationary', 'kriging', 'mps']).generate_item()\n",
        "#plot_sample(x, param_grid, param_mask)\n",
        "\n",
        "#num_categories = 20\n",
        "#x, param_grid, param_mask = CategoricalSpatialGenerator(size, param_generator, num_categories, methods=['mps', 'stationary']).generate_item()\n",
        "#plot_sample(x, param_grid, param_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK1RR7Wp2g76"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "class BaseModel:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "\n",
        "    def add_deposit(self, points, value):\n",
        "        self.layers.append((points, value))\n",
        "        return self\n",
        "\n",
        "    def _distribute_values(self, points, value):\n",
        "        num_points = len(points)\n",
        "        if isinstance(value, (int, float)):\n",
        "            return [value] * num_points\n",
        "        elif isinstance(value, (tuple, list)):\n",
        "            return np.interp(np.linspace(0, 1, num_points), np.linspace(0, 1, len(value)), value)\n",
        "        raise ValueError(\"Value must be a number or an array of numbers\")\n",
        "\n",
        "    def generate_primarys(self):\n",
        "        primarys = []\n",
        "        for layer, (points, value) in enumerate(self.layers):\n",
        "            distributed_values = self._distribute_values(points, value)\n",
        "            for (x, y), v in zip(points, distributed_values):\n",
        "                primarys.append((y, x, layer, v))\n",
        "        return torch.tensor(primarys, dtype=torch.float32)\n",
        "\n",
        "    def plot_model(self):\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        for i, (points, value) in enumerate(self.layers):\n",
        "            x_coords, y_coords = zip(*points)\n",
        "            distributed_values = self._distribute_values(points, value)\n",
        "            scatter = ax.scatter(x_coords, y_coords, c=distributed_values, cmap='viridis', s=50, edgecolors='black')\n",
        "            ax.plot(x_coords, y_coords, '-', alpha=0.5)\n",
        "            plt.colorbar(scatter, ax=ax, label=f'Layer {i}')\n",
        "        ax.set_ylim(ax.get_ylim()[::-1])  # Invert y-axis\n",
        "        ax.set_xlabel('X'), ax.set_ylabel('Y')\n",
        "        ax.set_title('Geological Model Layers')\n",
        "        ax.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def generate_points(num_points, width, elevations, noise_factor=0.1):\n",
        "    x = np.linspace(0, width, num_points)\n",
        "\n",
        "    # Interpolate elevations\n",
        "    if len(elevations) > 2:\n",
        "        control_points = np.linspace(0, width, len(elevations))\n",
        "        y = np.interp(x, control_points, elevations)\n",
        "    else:\n",
        "        y = np.linspace(elevations[0], elevations[-1], num_points)\n",
        "\n",
        "    # Add noise\n",
        "    elevation_range = max(elevations) - min(elevations)\n",
        "    noise = np.random.normal(0, noise_factor * elevation_range, num_points)\n",
        "    y += noise\n",
        "\n",
        "    return list(zip(x, y))\n",
        "\n",
        "def sine_vals(num_values, start=0, amp=40, noise=0.1):\n",
        "    x = np.linspace(0, 2 * np.pi, num_values)\n",
        "    amplitude = amp * np.random.rand()\n",
        "    phase = np.random.rand() * 2 * np.pi\n",
        "    y = amplitude * np.sin(x + phase) + np.random.normal(0, 0.1, num_values) + start\n",
        "    return y\n",
        "\n",
        "def generate_constrained_values(num_values, max_change=0.1):\n",
        "    base_value = random.random()\n",
        "    values = [base_value]\n",
        "    for _ in range(num_values - 1):\n",
        "        change = random.uniform(-max_change, max_change)\n",
        "        new_value = max(0, min(1, values[-1] + change))\n",
        "        values.append(new_value)\n",
        "    return values\n",
        "\n",
        "def two_layer_generator():\n",
        "    model = BaseModel()\n",
        "    width = 64\n",
        "    height = 32\n",
        "    layers = random.randint(2, 2)\n",
        "    points = random.randint(5, 15)\n",
        "    amp = height / layers\n",
        "\n",
        "    # First layer always at 0\n",
        "    first_layer_points = generate_points(points, width, [0, 0], noise_factor=0)\n",
        "    random_values = generate_constrained_values(random.randint(2, 5))\n",
        "    model.add_deposit(first_layer_points, random_values)\n",
        "\n",
        "    for i in range(1, layers):\n",
        "        random_values = generate_constrained_values(random.randint(2, 5))\n",
        "        model.add_deposit(\n",
        "            generate_points(points, width, sine_vals(points, amp * i - amp/2, amp=amp), noise_factor=0.05),\n",
        "            random_values\n",
        "        )\n",
        "\n",
        "    return model.generate_primarys()\n",
        "\n",
        "# Example usage:\n",
        "size = (32, 64)\n",
        "\n",
        "# Create the generator\n",
        "#generator = CategoricalSpatialGenerator(size, lambda: two_layer_generator(), num_categories=10, methods=['layered', 'vid'])\n",
        "\n",
        "# Generate the item\n",
        "#x, primary_grid, primary_mask = generator.generate_item()\n",
        "\n",
        "# Plot the sample\n",
        "#plot_sample(x, primary_grid, primary_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYy8p1c_Gmvu"
      },
      "outputs": [],
      "source": [
        "import os, random, torch, numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Grid sampling pattern\n",
        "def grid_sampling(size):\n",
        "    num_points = int(0.1 * size[0] * size[1])  # 10% of total points\n",
        "    step = max(1, int(min(size) / (num_points ** 0.5)))\n",
        "    mask = torch.zeros(1, *size)\n",
        "    mask[0, ::step, ::step] = 1\n",
        "    return mask\n",
        "\n",
        "# Clustered sampling pattern\n",
        "def clustered_sampling(size):\n",
        "    num_points = int(0.1 * size[0] * size[1])  # 10% of total points\n",
        "    mask = torch.zeros(1, *size)\n",
        "    num_clusters = 5\n",
        "    points_per_cluster = num_points // num_clusters\n",
        "    for _ in range(num_clusters):\n",
        "        center = torch.tensor([torch.randint(0, size[0], (1,)).item(),\n",
        "                               torch.randint(0, size[1], (1,)).item()])\n",
        "        cluster_points = torch.randn(points_per_cluster, 2) * torch.tensor([size[0], size[1]]) / 10 + center\n",
        "        cluster_points[:, 0] = cluster_points[:, 0].clamp(0, size[0] - 1)\n",
        "        cluster_points[:, 1] = cluster_points[:, 1].clamp(0, size[1] - 1)\n",
        "        cluster_points = cluster_points.long()\n",
        "        mask[0, cluster_points[:, 0], cluster_points[:, 1]] = 1\n",
        "    return mask\n",
        "\n",
        "\n",
        "class SpatialDataset(Dataset):\n",
        "    def __init__(self, num_generations, generator, sampling_fn, secondary_grid_fn, data_folder=None, dynamic_secondary_mask=False, x_channels=None, primary_channels=None, secondary_channels=None):\n",
        "        self.num_generations = num_generations\n",
        "        self.generator = generator\n",
        "        self.sampling_fn = sampling_fn\n",
        "        self.secondary_grid_fn = secondary_grid_fn\n",
        "        self.data_folder = data_folder\n",
        "        self.dynamic_secondary_mask = dynamic_secondary_mask\n",
        "        self.x_channels = x_channels\n",
        "        self.primary_channels = primary_channels\n",
        "        self.secondary_channels = secondary_channels\n",
        "\n",
        "        if data_folder is not None:\n",
        "            os.makedirs(self.data_folder, exist_ok=True)\n",
        "            if num_generations > 0:\n",
        "                self._generate_and_save_entries()\n",
        "            self.data = self._load_all_entries()\n",
        "        else:\n",
        "            self.data = self._generate_items()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _generate_and_save_entries(self):\n",
        "        entries = self._generate_items()\n",
        "        with open(os.path.join(self.data_folder, f'entries_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pkl'), 'wb') as f:\n",
        "            pickle.dump(entries, f)\n",
        "\n",
        "    def _load_all_entries(self):\n",
        "        entries = []\n",
        "        for file in os.listdir(self.data_folder):\n",
        "            if file.endswith('.pkl'):\n",
        "                with open(os.path.join(self.data_folder, file), 'rb') as f:\n",
        "                    entries.extend(pickle.load(f))\n",
        "        return entries\n",
        "\n",
        "    def _generate_items(self):\n",
        "        return [self._generate_item() for i in tqdm(range(self.num_generations), desc=\"Generating items\", mininterval=1.0)]\n",
        "\n",
        "    def _generate_item(self):\n",
        "        x, primary_grid, primary_mask = self.generator.generate_item()\n",
        "        secondary_grid = self.secondary_grid_fn(x)\n",
        "        secondary_mask = self.sampling_fn(secondary_grid.shape[1:])\n",
        "\n",
        "        return x, primary_grid, primary_mask, secondary_grid, secondary_mask\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, primary_grid, primary_mask, secondary_grid, saved_secondary_mask = self.data[idx]\n",
        "\n",
        "        if self.dynamic_secondary_mask:\n",
        "            secondary_mask = self.sampling_fn(secondary_grid.shape[1:])\n",
        "        else:\n",
        "            secondary_mask = saved_secondary_mask\n",
        "\n",
        "        x = self._apply_channel_selection(x, self.x_channels)\n",
        "        primary_grid = self._apply_channel_selection(primary_grid, self.primary_channels)\n",
        "        secondary_grid = self._apply_channel_selection(secondary_grid, self.secondary_channels)\n",
        "\n",
        "        return x, primary_grid, primary_mask, secondary_grid, secondary_mask\n",
        "\n",
        "    def _apply_channel_selection(self, tensor, channel_selection):\n",
        "        if channel_selection is not None:\n",
        "            if isinstance(channel_selection, int):\n",
        "                return tensor[channel_selection:channel_selection+1]\n",
        "            elif isinstance(channel_selection, (list, tuple)):\n",
        "                return tensor[list(channel_selection)]\n",
        "            else:\n",
        "                raise ValueError(\"channel_selection must be an integer, list, or tuple\")\n",
        "        return tensor\n",
        "\n",
        "# Example usage (rest of the code remains the same)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def secondary_grid_fn(x):\n",
        "    return 1-x\n",
        "\n",
        "def equal_grid_fn(x):\n",
        "    return x\n",
        "\n",
        "def random_sampling(size, min_samples=3):\n",
        "    total_points = size[0] * size[1]\n",
        "    target_samples = max(min_samples, int(0.01 * total_points))  # 10% of total points or min_samples, whichever is larger\n",
        "\n",
        "    mask = (torch.rand(1, *size) < (target_samples / total_points)).float()\n",
        "\n",
        "    # Ensure we have at least min_samples\n",
        "    while torch.sum(mask) < min_samples:\n",
        "        additional_samples = torch.rand(1, *size) < (min_samples - torch.sum(mask)) / total_points\n",
        "        mask = torch.logical_or(mask, additional_samples).float()\n",
        "\n",
        "    return mask\n",
        "\n",
        "def drilling_sampling(size, min_drillholes=5, max_drillholes=15, min_samples=3, max_samples=20):\n",
        "    mask = torch.zeros(1, *size)\n",
        "    height, width = size\n",
        "    num_drillholes = random.randint(min_drillholes, max_drillholes)\n",
        "\n",
        "    for _ in range(num_drillholes):\n",
        "        x = random.randint(0, width - 1)\n",
        "        num_samples = random.randint(min_samples, max_samples)\n",
        "        y_positions = random.sample(range(height), min(num_samples, height))\n",
        "        for y in y_positions:\n",
        "            mask[0, y, x] = 1\n",
        "\n",
        "    return mask\n",
        "generator = CategoricalSpatialGenerator(size, lambda: two_layer_generator(), num_categories=10, methods=['layered', 'vid'])\n",
        "dataset = SpatialDataset(1, generator, drilling_sampling, secondary_grid_fn, data_folder=\"data\", dynamic_secondary_mask=False, x_channels=1, secondary_channels=1, primary_channels=1)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
        "print(len(dataset))\n",
        "\n",
        "for batch in dataloader:\n",
        "    x, primary_grid, primary_mask, secondary_grid, secondary_mask = batch\n",
        "    print(f\"Shapes: x: {x.shape}, primary_grid: {primary_grid.shape}, primary_mask: {primary_mask.shape}, secondary_grid: {secondary_grid.shape}, secondary_mask: {secondary_mask.shape}\")\n",
        "\n",
        "    plot_sample(x[0], primary_grid[0], primary_mask[0])\n",
        "    plot_sample(secondary_grid[0], secondary_grid[0] * secondary_mask[0], secondary_mask[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzdjx-dw8JJ2"
      },
      "source": [
        "## Sparse Autoencoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLoyDuuW5GoH"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This implementation is based on the SparK (Sparse masKed modeling) approach\n",
        "from the paper \"Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling\"\n",
        "by Tian et al. (https://arxiv.org/pdf/2301.03580.pdf).\n",
        "\n",
        "Modifications:\n",
        "- Adapted the _get_active_ex_or_ii function to be more consistent with the original implementation\n",
        "- Integrated the sparse masking strategy with the ConvNeXt architecture\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from timm.models.layers import DropPath\n",
        "\n",
        "_cur_active: torch.Tensor = None\n",
        "\n",
        "def _get_active_ex_or_ii(H, W, returning_active_ex=True):\n",
        "    cur_H, cur_W = _cur_active.shape[-2:]\n",
        "\n",
        "    if H != cur_H or W != cur_W:\n",
        "        scale_factor = cur_H // H\n",
        "        active_ex = F.max_pool2d(_cur_active, kernel_size=scale_factor, stride=scale_factor)\n",
        "        active_ex = (active_ex > 0.5).float()\n",
        "    else:\n",
        "        active_ex = _cur_active\n",
        "\n",
        "    return active_ex if returning_active_ex else active_ex.squeeze(1).nonzero(as_tuple=True)\n",
        "\n",
        "\n",
        "def sp_conv_forward(self, x: torch.Tensor):\n",
        "    x = super(type(self), self).forward(x)\n",
        "    x *= _get_active_ex_or_ii(H=x.shape[2], W=x.shape[3], returning_active_ex=True)    # (BCHW) *= (B1HW), mask the output of conv\n",
        "    return x\n",
        "\n",
        "\n",
        "def sp_bn_forward(self, x: torch.Tensor):\n",
        "    ii = _get_active_ex_or_ii(H=x.shape[2], W=x.shape[3], returning_active_ex=False)\n",
        "\n",
        "    bhwc = x.permute(0, 2, 3, 1)\n",
        "    nc = bhwc[ii]                               # select the features on non-masked positions to form a flatten feature `nc`\n",
        "    nc = super(type(self), self).forward(nc)    # use BN1d to normalize this flatten feature `nc`\n",
        "\n",
        "    bchw = torch.zeros_like(bhwc)\n",
        "    bchw[ii] = nc\n",
        "    bchw = bchw.permute(0, 3, 1, 2)\n",
        "    return bchw\n",
        "\n",
        "\n",
        "class SparseConv2d(nn.Conv2d):\n",
        "    forward = sp_conv_forward   # hack: override the forward function; see `sp_conv_forward` above for more details\n",
        "\n",
        "\n",
        "class SparseMaxPooling(nn.MaxPool2d):\n",
        "    forward = sp_conv_forward   # hack: override the forward function; see `sp_conv_forward` above for more details\n",
        "\n",
        "\n",
        "class SparseAvgPooling(nn.AvgPool2d):\n",
        "    forward = sp_conv_forward   # hack: override the forward function; see `sp_conv_forward` above for more details\n",
        "\n",
        "\n",
        "class SparseBatchNorm2d(nn.BatchNorm1d):\n",
        "    forward = sp_bn_forward     # hack: override the forward function; see `sp_bn_forward` above for more details\n",
        "\n",
        "\n",
        "class SparseSyncBatchNorm2d(nn.SyncBatchNorm):\n",
        "    forward = sp_bn_forward     # hack: override the forward function; see `sp_bn_forward` above for more details\n",
        "\n",
        "\n",
        "class SparseConvNeXtLayerNorm(nn.LayerNorm):\n",
        "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\", sparse=True):\n",
        "        if data_format not in [\"channels_last\", \"channels_first\"]:\n",
        "            raise NotImplementedError\n",
        "        super().__init__(normalized_shape, eps, elementwise_affine=True)\n",
        "        self.data_format = data_format\n",
        "        self.sparse = sparse\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.ndim == 4: # BHWC or BCHW\n",
        "            if self.data_format == \"channels_last\": # BHWC\n",
        "                if self.sparse:\n",
        "                    ii = _get_active_ex_or_ii(H=x.shape[1], W=x.shape[2], returning_active_ex=False)\n",
        "                    nc = x[ii]\n",
        "                    nc = super(SparseConvNeXtLayerNorm, self).forward(nc)\n",
        "\n",
        "                    x = torch.zeros_like(x)\n",
        "                    x[ii] = nc\n",
        "                    return x\n",
        "                else:\n",
        "                    return super(SparseConvNeXtLayerNorm, self).forward(x)\n",
        "            else:       # channels_first, BCHW\n",
        "                if self.sparse:\n",
        "                    ii = _get_active_ex_or_ii(H=x.shape[2], W=x.shape[3], returning_active_ex=False)\n",
        "                    bhwc = x.permute(0, 2, 3, 1)\n",
        "                    nc = bhwc[ii]\n",
        "                    nc = super(SparseConvNeXtLayerNorm, self).forward(nc)\n",
        "\n",
        "                    x = torch.zeros_like(bhwc)\n",
        "                    x[ii] = nc\n",
        "                    return x.permute(0, 3, 1, 2)\n",
        "                else:\n",
        "                    u = x.mean(1, keepdim=True)\n",
        "                    s = (x - u).pow(2).mean(1, keepdim=True)\n",
        "                    x = (x - u) / torch.sqrt(s + self.eps)\n",
        "                    x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
        "                    return x\n",
        "        else:           # BLC or BC\n",
        "            if self.sparse:\n",
        "                raise NotImplementedError\n",
        "            else:\n",
        "                return super(SparseConvNeXtLayerNorm, self).forward(x)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return super(SparseConvNeXtLayerNorm, self).__repr__()[:-1] + f', ch={self.data_format.split(\"_\")[-1]}, sp={self.sparse})'\n",
        "\n",
        "\n",
        "class SparseConvNeXtBlock(nn.Module):\n",
        "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6, sparse=True, ks=7):\n",
        "        super().__init__()\n",
        "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=ks, padding=ks//2, groups=dim)  # depthwise conv\n",
        "        self.norm = SparseConvNeXtLayerNorm(dim, eps=1e-6, sparse=sparse)\n",
        "        self.pwconv1 = nn.Linear(dim, 4 * dim)  # pointwise/1x1 convs, implemented with linear layers\n",
        "        self.act = nn.GELU()\n",
        "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
        "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)),\n",
        "                                  requires_grad=True) if layer_scale_init_value > 0 else None\n",
        "        self.drop_path: nn.Module = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.sparse = sparse\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = x\n",
        "        x = self.dwconv(x)\n",
        "        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n",
        "        x = self.norm(x)\n",
        "        x = self.pwconv1(x)\n",
        "        x = self.act(x)            # GELU(0) == (0), so there is no need to mask x (no need to `x *= _get_active_ex_or_ii`)\n",
        "        x = self.pwconv2(x)\n",
        "        if self.gamma is not None:\n",
        "            x = self.gamma * x\n",
        "        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
        "\n",
        "        if self.sparse:\n",
        "            x *= _get_active_ex_or_ii(H=x.shape[2], W=x.shape[3], returning_active_ex=True)\n",
        "\n",
        "        x = input + self.drop_path(x)\n",
        "        return x\n",
        "\n",
        "    def __repr__(self):\n",
        "        return super(SparseConvNeXtBlock, self).__repr__()[:-1] + f', sp={self.sparse})'\n",
        "\n",
        "\n",
        "class SparseEncoder(nn.Module):\n",
        "    def __init__(self, cnn, input_size, sbn=False, verbose=False):\n",
        "        super(SparseEncoder, self).__init__()\n",
        "        self.sp_cnn = SparseEncoder.dense_model_to_sparse(m=cnn, verbose=verbose, sbn=sbn)\n",
        "        self.input_size, self.downsample_raito, self.enc_feat_map_chs = input_size, cnn.get_downsample_ratio(), cnn.get_feature_map_channels()\n",
        "\n",
        "    @staticmethod\n",
        "    def dense_model_to_sparse(m: nn.Module, verbose=False, sbn=False):\n",
        "        oup = m\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            m: nn.Conv2d\n",
        "            bias = m.bias is not None\n",
        "            oup = SparseConv2d(\n",
        "                m.in_channels, m.out_channels,\n",
        "                kernel_size=m.kernel_size, stride=m.stride, padding=m.padding,\n",
        "                dilation=m.dilation, groups=m.groups, bias=bias, padding_mode=m.padding_mode,\n",
        "            )\n",
        "            oup.weight.data.copy_(m.weight.data)\n",
        "            if bias:\n",
        "                oup.bias.data.copy_(m.bias.data)\n",
        "        elif isinstance(m, nn.MaxPool2d):\n",
        "            m: nn.MaxPool2d\n",
        "            oup = SparseMaxPooling(m.kernel_size, stride=m.stride, padding=m.padding, dilation=m.dilation, return_indices=m.return_indices, ceil_mode=m.ceil_mode)\n",
        "        elif isinstance(m, nn.AvgPool2d):\n",
        "            m: nn.AvgPool2d\n",
        "            oup = SparseAvgPooling(m.kernel_size, m.stride, m.padding, ceil_mode=m.ceil_mode, count_include_pad=m.count_include_pad, divisor_override=m.divisor_override)\n",
        "        elif isinstance(m, (nn.BatchNorm2d, nn.SyncBatchNorm)):\n",
        "            m: nn.BatchNorm2d\n",
        "            oup = (SparseSyncBatchNorm2d if sbn else SparseBatchNorm2d)(m.weight.shape[0], eps=m.eps, momentum=m.momentum, affine=m.affine, track_running_stats=m.track_running_stats)\n",
        "            oup.weight.data.copy_(m.weight.data)\n",
        "            oup.bias.data.copy_(m.bias.data)\n",
        "            oup.running_mean.data.copy_(m.running_mean.data)\n",
        "            oup.running_var.data.copy_(m.running_var.data)\n",
        "            oup.num_batches_tracked.data.copy_(m.num_batches_tracked.data)\n",
        "            if hasattr(m, \"qconfig\"):\n",
        "                oup.qconfig = m.qconfig\n",
        "        elif isinstance(m, nn.LayerNorm) and not isinstance(m, SparseConvNeXtLayerNorm):\n",
        "            m: nn.LayerNorm\n",
        "            oup = SparseConvNeXtLayerNorm(m.weight.shape[0], eps=m.eps)\n",
        "            oup.weight.data.copy_(m.weight.data)\n",
        "            oup.bias.data.copy_(m.bias.data)\n",
        "        elif isinstance(m, (nn.Conv1d,)):\n",
        "            raise NotImplementedError\n",
        "\n",
        "        for name, child in m.named_children():\n",
        "            oup.add_module(name, SparseEncoder.dense_model_to_sparse(child, verbose=verbose, sbn=sbn))\n",
        "        del m\n",
        "        return oup\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sp_cnn(x, hierarchical=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bFJXNpa9IIC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This implementation is based on the ConvNeXt architecture\n",
        "from the paper \"A ConvNet for the 2020s\"\n",
        "by Liu et al. (https://arxiv.org/pdf/2201.03545.pdf).\n",
        "\n",
        "Modifications:\n",
        "- Adapted to use a flexible number of stages, controlled by the lengths of 'depths' and 'dims' lists\n",
        "- Integrated with the SparK sparse masking strategy from Tian et al. (https://arxiv.org/pdf/2301.03580.pdf)\n",
        "- Added a custom Decoder class for upsampling and reconstruction\n",
        "\n",
        "The ConvNeXt architecture is combined with the sparse masking approach\n",
        "from SparK (Tian et al., https://arxiv.org/pdf/2301.03580.pdf)\n",
        "to create a sparse, hierarchical masked modeling framework for convolutional networks.\n",
        "\"\"\"\n",
        "\n",
        "from typing import List\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from timm.models.layers import trunc_normal_\n",
        "from timm.models import register_model\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "\n",
        "class ConvNeXt(nn.Module):\n",
        "    r\"\"\" ConvNeXt\n",
        "        A PyTorch impl of : `A ConvNet for the 2020s`  -\n",
        "          https://arxiv.org/pdf/2201.03545.pdf\n",
        "    Args:\n",
        "        in_chans (int): Number of input image channels. Default: 3\n",
        "        num_classes (int): Number of classes for classification head. Default: 1000\n",
        "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
        "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
        "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
        "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
        "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_chans=1, num_classes=1000,\n",
        "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0.,\n",
        "                 layer_scale_init_value=1e-6, head_init_scale=1., global_pool='avg',\n",
        "                 sparse=True,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.dims: List[int] = dims\n",
        "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
        "        stem = nn.Sequential(\n",
        "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
        "            SparseConvNeXtLayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\", sparse=sparse)\n",
        "        )\n",
        "        self.downsample_layers.append(stem)\n",
        "        for i in range(3):\n",
        "            downsample_layer = nn.Sequential(\n",
        "                SparseConvNeXtLayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\", sparse=sparse),\n",
        "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
        "            )\n",
        "            self.downsample_layers.append(downsample_layer)\n",
        "\n",
        "        self.stages = nn.ModuleList()  # 4 feature resolution stages, each consisting of multiple residual blocks\n",
        "        self.drop_path_rate = drop_path_rate\n",
        "        self.layer_scale_init_value = layer_scale_init_value\n",
        "        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
        "        cur = 0\n",
        "        for i in range(4):\n",
        "            stage = nn.Sequential(\n",
        "                *[SparseConvNeXtBlock(dim=dims[i], drop_path=dp_rates[cur + j],\n",
        "                                      layer_scale_init_value=layer_scale_init_value, sparse=sparse) for j in range(depths[i])]\n",
        "            )\n",
        "            self.stages.append(stage)\n",
        "            cur += depths[i]\n",
        "        self.depths = depths\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "        if num_classes > 0:\n",
        "            self.norm = SparseConvNeXtLayerNorm(dims[-1], eps=1e-6, sparse=False)  # final norm layer for LE/FT; should not be sparse\n",
        "            self.fc = nn.Linear(dims[-1], num_classes)\n",
        "        else:\n",
        "            self.norm = nn.Identity()\n",
        "            self.fc = nn.Identity()\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def get_downsample_ratio(self) -> int:\n",
        "        return 32\n",
        "\n",
        "    def get_feature_map_channels(self) -> List[int]:\n",
        "        return self.dims\n",
        "\n",
        "    def forward(self, x, hierarchical=False):\n",
        "        if hierarchical:\n",
        "            ls = []\n",
        "            for i in range(4):\n",
        "                x = self.downsample_layers[i](x)\n",
        "                x = self.stages[i](x)\n",
        "                ls.append(x)\n",
        "            return ls\n",
        "        else:\n",
        "            return self.fc(self.norm(x.mean([-2, -1]))) # (B, C, H, W) =mean=> (B, C) =norm&fc=> (B, NumCls)\n",
        "\n",
        "    def get_classifier(self):\n",
        "        return self.fc\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return f'drop_path_rate={self.drop_path_rate}, layer_scale_init_value={self.layer_scale_init_value:g}'\n",
        "\n",
        "def is_pow2n(x):\n",
        "    return x > 0 and (x & (x - 1) == 0)\n",
        "\n",
        "class UNetBlock(nn.Module):\n",
        "    def __init__(self, cin, cout, bn2d):\n",
        "        \"\"\"\n",
        "        a UNet block with 2x up sampling\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.up_sample = nn.ConvTranspose2d(cin, cin, kernel_size=4, stride=2, padding=1, bias=True)\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(cin, cin, kernel_size=3, stride=1, padding=1, bias=False), bn2d(cin), nn.ReLU6(inplace=True),\n",
        "            nn.Conv2d(cin, cout, kernel_size=3, stride=1, padding=1, bias=False), bn2d(cout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up_sample(x)\n",
        "        return self.conv(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, up_sample_ratio, out_chans=1, width=768, sbn=True):   # todo: the decoder's width follows a simple halfing rule; you can change it to any other rule\n",
        "        super().__init__()\n",
        "        self.width = width\n",
        "        assert is_pow2n(up_sample_ratio)\n",
        "        n = round(math.log2(up_sample_ratio))\n",
        "        channels = [self.width // 2 ** i for i in range(n + 1)] # todo: the decoder's width follows a simple halfing rule; you can change it to any other rule\n",
        "        bn2d = nn.SyncBatchNorm if sbn else nn.BatchNorm2d\n",
        "        self.dec = nn.ModuleList([UNetBlock(cin, cout, bn2d) for (cin, cout) in zip(channels[:-1], channels[1:])])\n",
        "        self.proj = nn.Conv2d(channels[-1], out_chans, kernel_size=1, stride=1, bias=True)\n",
        "\n",
        "        self.initialize()\n",
        "\n",
        "    def forward(self, to_dec: List[torch.Tensor]):\n",
        "        x = 0\n",
        "        for i, d in enumerate(self.dec):\n",
        "            if i < len(to_dec) and to_dec[i] is not None:\n",
        "                x = x + to_dec[i]\n",
        "            x = self.dec[i](x)\n",
        "        return self.proj(x)\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f'width={self.width}'\n",
        "\n",
        "    def initialize(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                trunc_normal_(m.weight, std=.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Conv2d):\n",
        "                trunc_normal_(m.weight, std=.02)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.)\n",
        "            elif isinstance(m, (nn.LayerNorm, nn.BatchNorm1d, nn.BatchNorm2d, nn.SyncBatchNorm)):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_CeKSqp3T-r"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train_model(sparse_encoder, imputation_decoder, subsurface_decoder, dataloader, num_epochs=10, learning_rate=1e-4, device=\"cuda\", save_model=False, model_save_path=\"model.pth\", use_secondary=True, use_input_mask=True, visualize=True, input_reconstruction_weight=10.0, use_sparse=True):\n",
        "    sparse_encoder.to(device)\n",
        "    subsurface_decoder.to(device)\n",
        "    sparse_encoder.train()\n",
        "    subsurface_decoder.train()\n",
        "\n",
        "    if use_secondary:\n",
        "        imputation_decoder.to(device)\n",
        "        imputation_decoder.train()\n",
        "        optimizer = optim.AdamW(list(sparse_encoder.parameters()) + list(imputation_decoder.parameters()) + list(subsurface_decoder.parameters()), lr=learning_rate)\n",
        "    else:\n",
        "        optimizer = optim.AdamW(list(sparse_encoder.parameters()) + list(subsurface_decoder.parameters()), lr=learning_rate)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    training_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_primary_loss = 0\n",
        "        total_secondary_loss = 0\n",
        "        total_imput_reconstruction_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            primary_grid, realization_input_grid, realization_input_mask, secondary_grid, random_sampling_mask = batch\n",
        "            batch_primary_grid = primary_grid.to(device)\n",
        "            batch_realization_input_grid = realization_input_grid.to(device)\n",
        "            batch_realization_input_mask = realization_input_mask.to(device)\n",
        "            batch_secondary_grid = secondary_grid.to(device).float()\n",
        "            batch_random_sampling_mask = random_sampling_mask.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            global _cur_active\n",
        "\n",
        "            if use_sparse:\n",
        "                if use_input_mask:\n",
        "                    _cur_active = batch_realization_input_mask\n",
        "                else:\n",
        "                    _cur_active = batch_random_sampling_mask\n",
        "            else:\n",
        "                _cur_active = torch.ones_like(batch_realization_input_mask).to(device)\n",
        "\n",
        "            if use_secondary:\n",
        "                model_input = batch_secondary_grid * _cur_active\n",
        "            else:\n",
        "                model_input = batch_primary_grid * _cur_active\n",
        "\n",
        "            features = sparse_encoder(model_input)\n",
        "\n",
        "            primary_output = subsurface_decoder(features[::-1])\n",
        "            primary_loss = criterion(primary_output, batch_primary_grid)\n",
        "            total_primary_loss += primary_loss.item()\n",
        "\n",
        "            if use_secondary:\n",
        "                secondary_output = imputation_decoder(features[::-1])\n",
        "                secondary_loss = criterion(secondary_output, batch_secondary_grid)\n",
        "                imput_reconstruction_loss = criterion(secondary_output * _cur_active, batch_secondary_grid * _cur_active)\n",
        "                total_secondary_loss += secondary_loss.item()\n",
        "            else:\n",
        "                input_reconstruction_loss = criterion(primary_output * _cur_active, batch_primary_grid * _cur_active)\n",
        "                secondary_loss = 0\n",
        "\n",
        "            total_imput_reconstruction_loss += input_reconstruction_loss.item()\n",
        "            loss = secondary_loss + primary_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_primary_loss = total_primary_loss / num_batches\n",
        "        avg_imput_reconstruction_loss = total_imput_reconstruction_loss / num_batches\n",
        "\n",
        "        if use_secondary:\n",
        "            avg_secondary_loss = total_secondary_loss / num_batches\n",
        "            training_losses.append({'epoch': epoch+1, 'secondary_loss': avg_secondary_loss, 'primary_loss': avg_primary_loss})\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Average Secondary Loss: {avg_secondary_loss:.10f}, Average Primary Loss: {avg_primary_loss:.10f}, Average Imput Reconstruction Loss: {avg_imput_reconstruction_loss:.10f}\")\n",
        "        else:\n",
        "            training_losses.append({'epoch': epoch+1, 'primary_loss': avg_primary_loss})\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Average Primary Loss: {avg_primary_loss:.10f}, Average Imput Reconstruction Loss: {avg_imput_reconstruction_loss:.10f}\")\n",
        "\n",
        "        if visualize:\n",
        "            with torch.no_grad():\n",
        "                visualize_results(batch_realization_input_grid[0], \"realization_input_grid\", batch_realization_input_mask[0], \"realization_input_mask\", batch_random_sampling_mask[0], \"random_sampling_mask\")\n",
        "                visualize_results(batch_primary_grid[0], \"primary_grid\", primary_output[0], \"primary_output\")\n",
        "                if use_secondary:\n",
        "                    visualize_results(batch_secondary_grid[0], \"secondary_grid\", secondary_output[0], \"secondary_output\")\n",
        "\n",
        "    if save_model:\n",
        "        model_dict = {\n",
        "            'sparse_encoder_state_dict': sparse_encoder.state_dict(),\n",
        "            'subsurface_decoder_state_dict': subsurface_decoder.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'use_secondary': use_secondary,\n",
        "            'use_sparse': use_sparse,\n",
        "            'training_losses': training_losses\n",
        "        }\n",
        "        if use_secondary:\n",
        "            model_dict['imputation_decoder_state_dict'] = imputation_decoder.state_dict()\n",
        "        torch.save(model_dict, model_save_path)\n",
        "        print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "    return sparse_encoder, imputation_decoder if use_secondary else None, subsurface_decoder, training_losses\n",
        "\n",
        "def load_model(model_path, sparse_encoder, imputation_decoder, subsurface_decoder, device=\"cuda\"):\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "    sparse_encoder.load_state_dict(checkpoint['sparse_encoder_state_dict'])\n",
        "    subsurface_decoder.load_state_dict(checkpoint['subsurface_decoder_state_dict'])\n",
        "    training_losses = checkpoint.get('training_losses', None)\n",
        "\n",
        "    use_secondary = checkpoint.get('use_secondary', True)\n",
        "    use_sparse = checkpoint.get('use_sparse', True)\n",
        "\n",
        "    if use_secondary:\n",
        "        if imputation_decoder is None:\n",
        "            raise ValueError(\"Model was saved with imputation, but no imputation_decoder was provided.\")\n",
        "        imputation_decoder.load_state_dict(checkpoint['imputation_decoder_state_dict'])\n",
        "    elif imputation_decoder is not None:\n",
        "        print(\"Warning: imputation_decoder provided but model was saved without imputation. Ignoring imputation_decoder.\")\n",
        "\n",
        "    return sparse_encoder, imputation_decoder if use_secondary else None, subsurface_decoder, use_secondary, use_sparse, training_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzAAYkLPD9FC"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOKCf2dF1EGA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.colors as mcolors\n",
        "\n",
        "def evaluate_model(sparse_encoder, subsurface_decoder, dataloader, device=\"cuda\", use_sparse=False, use_secondary=False, use_input_mask=True):\n",
        "    sparse_encoder.to(device)\n",
        "    subsurface_decoder.to(device)\n",
        "    sparse_encoder.eval()\n",
        "    subsurface_decoder.eval()\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    total_loss = 0\n",
        "    total_variance = 0\n",
        "    num_batches = 0\n",
        "    all_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            primary_grid, realization_input_grid, realization_input_mask, secondary_grid, random_sampling_mask = batch\n",
        "            batch_primary_grid = primary_grid.to(device)\n",
        "            batch_realization_input_grid = realization_input_grid.to(device)\n",
        "            batch_realization_input_mask = realization_input_mask.to(device)\n",
        "            batch_secondary_grid = secondary_grid.to(device).float()\n",
        "            batch_random_sampling_mask = random_sampling_mask.to(device)\n",
        "\n",
        "            global _cur_active\n",
        "\n",
        "            if use_sparse:\n",
        "                if use_input_mask:\n",
        "                    _cur_active = batch_realization_input_mask\n",
        "                else:\n",
        "                    _cur_active = batch_random_sampling_mask\n",
        "            else:\n",
        "                _cur_active = torch.ones_like(batch_realization_input_mask).to(device)\n",
        "\n",
        "            if use_secondary:\n",
        "                model_input = batch_secondary_grid * _cur_active\n",
        "            else:\n",
        "                model_input = batch_primary_grid * _cur_active\n",
        "\n",
        "            features = sparse_encoder(model_input)\n",
        "\n",
        "            primary_output = subsurface_decoder(features[::-1])\n",
        "\n",
        "            # Store outputs for variance calculation\n",
        "            all_outputs.append(primary_output.cpu())\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(primary_output, batch_primary_grid)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Compute variance of predictions\n",
        "            batch_variance = torch.var(primary_output).item()\n",
        "            total_variance += batch_variance\n",
        "\n",
        "            num_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_variance = total_variance / num_batches\n",
        "\n",
        "    # Calculate overall variance across all predictions\n",
        "    all_outputs = torch.cat(all_outputs, dim=0)\n",
        "    total_prediction_variance = torch.var(all_outputs).item()\n",
        "\n",
        "    return avg_loss, avg_variance, total_prediction_variance\n",
        "\n",
        "# Define the process_batch function\n",
        "def process_batch(sparse_encoder, subsurface_decoder, batch, device=\"cuda\", use_secondary=False, use_sparse=False, use_input_mask=True):\n",
        "    sparse_encoder.eval()\n",
        "    subsurface_decoder.eval()\n",
        "    with torch.no_grad():\n",
        "        primary_grid, realization_input_grid, realization_input_mask, secondary_grid, random_sampling_mask = batch\n",
        "        batch_primary_grid = primary_grid.to(device)\n",
        "        batch_realization_input_grid = realization_input_grid.to(device)\n",
        "        batch_realization_input_mask = realization_input_mask.to(device)\n",
        "        batch_secondary_grid = secondary_grid.to(device).float()\n",
        "        batch_random_sampling_mask = random_sampling_mask.to(device)\n",
        "\n",
        "        global _cur_active\n",
        "\n",
        "        if use_sparse:\n",
        "            if use_input_mask:\n",
        "                _cur_active = batch_realization_input_mask\n",
        "                current_mask = batch_realization_input_mask\n",
        "            else:\n",
        "                _cur_active = batch_random_sampling_mask\n",
        "                current_mask = batch_random_sampling_mask\n",
        "        else:\n",
        "            _cur_active = torch.ones_like(batch_realization_input_mask).to(device)\n",
        "            current_mask = torch.ones_like(batch_realization_input_mask).to(device)\n",
        "\n",
        "        if use_secondary:\n",
        "            model_input = batch_secondary_grid * _cur_active\n",
        "        else:\n",
        "            model_input = batch_primary_grid * _cur_active\n",
        "\n",
        "        features = sparse_encoder(model_input)\n",
        "\n",
        "        primary_output = subsurface_decoder(features[::-1])\n",
        "\n",
        "        return model_input.cpu(), primary_output.cpu(), current_mask.cpu(), batch_primary_grid.cpu()\n",
        "\n",
        "def plot_collected_images(collected_images, images_per_row=4):\n",
        "    \"\"\"\n",
        "    Visualize collected images with data validation and proper tensor handling.\n",
        "    If original_image is present in the data, displays it alongside the prediction.\n",
        "    \"\"\"\n",
        "    num_images = len(collected_images)\n",
        "    # Double the columns if we have original images to show them side by side\n",
        "    has_originals = any('original_image' in data for data in collected_images)\n",
        "    cols_per_item = 2 if has_originals else 1\n",
        "    images_per_row = min(images_per_row, num_images)\n",
        "    num_rows = (num_images + images_per_row - 1) // images_per_row\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, images_per_row * cols_per_item,\n",
        "                            figsize=(5 * images_per_row * cols_per_item, 5 * num_rows))\n",
        "    if num_rows == 1 and images_per_row == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for idx, data in enumerate(collected_images):\n",
        "        # Calculate base index for this item's axes\n",
        "        base_idx = idx * cols_per_item\n",
        "\n",
        "        try:\n",
        "            input_grid = data['input_grid'][0].squeeze().cpu().numpy()\n",
        "            output_grid = data['output_grid'][0].squeeze().cpu().numpy()\n",
        "            input_mask = data['input_mask'][0].squeeze().cpu().numpy()\n",
        "            title = data['title']\n",
        "\n",
        "            # Plot original image if available\n",
        "            if has_originals:\n",
        "                ax_orig = axes[base_idx]\n",
        "                if 'original_image' in data:\n",
        "                    original = data['original_image'][0].squeeze().cpu().numpy()\n",
        "                    im_orig = ax_orig.imshow(original, cmap='viridis', interpolation='nearest')\n",
        "                    ax_orig.set_title(f\"{title}\\n(Original)\")\n",
        "                    plt.colorbar(im_orig, ax=ax_orig)\n",
        "                else:\n",
        "                    ax_orig.text(0.5, 0.5, 'No original image',\n",
        "                               ha='center', va='center', transform=ax_orig.transAxes)\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Use next axis for prediction\n",
        "                ax = axes[base_idx + 1]\n",
        "            else:\n",
        "                ax = axes[base_idx]\n",
        "\n",
        "            # Plot the predicted values as background\n",
        "            im = ax.imshow(output_grid, cmap='viridis', interpolation='nearest')\n",
        "\n",
        "            # Get mask indices and corresponding values\n",
        "            mask_indices = np.argwhere(input_mask > 0)\n",
        "            if len(mask_indices) > 0:  # Only plot scatter if we have points\n",
        "                mask_values = input_grid[tuple(mask_indices.T)]  # Use proper indexing\n",
        "\n",
        "                # Verify we have the same number of points and values\n",
        "                assert len(mask_indices) == len(mask_values), \\\n",
        "                    f\"Mismatch between number of points ({len(mask_indices)}) and values ({len(mask_values)})\"\n",
        "\n",
        "                scatter = ax.scatter(mask_indices[:, 1],\n",
        "                                   mask_indices[:, 0],\n",
        "                                   c=mask_values,\n",
        "                                   cmap='viridis',\n",
        "                                   edgecolors='black',\n",
        "                                   s=50)\n",
        "\n",
        "            ax.set_title(f\"{title}\\n(Prediction)\" if has_originals else title)\n",
        "            ax.axis('off')\n",
        "            plt.colorbar(im, ax=ax)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Create an error message plot\n",
        "            current_ax = axes[base_idx]\n",
        "            current_ax.text(0.5, 0.5, f'Error processing image {idx}\\n{str(e)}',\n",
        "                          ha='center', va='center', transform=current_ax.transAxes, color='red')\n",
        "            current_ax.axis('off')\n",
        "\n",
        "            # If we're showing originals, clear the second axis too\n",
        "            if has_originals and base_idx + 1 < len(axes):\n",
        "                axes[base_idx + 1].axis('off')\n",
        "\n",
        "    # Remove any empty subplots\n",
        "    total_plots = num_rows * images_per_row * cols_per_item\n",
        "    for idx in range(len(collected_images) * cols_per_item, total_plots):\n",
        "        fig.delaxes(axes[idx])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf9TO118wmIs"
      },
      "source": [
        "# Non sparse model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8hKzG4vF9SQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Define data ranges and max epochs\n",
        "data_ranges = [100,200,400,800,1600,3200,6400,12800]\n",
        "epochs = [1,2,4,8,16,32,64,128]\n",
        "\n",
        "# Initialize results list\n",
        "results = []\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define test datasets and dataloaders for different scenarios\n",
        "# All test sets will use the same size (1000 samples) but different point ranges\n",
        "interpolation_generator = lambda: torch.rand(torch.randint(3, 50, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_close_generator = lambda: torch.rand(torch.randint(51, 70, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_far_generator = lambda: torch.rand(torch.randint(70, 90, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "\n",
        "# Create test datasets\n",
        "test_generators = {\n",
        "    'interpolation': interpolation_generator,\n",
        "    'extrapolation_close': extrapolation_close_generator,\n",
        "    'extrapolation_far': extrapolation_far_generator\n",
        "}\n",
        "\n",
        "test_datasets = {}\n",
        "for name, gen in test_generators.items():\n",
        "    generator_obj = SpatialGenerator((64, 64), gen, methods=['kriging'])\n",
        "    test_dataset = SpatialDataset(1000, generator_obj, drilling_sampling, lambda x: x,\n",
        "                                  dynamic_secondary_mask=True, x_channels=0,\n",
        "                                  secondary_channels=0, primary_channels=0)\n",
        "    test_datasets[name] = test_dataset\n",
        "\n",
        "test_dataloaders = {name: DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                     num_workers=0, pin_memory=True) for name, dataset in test_datasets.items()}\n",
        "\n",
        "# Prepare to collect images for plotting\n",
        "collected_images = []\n",
        "use_sparse=False\n",
        "use_input_mask=True\n",
        "\n",
        "for data_range in data_ranges:\n",
        "    print(f\"\\nStarting training with data size: {data_range}\")\n",
        "\n",
        "    # Create training dataset using the same range as interpolation test (3-50)\n",
        "    generator = SpatialGenerator((64, 64), interpolation_generator, methods=['kriging'])\n",
        "    train_dataset = SpatialDataset(data_range, generator, drilling_sampling, lambda x: x,\n",
        "                                   dynamic_secondary_mask=True, x_channels=0,\n",
        "                                   secondary_channels=0, primary_channels=0)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
        "                                  num_workers=0, pin_memory=True)\n",
        "\n",
        "    # Initialize the models\n",
        "    convnext = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]).to(device)\n",
        "    sparse_encoder = SparseEncoder(convnext, input_size=(64, 64)).to(device)\n",
        "    subsurface_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "\n",
        "    # Progressive training loop\n",
        "    current_epoch = 0\n",
        "\n",
        "    for target_epoch in epochs:\n",
        "        epochs_to_train = target_epoch - current_epoch\n",
        "        if epochs_to_train <= 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"Training from epoch {current_epoch + 1} to {target_epoch}\")\n",
        "\n",
        "        # Start timing the training\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        # Train the model\n",
        "        sparse_encoder, _, subsurface_decoder, training_losses = train_model(\n",
        "            sparse_encoder, None, subsurface_decoder, train_dataloader,\n",
        "            use_sparse=use_sparse,\n",
        "            model_save_path=f\"model_data{data_range}_epochs{target_epoch}.pth\",\n",
        "            num_epochs=epochs_to_train,\n",
        "            use_secondary=False,\n",
        "            use_input_mask=use_input_mask,\n",
        "            device=device,\n",
        "            save_model=False,\n",
        "            visualize=False\n",
        "        )\n",
        "\n",
        "        # End timing the training\n",
        "        training_end_time = time.time()\n",
        "        training_time = training_end_time - training_start_time  # Calculate training time\n",
        "\n",
        "        # Collect final training loss\n",
        "        final_training_loss = training_losses[-1]['primary_loss']\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        test_metrics = {}\n",
        "        evaluation_times = {}\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        for name, dataloader in test_dataloaders.items():\n",
        "            # Start timing the evaluation\n",
        "            evaluation_start_time = time.time()\n",
        "\n",
        "            loss, variance, total_variance = evaluate_model(\n",
        "                sparse_encoder, subsurface_decoder,\n",
        "                dataloader, device=device,\n",
        "                use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "\n",
        "            # End timing the evaluation\n",
        "            evaluation_end_time = time.time()\n",
        "            evaluation_time = evaluation_end_time - evaluation_start_time  # Calculate evaluation time\n",
        "\n",
        "            test_metrics[name] = {\n",
        "                'loss': loss,\n",
        "                'batch_variance': variance,\n",
        "                'total_variance': total_variance\n",
        "            }\n",
        "            evaluation_times[name] = evaluation_time  # Store evaluation time\n",
        "\n",
        "        # Append the results\n",
        "        results.append({\n",
        "            'data_size': data_range,\n",
        "            'epochs': target_epoch,\n",
        "            'training_loss': final_training_loss,\n",
        "            'training_time': training_time,  # Add training time\n",
        "            'evaluation_time_interpolation': evaluation_times['interpolation'],  # Add evaluation times\n",
        "            'evaluation_time_extrapolation_close': evaluation_times['extrapolation_close'],\n",
        "            'evaluation_time_extrapolation_far': evaluation_times['extrapolation_far'],\n",
        "            'test_loss_interpolation': test_metrics['interpolation']['loss'],\n",
        "            'test_variance_interpolation': test_metrics['interpolation']['total_variance'],\n",
        "            'test_loss_extrapolation_close': test_metrics['extrapolation_close']['loss'],\n",
        "            'test_variance_extrapolation_close': test_metrics['extrapolation_close']['total_variance'],\n",
        "            'test_loss_extrapolation_far': test_metrics['extrapolation_far']['loss'],\n",
        "            'test_variance_extrapolation_far': test_metrics['extrapolation_far']['total_variance'],\n",
        "            'training_points_range': '3-50'\n",
        "        })\n",
        "\n",
        "        current_epoch = target_epoch\n",
        "\n",
        "        # Process and collect images for training data\n",
        "        train_iter = iter(train_dataloader)\n",
        "        train_batch = next(train_iter)\n",
        "        train_input, train_output, train_mask = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, train_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "        )\n",
        "        collected_images.append({\n",
        "            'title': f'Train Size: {data_range}, Epochs: {target_epoch}',\n",
        "            'input_grid': train_input,\n",
        "            'output_grid': train_output,\n",
        "            'input_mask': train_mask\n",
        "        })\n",
        "\n",
        "        # Process and collect images for test datasets\n",
        "        for name, dataset in test_datasets.items():\n",
        "            test_dataloader = DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                         num_workers=0, pin_memory=True)\n",
        "            test_iter = iter(test_dataloader)\n",
        "            test_batch = next(test_iter)\n",
        "            test_input, test_output, test_mask = process_batch(\n",
        "                sparse_encoder, subsurface_decoder, test_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "            collected_images.append({\n",
        "                'title': f'Test: {name}, Epochs: {target_epoch}',\n",
        "                'input_grid': test_input,\n",
        "                'output_grid': test_output,\n",
        "                'input_mask': test_mask\n",
        "            })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n",
        "\n",
        "# Create visualization plots\n",
        "plt.style.use('seaborn')\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
        "\n",
        "# 1. Test Losses vs Data Size for Different Epochs\n",
        "ax1 = axes[0, 0]\n",
        "test_types = {\n",
        "    'test_loss_interpolation': 'Interpolation (3-50)',\n",
        "    'test_loss_extrapolation_close': 'Close Extrapolation (51-70)',\n",
        "    'test_loss_extrapolation_far': 'Far Extrapolation (70-90)'\n",
        "}\n",
        "\n",
        "for test_type, label in test_types.items():\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax1.plot(epoch_data['data_size'], epoch_data[test_type],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax1.set_xlabel('Training Data Size')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.set_title('Test Losses vs Training Data Size\\n(Training Range: 3-50 points)')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True)\n",
        "\n",
        "# 2. Test Losses vs Epochs for Different Data Sizes\n",
        "ax2 = axes[0, 1]\n",
        "for test_type, label in test_types.items():\n",
        "    for data_size in data_ranges:\n",
        "        size_data = df_results[df_results['data_size'] == data_size]\n",
        "        ax2.plot(size_data['epochs'], size_data[test_type],\n",
        "                 label=f'{label} (Size {data_size})', marker='o', alpha=0.7)\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Test Loss')\n",
        "ax2.set_title('Test Losses vs Epochs\\n(Training Range: 3-50 points)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True)\n",
        "\n",
        "# 3. Heatmaps for each test type including Training Loss\n",
        "fig_heatmaps, axes_heatmaps = plt.subplots(1, 4, figsize=(25, 6))\n",
        "test_types_with_training = {\n",
        "    'training_loss': 'Training Loss',\n",
        "    **test_types\n",
        "}\n",
        "for idx, (test_type, label) in enumerate(test_types_with_training.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=test_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_heatmaps[idx])\n",
        "    axes_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_heatmaps.tight_layout()\n",
        "# Removed plt.show() here\n",
        "\n",
        "# 4. Comparison of test types\n",
        "ax4 = axes[1, 1]\n",
        "box_data = [df_results[test_type] for test_type in test_types.keys()]\n",
        "ax4.boxplot(box_data, labels=[label.replace('\\n', ' ') for label in test_types.values()])\n",
        "ax4.set_ylabel('Test Loss')\n",
        "ax4.set_title('Distribution of Test Losses by Type\\n(Training Range: 3-50 points)')\n",
        "ax4.grid(True)\n",
        "\n",
        "# 5. Loss Ratio Analysis\n",
        "ax3 = axes[1, 0]\n",
        "df_results['close_extrapolation_ratio'] = df_results['test_loss_extrapolation_close'] / df_results['test_loss_interpolation']\n",
        "df_results['far_extrapolation_ratio'] = df_results['test_loss_extrapolation_far'] / df_results['test_loss_interpolation']\n",
        "\n",
        "for ratio, label in [('close_extrapolation_ratio', 'Close Extrapolation / Interpolation'),\n",
        "                     ('far_extrapolation_ratio', 'Far Extrapolation / Interpolation')]:\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax3.plot(epoch_data['data_size'], epoch_data[ratio],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax3.axhline(y=1, color='r', linestyle='--', label='Baseline (Equal Performance)')\n",
        "ax3.set_xlabel('Training Data Size')\n",
        "ax3.set_ylabel('Loss Ratio')\n",
        "ax3.set_title('Extrapolation Performance Relative to Interpolation\\n(Training Range: 3-50 points)')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(True)\n",
        "\n",
        "# Heatmaps for variances of each test type\n",
        "fig_variance_heatmaps, axes_variance_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "variance_test_types = {\n",
        "    'test_variance_interpolation': 'Interpolation Variance',\n",
        "    'test_variance_extrapolation_close': 'Close Extrapolation Variance',\n",
        "    'test_variance_extrapolation_far': 'Far Extrapolation Variance'\n",
        "}\n",
        "for idx, (variance_type, label) in enumerate(variance_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=variance_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_variance_heatmaps[idx])\n",
        "    axes_variance_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_variance_heatmaps.tight_layout()\n",
        "\n",
        "# 7. Training Loss Heatmap (This remains unchanged)\n",
        "ax7 = axes[2, 1]\n",
        "training_loss_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_loss')\n",
        "sns.heatmap(training_loss_pivot, annot=True, fmt=\".6f\", cmap='viridis', ax=ax7)\n",
        "ax7.set_title('Training Loss Heatmap')\n",
        "\n",
        "# 8. Training Time Heatmap\n",
        "ax8 = axes[2, 0]\n",
        "training_time_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_time')\n",
        "sns.heatmap(training_time_pivot, annot=True, fmt=\".2f\", cmap='Blues', ax=ax8)\n",
        "ax8.set_title('Training Time Heatmap')\n",
        "ax8.set_xlabel('Epochs')\n",
        "ax8.set_ylabel('Training Data Size')\n",
        "\n",
        "# 9. Evaluation Time Heatmaps for each test set\n",
        "fig_eval_time_heatmaps, axes_eval_time_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "evaluation_time_test_types = {\n",
        "    'evaluation_time_interpolation': 'Interpolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_close': 'Close Extrapolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_far': 'Far Extrapolation Evaluation Time'\n",
        "}\n",
        "for idx, (eval_time_type, label) in enumerate(evaluation_time_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=eval_time_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap='Greens', ax=axes_eval_time_heatmaps[idx])\n",
        "    axes_eval_time_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_eval_time_heatmaps[idx].set_xlabel('Epochs')\n",
        "    axes_eval_time_heatmaps[idx].set_ylabel('Training Data Size')\n",
        "fig_eval_time_heatmaps.tight_layout()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Call the function to plot collected images\n",
        "plot_collected_images(collected_images, images_per_row=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOC_ZnTEWqzm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Define data ranges and max epochs\n",
        "data_ranges = [100,200,400,800,1600,3200,6400,12800]\n",
        "epochs = [1,2,4,8,16,32,64,128]\n",
        "\n",
        "# Initialize results list\n",
        "results = []\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define test datasets and dataloaders for different scenarios\n",
        "# All test sets will use the same size (1000 samples) but different point ranges\n",
        "interpolation_generator = lambda: torch.rand(torch.randint(3, 50, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_close_generator = lambda: torch.rand(torch.randint(51, 70, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_far_generator = lambda: torch.rand(torch.randint(70, 90, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "\n",
        "# Create test datasets\n",
        "test_generators = {\n",
        "    'interpolation': interpolation_generator,\n",
        "    'extrapolation_close': extrapolation_close_generator,\n",
        "    'extrapolation_far': extrapolation_far_generator\n",
        "}\n",
        "\n",
        "test_datasets = {}\n",
        "for name, gen in test_generators.items():\n",
        "    generator_obj = SpatialGenerator((64, 64), gen, methods=['kriging'])\n",
        "    test_dataset = SpatialDataset(1000, generator_obj, drilling_sampling, lambda x: x,\n",
        "                                  dynamic_secondary_mask=True, x_channels=0,\n",
        "                                  secondary_channels=0, primary_channels=0)\n",
        "    test_datasets[name] = test_dataset\n",
        "\n",
        "test_dataloaders = {name: DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                     num_workers=0, pin_memory=True) for name, dataset in test_datasets.items()}\n",
        "\n",
        "# Prepare to collect images for plotting\n",
        "collected_images = []\n",
        "use_sparse=True\n",
        "use_input_mask=True\n",
        "\n",
        "for data_range in data_ranges:\n",
        "    print(f\"\\nStarting training with data size: {data_range}\")\n",
        "\n",
        "    # Create training dataset using the same range as interpolation test (3-50)\n",
        "    generator = SpatialGenerator((64, 64), interpolation_generator, methods=['kriging'])\n",
        "    train_dataset = SpatialDataset(data_range, generator, drilling_sampling, lambda x: x,\n",
        "                                   dynamic_secondary_mask=True, x_channels=0,\n",
        "                                   secondary_channels=0, primary_channels=0)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
        "                                  num_workers=0, pin_memory=True)\n",
        "\n",
        "    # Initialize the models\n",
        "    convnext = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]).to(device)\n",
        "    sparse_encoder = SparseEncoder(convnext, input_size=(64, 64)).to(device)\n",
        "    subsurface_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "\n",
        "    # Progressive training loop\n",
        "    current_epoch = 0\n",
        "\n",
        "    for target_epoch in epochs:\n",
        "        epochs_to_train = target_epoch - current_epoch\n",
        "        if epochs_to_train <= 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"Training from epoch {current_epoch + 1} to {target_epoch}\")\n",
        "\n",
        "        # Start timing the training\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        # Train the model\n",
        "        sparse_encoder, _, subsurface_decoder, training_losses = train_model(\n",
        "            sparse_encoder, None, subsurface_decoder, train_dataloader,\n",
        "            use_sparse=use_sparse,\n",
        "            model_save_path=f\"model_data{data_range}_epochs{target_epoch}.pth\",\n",
        "            num_epochs=epochs_to_train,\n",
        "            use_secondary=False,\n",
        "            use_input_mask=use_input_mask,\n",
        "            device=device,\n",
        "            save_model=False,\n",
        "            visualize=False\n",
        "        )\n",
        "\n",
        "        # End timing the training\n",
        "        training_end_time = time.time()\n",
        "        training_time = training_end_time - training_start_time  # Calculate training time\n",
        "\n",
        "        # Collect final training loss\n",
        "        final_training_loss = training_losses[-1]['primary_loss']\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        test_metrics = {}\n",
        "        evaluation_times = {}\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        for name, dataloader in test_dataloaders.items():\n",
        "            # Start timing the evaluation\n",
        "            evaluation_start_time = time.time()\n",
        "\n",
        "            loss, variance, total_variance = evaluate_model(\n",
        "                sparse_encoder, subsurface_decoder,\n",
        "                dataloader, device=device,\n",
        "                use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "\n",
        "            # End timing the evaluation\n",
        "            evaluation_end_time = time.time()\n",
        "            evaluation_time = evaluation_end_time - evaluation_start_time  # Calculate evaluation time\n",
        "\n",
        "            test_metrics[name] = {\n",
        "                'loss': loss,\n",
        "                'batch_variance': variance,\n",
        "                'total_variance': total_variance\n",
        "            }\n",
        "            evaluation_times[name] = evaluation_time  # Store evaluation time\n",
        "\n",
        "        # Append the results\n",
        "        results.append({\n",
        "            'data_size': data_range,\n",
        "            'epochs': target_epoch,\n",
        "            'training_loss': final_training_loss,\n",
        "            'training_time': training_time,  # Add training time\n",
        "            'evaluation_time_interpolation': evaluation_times['interpolation'],  # Add evaluation times\n",
        "            'evaluation_time_extrapolation_close': evaluation_times['extrapolation_close'],\n",
        "            'evaluation_time_extrapolation_far': evaluation_times['extrapolation_far'],\n",
        "            'test_loss_interpolation': test_metrics['interpolation']['loss'],\n",
        "            'test_variance_interpolation': test_metrics['interpolation']['total_variance'],\n",
        "            'test_loss_extrapolation_close': test_metrics['extrapolation_close']['loss'],\n",
        "            'test_variance_extrapolation_close': test_metrics['extrapolation_close']['total_variance'],\n",
        "            'test_loss_extrapolation_far': test_metrics['extrapolation_far']['loss'],\n",
        "            'test_variance_extrapolation_far': test_metrics['extrapolation_far']['total_variance'],\n",
        "            'training_points_range': '3-50'\n",
        "        })\n",
        "\n",
        "        current_epoch = target_epoch\n",
        "\n",
        "        # Process and collect images for training data\n",
        "        train_iter = iter(train_dataloader)\n",
        "        train_batch = next(train_iter)\n",
        "        train_input, train_output, train_mask = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, train_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "        )\n",
        "        collected_images.append({\n",
        "            'title': f'Train Size: {data_range}, Epochs: {target_epoch}',\n",
        "            'input_grid': train_input,\n",
        "            'output_grid': train_output,\n",
        "            'input_mask': train_mask\n",
        "        })\n",
        "\n",
        "        # Process and collect images for test datasets\n",
        "        for name, dataset in test_datasets.items():\n",
        "            test_dataloader = DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                         num_workers=0, pin_memory=True)\n",
        "            test_iter = iter(test_dataloader)\n",
        "            test_batch = next(test_iter)\n",
        "            test_input, test_output, test_mask = process_batch(\n",
        "                sparse_encoder, subsurface_decoder, test_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "            collected_images.append({\n",
        "                'title': f'Test: {name}, Epochs: {target_epoch}',\n",
        "                'input_grid': test_input,\n",
        "                'output_grid': test_output,\n",
        "                'input_mask': test_mask\n",
        "            })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n",
        "\n",
        "# Create visualization plots\n",
        "plt.style.use('seaborn')\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
        "\n",
        "# 1. Test Losses vs Data Size for Different Epochs\n",
        "ax1 = axes[0, 0]\n",
        "test_types = {\n",
        "    'test_loss_interpolation': 'Interpolation (3-50)',\n",
        "    'test_loss_extrapolation_close': 'Close Extrapolation (51-70)',\n",
        "    'test_loss_extrapolation_far': 'Far Extrapolation (70-90)'\n",
        "}\n",
        "\n",
        "for test_type, label in test_types.items():\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax1.plot(epoch_data['data_size'], epoch_data[test_type],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax1.set_xlabel('Training Data Size')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.set_title('Test Losses vs Training Data Size\\n(Training Range: 3-50 points)')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True)\n",
        "\n",
        "# 2. Test Losses vs Epochs for Different Data Sizes\n",
        "ax2 = axes[0, 1]\n",
        "for test_type, label in test_types.items():\n",
        "    for data_size in data_ranges:\n",
        "        size_data = df_results[df_results['data_size'] == data_size]\n",
        "        ax2.plot(size_data['epochs'], size_data[test_type],\n",
        "                 label=f'{label} (Size {data_size})', marker='o', alpha=0.7)\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Test Loss')\n",
        "ax2.set_title('Test Losses vs Epochs\\n(Training Range: 3-50 points)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True)\n",
        "\n",
        "# 3. Heatmaps for each test type including Training Loss\n",
        "fig_heatmaps, axes_heatmaps = plt.subplots(1, 4, figsize=(25, 6))\n",
        "test_types_with_training = {\n",
        "    'training_loss': 'Training Loss',\n",
        "    **test_types\n",
        "}\n",
        "for idx, (test_type, label) in enumerate(test_types_with_training.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=test_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_heatmaps[idx])\n",
        "    axes_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_heatmaps.tight_layout()\n",
        "# Removed plt.show() here\n",
        "\n",
        "# 4. Comparison of test types\n",
        "ax4 = axes[1, 1]\n",
        "box_data = [df_results[test_type] for test_type in test_types.keys()]\n",
        "ax4.boxplot(box_data, labels=[label.replace('\\n', ' ') for label in test_types.values()])\n",
        "ax4.set_ylabel('Test Loss')\n",
        "ax4.set_title('Distribution of Test Losses by Type\\n(Training Range: 3-50 points)')\n",
        "ax4.grid(True)\n",
        "\n",
        "# 5. Loss Ratio Analysis\n",
        "ax3 = axes[1, 0]\n",
        "df_results['close_extrapolation_ratio'] = df_results['test_loss_extrapolation_close'] / df_results['test_loss_interpolation']\n",
        "df_results['far_extrapolation_ratio'] = df_results['test_loss_extrapolation_far'] / df_results['test_loss_interpolation']\n",
        "\n",
        "for ratio, label in [('close_extrapolation_ratio', 'Close Extrapolation / Interpolation'),\n",
        "                     ('far_extrapolation_ratio', 'Far Extrapolation / Interpolation')]:\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax3.plot(epoch_data['data_size'], epoch_data[ratio],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax3.axhline(y=1, color='r', linestyle='--', label='Baseline (Equal Performance)')\n",
        "ax3.set_xlabel('Training Data Size')\n",
        "ax3.set_ylabel('Loss Ratio')\n",
        "ax3.set_title('Extrapolation Performance Relative to Interpolation\\n(Training Range: 3-50 points)')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(True)\n",
        "\n",
        "# Heatmaps for variances of each test type\n",
        "fig_variance_heatmaps, axes_variance_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "variance_test_types = {\n",
        "    'test_variance_interpolation': 'Interpolation Variance',\n",
        "    'test_variance_extrapolation_close': 'Close Extrapolation Variance',\n",
        "    'test_variance_extrapolation_far': 'Far Extrapolation Variance'\n",
        "}\n",
        "for idx, (variance_type, label) in enumerate(variance_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=variance_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_variance_heatmaps[idx])\n",
        "    axes_variance_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_variance_heatmaps.tight_layout()\n",
        "\n",
        "# 7. Training Loss Heatmap (This remains unchanged)\n",
        "ax7 = axes[2, 1]\n",
        "training_loss_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_loss')\n",
        "sns.heatmap(training_loss_pivot, annot=True, fmt=\".6f\", cmap='viridis', ax=ax7)\n",
        "ax7.set_title('Training Loss Heatmap')\n",
        "\n",
        "# 8. Training Time Heatmap\n",
        "ax8 = axes[2, 0]\n",
        "training_time_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_time')\n",
        "sns.heatmap(training_time_pivot, annot=True, fmt=\".2f\", cmap='Blues', ax=ax8)\n",
        "ax8.set_title('Training Time Heatmap')\n",
        "ax8.set_xlabel('Epochs')\n",
        "ax8.set_ylabel('Training Data Size')\n",
        "\n",
        "# 9. Evaluation Time Heatmaps for each test set\n",
        "fig_eval_time_heatmaps, axes_eval_time_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "evaluation_time_test_types = {\n",
        "    'evaluation_time_interpolation': 'Interpolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_close': 'Close Extrapolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_far': 'Far Extrapolation Evaluation Time'\n",
        "}\n",
        "for idx, (eval_time_type, label) in enumerate(evaluation_time_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=eval_time_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap='Greens', ax=axes_eval_time_heatmaps[idx])\n",
        "    axes_eval_time_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_eval_time_heatmaps[idx].set_xlabel('Epochs')\n",
        "    axes_eval_time_heatmaps[idx].set_ylabel('Training Data Size')\n",
        "fig_eval_time_heatmaps.tight_layout()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Call the function to plot collected images\n",
        "plot_collected_images(collected_images, images_per_row=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r5lOH4QPO0g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Define data ranges and max epochs\n",
        "data_ranges = [100,200,400,800,1600,3200,6400,12800]\n",
        "epochs = [1,2,4,8,16,32,64,128]\n",
        "\n",
        "# Initialize results list\n",
        "results = []\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define test datasets and dataloaders for different scenarios\n",
        "# All test sets will use the same size (1000 samples) but different point ranges\n",
        "interpolation_generator = lambda: torch.rand(torch.randint(3, 50, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_close_generator = lambda: torch.rand(torch.randint(51, 70, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_far_generator = lambda: torch.rand(torch.randint(70, 90, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "\n",
        "# Create test datasets\n",
        "test_generators = {\n",
        "    'interpolation': interpolation_generator,\n",
        "    'extrapolation_close': extrapolation_close_generator,\n",
        "    'extrapolation_far': extrapolation_far_generator\n",
        "}\n",
        "\n",
        "test_datasets = {}\n",
        "for name, gen in test_generators.items():\n",
        "    generator_obj = SpatialGenerator((64, 64), gen, methods=['kriging'])\n",
        "    test_dataset = SpatialDataset(1000, generator_obj, drilling_sampling, lambda x: x,\n",
        "                                  dynamic_secondary_mask=True, x_channels=0,\n",
        "                                  secondary_channels=0, primary_channels=0)\n",
        "    test_datasets[name] = test_dataset\n",
        "\n",
        "test_dataloaders = {name: DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                     num_workers=0, pin_memory=True) for name, dataset in test_datasets.items()}\n",
        "\n",
        "# Prepare to collect images for plotting\n",
        "collected_images = []\n",
        "use_sparse=True\n",
        "use_input_mask=True\n",
        "\n",
        "for data_range in data_ranges:\n",
        "    print(f\"\\nStarting training with data size: {data_range}\")\n",
        "\n",
        "    # Create training dataset using the same range as interpolation test (3-50)\n",
        "    generator = SpatialGenerator((64, 64), interpolation_generator, methods=['kriging'])\n",
        "    train_dataset = SpatialDataset(data_range, generator, drilling_sampling, lambda x: x,\n",
        "                                   dynamic_secondary_mask=True, x_channels=0,\n",
        "                                   secondary_channels=0, primary_channels=0)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
        "                                  num_workers=0, pin_memory=True)\n",
        "\n",
        "    # Initialize the models\n",
        "    convnext = ConvNeXt(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768]).to(device)\n",
        "    sparse_encoder = SparseEncoder(convnext, input_size=(64, 64)).to(device)\n",
        "    subsurface_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "\n",
        "    # Progressive training loop\n",
        "    current_epoch = 0\n",
        "\n",
        "    for target_epoch in epochs:\n",
        "        epochs_to_train = target_epoch - current_epoch\n",
        "        if epochs_to_train <= 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"Training from epoch {current_epoch + 1} to {target_epoch}\")\n",
        "\n",
        "        # Start timing the training\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        # Train the model\n",
        "        sparse_encoder, _, subsurface_decoder, training_losses = train_model(\n",
        "            sparse_encoder, None, subsurface_decoder, train_dataloader,\n",
        "            use_sparse=use_sparse,\n",
        "            model_save_path=f\"model_data{data_range}_epochs{target_epoch}.pth\",\n",
        "            num_epochs=epochs_to_train,\n",
        "            use_secondary=False,\n",
        "            use_input_mask=use_input_mask,\n",
        "            device=device,\n",
        "            save_model=False,\n",
        "            visualize=False\n",
        "        )\n",
        "\n",
        "        # End timing the training\n",
        "        training_end_time = time.time()\n",
        "        training_time = training_end_time - training_start_time  # Calculate training time\n",
        "\n",
        "        # Collect final training loss\n",
        "        final_training_loss = training_losses[-1]['primary_loss']\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        test_metrics = {}\n",
        "        evaluation_times = {}\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        for name, dataloader in test_dataloaders.items():\n",
        "            # Start timing the evaluation\n",
        "            evaluation_start_time = time.time()\n",
        "\n",
        "            loss, variance, total_variance = evaluate_model(\n",
        "                sparse_encoder, subsurface_decoder,\n",
        "                dataloader, device=device,\n",
        "                use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "\n",
        "            # End timing the evaluation\n",
        "            evaluation_end_time = time.time()\n",
        "            evaluation_time = evaluation_end_time - evaluation_start_time  # Calculate evaluation time\n",
        "\n",
        "            test_metrics[name] = {\n",
        "                'loss': loss,\n",
        "                'batch_variance': variance,\n",
        "                'total_variance': total_variance\n",
        "            }\n",
        "            evaluation_times[name] = evaluation_time  # Store evaluation time\n",
        "\n",
        "        # Append the results\n",
        "        results.append({\n",
        "            'data_size': data_range,\n",
        "            'epochs': target_epoch,\n",
        "            'training_loss': final_training_loss,\n",
        "            'training_time': training_time,  # Add training time\n",
        "            'evaluation_time_interpolation': evaluation_times['interpolation'],  # Add evaluation times\n",
        "            'evaluation_time_extrapolation_close': evaluation_times['extrapolation_close'],\n",
        "            'evaluation_time_extrapolation_far': evaluation_times['extrapolation_far'],\n",
        "            'test_loss_interpolation': test_metrics['interpolation']['loss'],\n",
        "            'test_variance_interpolation': test_metrics['interpolation']['total_variance'],\n",
        "            'test_loss_extrapolation_close': test_metrics['extrapolation_close']['loss'],\n",
        "            'test_variance_extrapolation_close': test_metrics['extrapolation_close']['total_variance'],\n",
        "            'test_loss_extrapolation_far': test_metrics['extrapolation_far']['loss'],\n",
        "            'test_variance_extrapolation_far': test_metrics['extrapolation_far']['total_variance'],\n",
        "            'training_points_range': '3-50'\n",
        "        })\n",
        "\n",
        "        current_epoch = target_epoch\n",
        "\n",
        "        # Process and collect images for training data\n",
        "        train_iter = iter(train_dataloader)\n",
        "        train_batch = next(train_iter)\n",
        "        train_input, train_output, train_mask = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, train_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "        )\n",
        "        collected_images.append({\n",
        "            'title': f'Train Size: {data_range}, Epochs: {target_epoch}',\n",
        "            'input_grid': train_input,\n",
        "            'output_grid': train_output,\n",
        "            'input_mask': train_mask\n",
        "        })\n",
        "\n",
        "        # Process and collect images for test datasets\n",
        "        for name, dataset in test_datasets.items():\n",
        "            test_dataloader = DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                         num_workers=0, pin_memory=True)\n",
        "            test_iter = iter(test_dataloader)\n",
        "            test_batch = next(test_iter)\n",
        "            test_input, test_output, test_mask = process_batch(\n",
        "                sparse_encoder, subsurface_decoder, test_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "            collected_images.append({\n",
        "                'title': f'Test: {name}, Epochs: {target_epoch}',\n",
        "                'input_grid': test_input,\n",
        "                'output_grid': test_output,\n",
        "                'input_mask': test_mask\n",
        "            })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n",
        "\n",
        "# Create visualization plots\n",
        "plt.style.use('seaborn')\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
        "\n",
        "# 1. Test Losses vs Data Size for Different Epochs\n",
        "ax1 = axes[0, 0]\n",
        "test_types = {\n",
        "    'test_loss_interpolation': 'Interpolation (3-50)',\n",
        "    'test_loss_extrapolation_close': 'Close Extrapolation (51-70)',\n",
        "    'test_loss_extrapolation_far': 'Far Extrapolation (70-90)'\n",
        "}\n",
        "\n",
        "for test_type, label in test_types.items():\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax1.plot(epoch_data['data_size'], epoch_data[test_type],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax1.set_xlabel('Training Data Size')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.set_title('Test Losses vs Training Data Size\\n(Training Range: 3-50 points)')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True)\n",
        "\n",
        "# 2. Test Losses vs Epochs for Different Data Sizes\n",
        "ax2 = axes[0, 1]\n",
        "for test_type, label in test_types.items():\n",
        "    for data_size in data_ranges:\n",
        "        size_data = df_results[df_results['data_size'] == data_size]\n",
        "        ax2.plot(size_data['epochs'], size_data[test_type],\n",
        "                 label=f'{label} (Size {data_size})', marker='o', alpha=0.7)\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Test Loss')\n",
        "ax2.set_title('Test Losses vs Epochs\\n(Training Range: 3-50 points)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True)\n",
        "\n",
        "# 3. Heatmaps for each test type including Training Loss\n",
        "fig_heatmaps, axes_heatmaps = plt.subplots(1, 4, figsize=(25, 6))\n",
        "test_types_with_training = {\n",
        "    'training_loss': 'Training Loss',\n",
        "    **test_types\n",
        "}\n",
        "for idx, (test_type, label) in enumerate(test_types_with_training.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=test_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_heatmaps[idx])\n",
        "    axes_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_heatmaps.tight_layout()\n",
        "# Removed plt.show() here\n",
        "\n",
        "# 4. Comparison of test types\n",
        "ax4 = axes[1, 1]\n",
        "box_data = [df_results[test_type] for test_type in test_types.keys()]\n",
        "ax4.boxplot(box_data, labels=[label.replace('\\n', ' ') for label in test_types.values()])\n",
        "ax4.set_ylabel('Test Loss')\n",
        "ax4.set_title('Distribution of Test Losses by Type\\n(Training Range: 3-50 points)')\n",
        "ax4.grid(True)\n",
        "\n",
        "# 5. Loss Ratio Analysis\n",
        "ax3 = axes[1, 0]\n",
        "df_results['close_extrapolation_ratio'] = df_results['test_loss_extrapolation_close'] / df_results['test_loss_interpolation']\n",
        "df_results['far_extrapolation_ratio'] = df_results['test_loss_extrapolation_far'] / df_results['test_loss_interpolation']\n",
        "\n",
        "for ratio, label in [('close_extrapolation_ratio', 'Close Extrapolation / Interpolation'),\n",
        "                     ('far_extrapolation_ratio', 'Far Extrapolation / Interpolation')]:\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax3.plot(epoch_data['data_size'], epoch_data[ratio],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax3.axhline(y=1, color='r', linestyle='--', label='Baseline (Equal Performance)')\n",
        "ax3.set_xlabel('Training Data Size')\n",
        "ax3.set_ylabel('Loss Ratio')\n",
        "ax3.set_title('Extrapolation Performance Relative to Interpolation\\n(Training Range: 3-50 points)')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(True)\n",
        "\n",
        "# Heatmaps for variances of each test type\n",
        "fig_variance_heatmaps, axes_variance_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "variance_test_types = {\n",
        "    'test_variance_interpolation': 'Interpolation Variance',\n",
        "    'test_variance_extrapolation_close': 'Close Extrapolation Variance',\n",
        "    'test_variance_extrapolation_far': 'Far Extrapolation Variance'\n",
        "}\n",
        "for idx, (variance_type, label) in enumerate(variance_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=variance_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_variance_heatmaps[idx])\n",
        "    axes_variance_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_variance_heatmaps.tight_layout()\n",
        "\n",
        "# 7. Training Loss Heatmap (This remains unchanged)\n",
        "ax7 = axes[2, 1]\n",
        "training_loss_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_loss')\n",
        "sns.heatmap(training_loss_pivot, annot=True, fmt=\".6f\", cmap='viridis', ax=ax7)\n",
        "ax7.set_title('Training Loss Heatmap')\n",
        "\n",
        "# 8. Training Time Heatmap\n",
        "ax8 = axes[2, 0]\n",
        "training_time_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_time')\n",
        "sns.heatmap(training_time_pivot, annot=True, fmt=\".2f\", cmap='Blues', ax=ax8)\n",
        "ax8.set_title('Training Time Heatmap')\n",
        "ax8.set_xlabel('Epochs')\n",
        "ax8.set_ylabel('Training Data Size')\n",
        "\n",
        "# 9. Evaluation Time Heatmaps for each test set\n",
        "fig_eval_time_heatmaps, axes_eval_time_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "evaluation_time_test_types = {\n",
        "    'evaluation_time_interpolation': 'Interpolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_close': 'Close Extrapolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_far': 'Far Extrapolation Evaluation Time'\n",
        "}\n",
        "for idx, (eval_time_type, label) in enumerate(evaluation_time_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=eval_time_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap='Greens', ax=axes_eval_time_heatmaps[idx])\n",
        "    axes_eval_time_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_eval_time_heatmaps[idx].set_xlabel('Epochs')\n",
        "    axes_eval_time_heatmaps[idx].set_ylabel('Training Data Size')\n",
        "fig_eval_time_heatmaps.tight_layout()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Call the function to plot collected images\n",
        "plot_collected_images(collected_images, images_per_row=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93jStMkQweb2"
      },
      "source": [
        "# Fine Tunning Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuMxIY_IcRjn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Define data ranges and max epochs\n",
        "data_ranges = [100,200,400,800,1600,3200,6400,12800]\n",
        "epochs = [1,2,4,8,16,32,64,128]\n",
        "\n",
        "# Initialize results list\n",
        "results = []\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define test datasets and dataloaders for different scenarios\n",
        "# All test sets will use the same size (1000 samples) but different point ranges\n",
        "interpolation_generator = lambda: torch.rand(torch.randint(3, 50, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_close_generator = lambda: torch.rand(torch.randint(51, 70, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_far_generator = lambda: torch.rand(torch.randint(70, 90, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "\n",
        "# Create test datasets\n",
        "test_generators = {\n",
        "    'interpolation': interpolation_generator,\n",
        "    'extrapolation_close': extrapolation_close_generator,\n",
        "    'extrapolation_far': extrapolation_far_generator\n",
        "}\n",
        "\n",
        "test_datasets = {}\n",
        "for name, gen in test_generators.items():\n",
        "    generator_obj = SpatialGenerator((64, 64), gen, methods=['kriging'])\n",
        "    test_dataset = SpatialDataset(1000, generator_obj, drilling_sampling, lambda x: x,\n",
        "                                  dynamic_secondary_mask=True, x_channels=0,\n",
        "                                  secondary_channels=0, primary_channels=0)\n",
        "    test_datasets[name] = test_dataset\n",
        "\n",
        "test_dataloaders = {name: DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                     num_workers=0, pin_memory=True) for name, dataset in test_datasets.items()}\n",
        "\n",
        "# Prepare to collect images for plotting\n",
        "collected_images = []\n",
        "use_sparse=True\n",
        "use_input_mask=True\n",
        "\n",
        "for data_range in data_ranges:\n",
        "    print(f\"\\nStarting training with data size: {data_range}\")\n",
        "\n",
        "    # Create training dataset using the same range as interpolation test (3-50)\n",
        "    generator = SpatialGenerator((64, 64), interpolation_generator, methods=['kriging'])\n",
        "    train_dataset = SpatialDataset(data_range, generator, drilling_sampling, lambda x: x,\n",
        "                                   dynamic_secondary_mask=True, x_channels=0,\n",
        "                                   secondary_channels=0, primary_channels=0)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
        "                                  num_workers=0, pin_memory=True)\n",
        "\n",
        "    # Initialize the models\n",
        "    convnext = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]).to(device)\n",
        "    sparse_encoder = SparseEncoder(convnext, input_size=(64, 64)).to(device)\n",
        "    subsurface_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "    last_model_path = \"drive/MyDrive/Models/base_id_1000k.pth\"\n",
        "\n",
        "    # Load the model state\n",
        "    sparse_encoder, _ , subsurface_decoder, use_secondary, use_sparse, training_losses = load_model(\n",
        "        last_model_path,\n",
        "        sparse_encoder,\n",
        "        None,\n",
        "        subsurface_decoder,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Progressive training loop\n",
        "    current_epoch = 0\n",
        "\n",
        "    for target_epoch in epochs:\n",
        "        epochs_to_train = target_epoch - current_epoch\n",
        "        if epochs_to_train <= 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"Training from epoch {current_epoch + 1} to {target_epoch}\")\n",
        "\n",
        "        # Start timing the training\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        # Train the model\n",
        "        sparse_encoder, _, subsurface_decoder, training_losses = train_model(\n",
        "            sparse_encoder, None, subsurface_decoder, train_dataloader,\n",
        "            use_sparse=use_sparse,\n",
        "            model_save_path=f\"model_data{data_range}_epochs{target_epoch}.pth\",\n",
        "            num_epochs=epochs_to_train,\n",
        "            use_secondary=False,\n",
        "            use_input_mask=use_input_mask,\n",
        "            device=device,\n",
        "            save_model=False,\n",
        "            visualize=False\n",
        "        )\n",
        "\n",
        "        # End timing the training\n",
        "        training_end_time = time.time()\n",
        "        training_time = training_end_time - training_start_time  # Calculate training time\n",
        "\n",
        "        # Collect final training loss\n",
        "        final_training_loss = training_losses[-1]['primary_loss']\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        test_metrics = {}\n",
        "        evaluation_times = {}\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        for name, dataloader in test_dataloaders.items():\n",
        "            # Start timing the evaluation\n",
        "            evaluation_start_time = time.time()\n",
        "\n",
        "            loss, variance, total_variance = evaluate_model(\n",
        "                sparse_encoder, subsurface_decoder,\n",
        "                dataloader, device=device,\n",
        "                use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "\n",
        "            # End timing the evaluation\n",
        "            evaluation_end_time = time.time()\n",
        "            evaluation_time = evaluation_end_time - evaluation_start_time  # Calculate evaluation time\n",
        "\n",
        "            test_metrics[name] = {\n",
        "                'loss': loss,\n",
        "                'batch_variance': variance,\n",
        "                'total_variance': total_variance\n",
        "            }\n",
        "            evaluation_times[name] = evaluation_time  # Store evaluation time\n",
        "\n",
        "        # Append the results\n",
        "        results.append({\n",
        "            'data_size': data_range,\n",
        "            'epochs': target_epoch,\n",
        "            'training_loss': final_training_loss,\n",
        "            'training_time': training_time,  # Add training time\n",
        "            'evaluation_time_interpolation': evaluation_times['interpolation'],  # Add evaluation times\n",
        "            'evaluation_time_extrapolation_close': evaluation_times['extrapolation_close'],\n",
        "            'evaluation_time_extrapolation_far': evaluation_times['extrapolation_far'],\n",
        "            'test_loss_interpolation': test_metrics['interpolation']['loss'],\n",
        "            'test_variance_interpolation': test_metrics['interpolation']['total_variance'],\n",
        "            'test_loss_extrapolation_close': test_metrics['extrapolation_close']['loss'],\n",
        "            'test_variance_extrapolation_close': test_metrics['extrapolation_close']['total_variance'],\n",
        "            'test_loss_extrapolation_far': test_metrics['extrapolation_far']['loss'],\n",
        "            'test_variance_extrapolation_far': test_metrics['extrapolation_far']['total_variance'],\n",
        "            'training_points_range': '3-50'\n",
        "        })\n",
        "\n",
        "        current_epoch = target_epoch\n",
        "\n",
        "        # Process and collect images for training data\n",
        "        train_iter = iter(train_dataloader)\n",
        "        train_batch = next(train_iter)\n",
        "        train_input, train_output, train_mask = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, train_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "        )\n",
        "        collected_images.append({\n",
        "            'title': f'Train Size: {data_range}, Epochs: {target_epoch}',\n",
        "            'input_grid': train_input,\n",
        "            'output_grid': train_output,\n",
        "            'input_mask': train_mask\n",
        "        })\n",
        "\n",
        "        # Process and collect images for test datasets\n",
        "        for name, dataset in test_datasets.items():\n",
        "            test_dataloader = DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                         num_workers=0, pin_memory=True)\n",
        "            test_iter = iter(test_dataloader)\n",
        "            test_batch = next(test_iter)\n",
        "            test_input, test_output, test_mask = process_batch(\n",
        "                sparse_encoder, subsurface_decoder, test_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "            collected_images.append({\n",
        "                'title': f'Test: {name}, Epochs: {target_epoch}',\n",
        "                'input_grid': test_input,\n",
        "                'output_grid': test_output,\n",
        "                'input_mask': test_mask\n",
        "            })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n",
        "\n",
        "# Create visualization plots\n",
        "plt.style.use('seaborn')\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
        "\n",
        "# 1. Test Losses vs Data Size for Different Epochs\n",
        "ax1 = axes[0, 0]\n",
        "test_types = {\n",
        "    'test_loss_interpolation': 'Interpolation (3-50)',\n",
        "    'test_loss_extrapolation_close': 'Close Extrapolation (51-70)',\n",
        "    'test_loss_extrapolation_far': 'Far Extrapolation (70-90)'\n",
        "}\n",
        "\n",
        "for test_type, label in test_types.items():\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax1.plot(epoch_data['data_size'], epoch_data[test_type],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax1.set_xlabel('Training Data Size')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.set_title('Test Losses vs Training Data Size\\n(Training Range: 3-50 points)')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True)\n",
        "\n",
        "# 2. Test Losses vs Epochs for Different Data Sizes\n",
        "ax2 = axes[0, 1]\n",
        "for test_type, label in test_types.items():\n",
        "    for data_size in data_ranges:\n",
        "        size_data = df_results[df_results['data_size'] == data_size]\n",
        "        ax2.plot(size_data['epochs'], size_data[test_type],\n",
        "                 label=f'{label} (Size {data_size})', marker='o', alpha=0.7)\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Test Loss')\n",
        "ax2.set_title('Test Losses vs Epochs\\n(Training Range: 3-50 points)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True)\n",
        "\n",
        "# 3. Heatmaps for each test type including Training Loss\n",
        "fig_heatmaps, axes_heatmaps = plt.subplots(1, 4, figsize=(25, 6))\n",
        "test_types_with_training = {\n",
        "    'training_loss': 'Training Loss',\n",
        "    **test_types\n",
        "}\n",
        "for idx, (test_type, label) in enumerate(test_types_with_training.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=test_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_heatmaps[idx])\n",
        "    axes_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_heatmaps.tight_layout()\n",
        "# Removed plt.show() here\n",
        "\n",
        "# 4. Comparison of test types\n",
        "ax4 = axes[1, 1]\n",
        "box_data = [df_results[test_type] for test_type in test_types.keys()]\n",
        "ax4.boxplot(box_data, labels=[label.replace('\\n', ' ') for label in test_types.values()])\n",
        "ax4.set_ylabel('Test Loss')\n",
        "ax4.set_title('Distribution of Test Losses by Type\\n(Training Range: 3-50 points)')\n",
        "ax4.grid(True)\n",
        "\n",
        "# 5. Loss Ratio Analysis\n",
        "ax3 = axes[1, 0]\n",
        "df_results['close_extrapolation_ratio'] = df_results['test_loss_extrapolation_close'] / df_results['test_loss_interpolation']\n",
        "df_results['far_extrapolation_ratio'] = df_results['test_loss_extrapolation_far'] / df_results['test_loss_interpolation']\n",
        "\n",
        "for ratio, label in [('close_extrapolation_ratio', 'Close Extrapolation / Interpolation'),\n",
        "                     ('far_extrapolation_ratio', 'Far Extrapolation / Interpolation')]:\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax3.plot(epoch_data['data_size'], epoch_data[ratio],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax3.axhline(y=1, color='r', linestyle='--', label='Baseline (Equal Performance)')\n",
        "ax3.set_xlabel('Training Data Size')\n",
        "ax3.set_ylabel('Loss Ratio')\n",
        "ax3.set_title('Extrapolation Performance Relative to Interpolation\\n(Training Range: 3-50 points)')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(True)\n",
        "\n",
        "# Heatmaps for variances of each test type\n",
        "fig_variance_heatmaps, axes_variance_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "variance_test_types = {\n",
        "    'test_variance_interpolation': 'Interpolation Variance',\n",
        "    'test_variance_extrapolation_close': 'Close Extrapolation Variance',\n",
        "    'test_variance_extrapolation_far': 'Far Extrapolation Variance'\n",
        "}\n",
        "for idx, (variance_type, label) in enumerate(variance_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=variance_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_variance_heatmaps[idx])\n",
        "    axes_variance_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_variance_heatmaps.tight_layout()\n",
        "\n",
        "# 7. Training Loss Heatmap (This remains unchanged)\n",
        "ax7 = axes[2, 1]\n",
        "training_loss_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_loss')\n",
        "sns.heatmap(training_loss_pivot, annot=True, fmt=\".6f\", cmap='viridis', ax=ax7)\n",
        "ax7.set_title('Training Loss Heatmap')\n",
        "\n",
        "# 8. Training Time Heatmap\n",
        "ax8 = axes[2, 0]\n",
        "training_time_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_time')\n",
        "sns.heatmap(training_time_pivot, annot=True, fmt=\".2f\", cmap='Blues', ax=ax8)\n",
        "ax8.set_title('Training Time Heatmap')\n",
        "ax8.set_xlabel('Epochs')\n",
        "ax8.set_ylabel('Training Data Size')\n",
        "\n",
        "# 9. Evaluation Time Heatmaps for each test set\n",
        "fig_eval_time_heatmaps, axes_eval_time_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "evaluation_time_test_types = {\n",
        "    'evaluation_time_interpolation': 'Interpolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_close': 'Close Extrapolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_far': 'Far Extrapolation Evaluation Time'\n",
        "}\n",
        "for idx, (eval_time_type, label) in enumerate(evaluation_time_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=eval_time_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap='Greens', ax=axes_eval_time_heatmaps[idx])\n",
        "    axes_eval_time_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_eval_time_heatmaps[idx].set_xlabel('Epochs')\n",
        "    axes_eval_time_heatmaps[idx].set_ylabel('Training Data Size')\n",
        "fig_eval_time_heatmaps.tight_layout()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Call the function to plot collected images\n",
        "plot_collected_images(collected_images, images_per_row=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64cqIqec3ZAH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Define data ranges and max epochs\n",
        "data_ranges = [100,200,400,800,1600,3200,6400,12800]\n",
        "epochs = [1,2,4,8,16,32,64,128]\n",
        "\n",
        "# Initialize results list\n",
        "results = []\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define test datasets and dataloaders for different scenarios\n",
        "# All test sets will use the same size (1000 samples) but different point ranges\n",
        "interpolation_generator = lambda: torch.rand(torch.randint(3, 50, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_close_generator = lambda: torch.rand(torch.randint(51, 70, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_far_generator = lambda: torch.rand(torch.randint(70, 90, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "\n",
        "# Create test datasets\n",
        "test_generators = {\n",
        "    'interpolation': interpolation_generator,\n",
        "    'extrapolation_close': extrapolation_close_generator,\n",
        "    'extrapolation_far': extrapolation_far_generator\n",
        "}\n",
        "\n",
        "test_datasets = {}\n",
        "for name, gen in test_generators.items():\n",
        "    generator_obj = SpatialGenerator((64, 64), gen, methods=['id'])\n",
        "    test_dataset = SpatialDataset(1000, generator_obj, drilling_sampling, lambda x: x,\n",
        "                                  dynamic_secondary_mask=True, x_channels=0,\n",
        "                                  secondary_channels=0, primary_channels=0)\n",
        "    test_datasets[name] = test_dataset\n",
        "\n",
        "test_dataloaders = {name: DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                     num_workers=0, pin_memory=True) for name, dataset in test_datasets.items()}\n",
        "\n",
        "# Prepare to collect images for plotting\n",
        "collected_images = []\n",
        "use_sparse=True\n",
        "use_input_mask=True\n",
        "\n",
        "for data_range in data_ranges:\n",
        "    print(f\"\\nStarting training with data size: {data_range}\")\n",
        "\n",
        "    # Create training dataset using the same range as interpolation test (3-50)\n",
        "    generator = SpatialGenerator((64, 64), interpolation_generator, methods=['id'])\n",
        "    train_dataset = SpatialDataset(data_range, generator, drilling_sampling, lambda x: x,\n",
        "                                   dynamic_secondary_mask=True, x_channels=0,\n",
        "                                   secondary_channels=0, primary_channels=0)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
        "                                  num_workers=0, pin_memory=True)\n",
        "\n",
        "    # Initialize the models\n",
        "    convnext = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]).to(device)\n",
        "    sparse_encoder = SparseEncoder(convnext, input_size=(64, 64)).to(device)\n",
        "    subsurface_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "    last_model_path = \"drive/MyDrive/Models/base_id_1000k.pth\"\n",
        "\n",
        "    # Load the model state\n",
        "    sparse_encoder, _ , subsurface_decoder, use_secondary, use_sparse, training_losses = load_model(\n",
        "        last_model_path,\n",
        "        sparse_encoder,\n",
        "        None,\n",
        "        subsurface_decoder,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Progressive training loop\n",
        "    current_epoch = 0\n",
        "\n",
        "    for target_epoch in epochs:\n",
        "        epochs_to_train = target_epoch - current_epoch\n",
        "        if epochs_to_train <= 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"Training from epoch {current_epoch + 1} to {target_epoch}\")\n",
        "\n",
        "        # Start timing the training\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        # Train the model\n",
        "        sparse_encoder, _, subsurface_decoder, training_losses = train_model(\n",
        "            sparse_encoder, None, subsurface_decoder, train_dataloader,\n",
        "            use_sparse=use_sparse,\n",
        "            model_save_path=f\"model_data{data_range}_epochs{target_epoch}.pth\",\n",
        "            num_epochs=epochs_to_train,\n",
        "            use_secondary=False,\n",
        "            use_input_mask=use_input_mask,\n",
        "            device=device,\n",
        "            save_model=False,\n",
        "            visualize=False\n",
        "        )\n",
        "\n",
        "        # End timing the training\n",
        "        training_end_time = time.time()\n",
        "        training_time = training_end_time - training_start_time  # Calculate training time\n",
        "\n",
        "        # Collect final training loss\n",
        "        final_training_loss = training_losses[-1]['primary_loss']\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        test_metrics = {}\n",
        "        evaluation_times = {}\n",
        "\n",
        "        # Evaluate the model on all three test sets\n",
        "        for name, dataloader in test_dataloaders.items():\n",
        "            # Start timing the evaluation\n",
        "            evaluation_start_time = time.time()\n",
        "\n",
        "            loss, variance, total_variance = evaluate_model(\n",
        "                sparse_encoder, subsurface_decoder,\n",
        "                dataloader, device=device,\n",
        "                use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "\n",
        "            # End timing the evaluation\n",
        "            evaluation_end_time = time.time()\n",
        "            evaluation_time = evaluation_end_time - evaluation_start_time  # Calculate evaluation time\n",
        "\n",
        "            test_metrics[name] = {\n",
        "                'loss': loss,\n",
        "                'batch_variance': variance,\n",
        "                'total_variance': total_variance\n",
        "            }\n",
        "            evaluation_times[name] = evaluation_time  # Store evaluation time\n",
        "\n",
        "        # Append the results\n",
        "        results.append({\n",
        "            'data_size': data_range,\n",
        "            'epochs': target_epoch,\n",
        "            'training_loss': final_training_loss,\n",
        "            'training_time': training_time,  # Add training time\n",
        "            'evaluation_time_interpolation': evaluation_times['interpolation'],  # Add evaluation times\n",
        "            'evaluation_time_extrapolation_close': evaluation_times['extrapolation_close'],\n",
        "            'evaluation_time_extrapolation_far': evaluation_times['extrapolation_far'],\n",
        "            'test_loss_interpolation': test_metrics['interpolation']['loss'],\n",
        "            'test_variance_interpolation': test_metrics['interpolation']['total_variance'],\n",
        "            'test_loss_extrapolation_close': test_metrics['extrapolation_close']['loss'],\n",
        "            'test_variance_extrapolation_close': test_metrics['extrapolation_close']['total_variance'],\n",
        "            'test_loss_extrapolation_far': test_metrics['extrapolation_far']['loss'],\n",
        "            'test_variance_extrapolation_far': test_metrics['extrapolation_far']['total_variance'],\n",
        "            'training_points_range': '3-50'\n",
        "        })\n",
        "\n",
        "        current_epoch = target_epoch\n",
        "\n",
        "        # Process and collect images for training data\n",
        "        train_iter = iter(train_dataloader)\n",
        "        train_batch = next(train_iter)\n",
        "        train_input, train_output, train_mask = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, train_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "        )\n",
        "        collected_images.append({\n",
        "            'title': f'Train Size: {data_range}, Epochs: {target_epoch}',\n",
        "            'input_grid': train_input,\n",
        "            'output_grid': train_output,\n",
        "            'input_mask': train_mask\n",
        "        })\n",
        "\n",
        "        # Process and collect images for test datasets\n",
        "        for name, dataset in test_datasets.items():\n",
        "            test_dataloader = DataLoader(dataset, batch_size=128, shuffle=False,\n",
        "                                         num_workers=0, pin_memory=True)\n",
        "            test_iter = iter(test_dataloader)\n",
        "            test_batch = next(test_iter)\n",
        "            test_input, test_output, test_mask = process_batch(\n",
        "                sparse_encoder, subsurface_decoder, test_batch, device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "            collected_images.append({\n",
        "                'title': f'Test: {name}, Epochs: {target_epoch}',\n",
        "                'input_grid': test_input,\n",
        "                'output_grid': test_output,\n",
        "                'input_mask': test_mask\n",
        "            })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n",
        "\n",
        "# Create visualization plots\n",
        "plt.style.use('seaborn')\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
        "\n",
        "# 1. Test Losses vs Data Size for Different Epochs\n",
        "ax1 = axes[0, 0]\n",
        "test_types = {\n",
        "    'test_loss_interpolation': 'Interpolation (3-50)',\n",
        "    'test_loss_extrapolation_close': 'Close Extrapolation (51-70)',\n",
        "    'test_loss_extrapolation_far': 'Far Extrapolation (70-90)'\n",
        "}\n",
        "\n",
        "for test_type, label in test_types.items():\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax1.plot(epoch_data['data_size'], epoch_data[test_type],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax1.set_xlabel('Training Data Size')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.set_title('Test Losses vs Training Data Size\\n(Training Range: 3-50 points)')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True)\n",
        "\n",
        "# 2. Test Losses vs Epochs for Different Data Sizes\n",
        "ax2 = axes[0, 1]\n",
        "for test_type, label in test_types.items():\n",
        "    for data_size in data_ranges:\n",
        "        size_data = df_results[df_results['data_size'] == data_size]\n",
        "        ax2.plot(size_data['epochs'], size_data[test_type],\n",
        "                 label=f'{label} (Size {data_size})', marker='o', alpha=0.7)\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Test Loss')\n",
        "ax2.set_title('Test Losses vs Epochs\\n(Training Range: 3-50 points)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True)\n",
        "\n",
        "# 3. Heatmaps for each test type including Training Loss\n",
        "fig_heatmaps, axes_heatmaps = plt.subplots(1, 4, figsize=(25, 6))\n",
        "test_types_with_training = {\n",
        "    'training_loss': 'Training Loss',\n",
        "    **test_types\n",
        "}\n",
        "for idx, (test_type, label) in enumerate(test_types_with_training.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=test_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_heatmaps[idx])\n",
        "    axes_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_heatmaps.tight_layout()\n",
        "# Removed plt.show() here\n",
        "\n",
        "# 4. Comparison of test types\n",
        "ax4 = axes[1, 1]\n",
        "box_data = [df_results[test_type] for test_type in test_types.keys()]\n",
        "ax4.boxplot(box_data, labels=[label.replace('\\n', ' ') for label in test_types.values()])\n",
        "ax4.set_ylabel('Test Loss')\n",
        "ax4.set_title('Distribution of Test Losses by Type\\n(Training Range: 3-50 points)')\n",
        "ax4.grid(True)\n",
        "\n",
        "# 5. Loss Ratio Analysis\n",
        "ax3 = axes[1, 0]\n",
        "df_results['close_extrapolation_ratio'] = df_results['test_loss_extrapolation_close'] / df_results['test_loss_interpolation']\n",
        "df_results['far_extrapolation_ratio'] = df_results['test_loss_extrapolation_far'] / df_results['test_loss_interpolation']\n",
        "\n",
        "for ratio, label in [('close_extrapolation_ratio', 'Close Extrapolation / Interpolation'),\n",
        "                     ('far_extrapolation_ratio', 'Far Extrapolation / Interpolation')]:\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax3.plot(epoch_data['data_size'], epoch_data[ratio],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax3.axhline(y=1, color='r', linestyle='--', label='Baseline (Equal Performance)')\n",
        "ax3.set_xlabel('Training Data Size')\n",
        "ax3.set_ylabel('Loss Ratio')\n",
        "ax3.set_title('Extrapolation Performance Relative to Interpolation\\n(Training Range: 3-50 points)')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(True)\n",
        "\n",
        "# Heatmaps for variances of each test type\n",
        "fig_variance_heatmaps, axes_variance_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "variance_test_types = {\n",
        "    'test_variance_interpolation': 'Interpolation Variance',\n",
        "    'test_variance_extrapolation_close': 'Close Extrapolation Variance',\n",
        "    'test_variance_extrapolation_far': 'Far Extrapolation Variance'\n",
        "}\n",
        "for idx, (variance_type, label) in enumerate(variance_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=variance_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_variance_heatmaps[idx])\n",
        "    axes_variance_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "fig_variance_heatmaps.tight_layout()\n",
        "\n",
        "# 7. Training Loss Heatmap (This remains unchanged)\n",
        "ax7 = axes[2, 1]\n",
        "training_loss_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_loss')\n",
        "sns.heatmap(training_loss_pivot, annot=True, fmt=\".6f\", cmap='viridis', ax=ax7)\n",
        "ax7.set_title('Training Loss Heatmap')\n",
        "\n",
        "# 8. Training Time Heatmap\n",
        "ax8 = axes[2, 0]\n",
        "training_time_pivot = df_results.pivot(index='data_size', columns='epochs', values='training_time')\n",
        "sns.heatmap(training_time_pivot, annot=True, fmt=\".2f\", cmap='Blues', ax=ax8)\n",
        "ax8.set_title('Training Time Heatmap')\n",
        "ax8.set_xlabel('Epochs')\n",
        "ax8.set_ylabel('Training Data Size')\n",
        "\n",
        "# 9. Evaluation Time Heatmaps for each test set\n",
        "fig_eval_time_heatmaps, axes_eval_time_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "evaluation_time_test_types = {\n",
        "    'evaluation_time_interpolation': 'Interpolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_close': 'Close Extrapolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_far': 'Far Extrapolation Evaluation Time'\n",
        "}\n",
        "for idx, (eval_time_type, label) in enumerate(evaluation_time_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='data_size', columns='epochs', values=eval_time_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap='Greens', ax=axes_eval_time_heatmaps[idx])\n",
        "    axes_eval_time_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_eval_time_heatmaps[idx].set_xlabel('Epochs')\n",
        "    axes_eval_time_heatmaps[idx].set_ylabel('Training Data Size')\n",
        "fig_eval_time_heatmaps.tight_layout()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Call the function to plot collected images\n",
        "plot_collected_images(collected_images, images_per_row=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geyeExzrsmMN"
      },
      "source": [
        "# Layered Data Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPvrij6otY5Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Define sampling percentages and max epochs\n",
        "sampling_percentages = [1, 2, 3, 4, 5, 10, 15]  # Percentages of total points\n",
        "epochs = [1, 2, 5, 10, 20, 100, 150]\n",
        "fixed_dataset_size = 1000\n",
        "size = (32,64)\n",
        "\n",
        "def percentage_random_sampling(size, percentage):\n",
        "    mask = torch.zeros(1, *size)\n",
        "    height, width = size\n",
        "    total_points = height * width\n",
        "    target_points = int((percentage / 100.0) * total_points)\n",
        "\n",
        "    if percentage >= 100:\n",
        "        mask[:] = 1\n",
        "        return mask\n",
        "\n",
        "    if target_points == 0:\n",
        "        return mask\n",
        "\n",
        "    indices = torch.randperm(total_points)[:target_points]\n",
        "    y_indices = indices // width\n",
        "    x_indices = indices % width\n",
        "    mask[0, y_indices, x_indices] = 1\n",
        "\n",
        "    return mask\n",
        "\n",
        "# Initialize results list and device\n",
        "results = []\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create test generators\n",
        "interpolation_generator = lambda: torch.rand(torch.randint(3, 50, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_close_generator = lambda: torch.rand(torch.randint(51, 70, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_far_generator = lambda: torch.rand(torch.randint(70, 90, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "\n",
        "test_generators = {\n",
        "    'interpolation': interpolation_generator,\n",
        "    'extrapolation_close': extrapolation_close_generator,\n",
        "    'extrapolation_far': extrapolation_far_generator\n",
        "}\n",
        "\n",
        "# Create consistent validation datasets for each sampling percentage\n",
        "print(\"Creating consistent validation datasets...\")\n",
        "consistent_test_datasets = {}\n",
        "validation_states = {}\n",
        "\n",
        "for sampling_percentage in sampling_percentages:\n",
        "    consistent_test_datasets[sampling_percentage] = {}\n",
        "    validation_states[sampling_percentage] = {}\n",
        "\n",
        "    for name, gen in test_generators.items():\n",
        "        # Set seeds for reproducibility\n",
        "        torch.manual_seed(42 + sampling_percentage)\n",
        "        np.random.seed(42 + sampling_percentage)\n",
        "        random.seed(42 + sampling_percentage)\n",
        "\n",
        "        generator_obj = CategoricalSpatialGenerator(size, lambda: two_layer_generator(),\n",
        "                                                  num_categories=10, methods=['layered', 'vid'])\n",
        "\n",
        "        test_dataset = SpatialDataset(1000, generator_obj,\n",
        "                                    lambda size: percentage_random_sampling(size, sampling_percentage),\n",
        "                                    lambda x: x,\n",
        "                                    dynamic_secondary_mask=True,\n",
        "                                    x_channels=1,\n",
        "                                    secondary_channels=1,\n",
        "                                    primary_channels=1)\n",
        "\n",
        "        consistent_test_datasets[sampling_percentage][name] = test_dataset\n",
        "\n",
        "        # Store random states for this sampling percentage and test type\n",
        "        validation_states[sampling_percentage][name] = {\n",
        "            'torch_rng': torch.get_rng_state(),\n",
        "            'numpy_rng': np.random.get_state(),\n",
        "            'random_rng': random.getstate()\n",
        "        }\n",
        "\n",
        "consistent_test_dataloaders = {\n",
        "    sampling_percentage: {\n",
        "        name: DataLoader(dataset, batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n",
        "        for name, dataset in test_datasets.items()\n",
        "    }\n",
        "    for sampling_percentage, test_datasets in consistent_test_datasets.items()\n",
        "}\n",
        "\n",
        "collected_images = []\n",
        "use_sparse = True\n",
        "use_input_mask = False\n",
        "\n",
        "for sampling_percentage in sampling_percentages:\n",
        "    print(f\"\\nStarting training with sampling percentage: {sampling_percentage}%\")\n",
        "\n",
        "    # Create training dataset with current sampling percentage\n",
        "    generator = CategoricalSpatialGenerator(size, lambda: two_layer_generator(),\n",
        "                                          num_categories=10, methods=['layered', 'vid'])\n",
        "    train_dataset = SpatialDataset(fixed_dataset_size, generator,\n",
        "                                  lambda size: percentage_random_sampling(size, sampling_percentage),\n",
        "                                  lambda x: x,\n",
        "                                  dynamic_secondary_mask=True,\n",
        "                                  x_channels=1,\n",
        "                                  secondary_channels=1,\n",
        "                                  primary_channels=1)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
        "                                num_workers=0, pin_memory=True)\n",
        "\n",
        "    # Initialize the models\n",
        "    convnext = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]).to(device)\n",
        "    sparse_encoder = SparseEncoder(convnext, input_size=(32, 64)).to(device)\n",
        "    subsurface_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "    last_model_path = \"drive/MyDrive/Models/base_id_1000k.pth\"\n",
        "\n",
        "    # Load the model state\n",
        "    sparse_encoder, _ , subsurface_decoder, use_secondary, use_sparse, training_losses = load_model(\n",
        "        last_model_path,\n",
        "        sparse_encoder,\n",
        "        None,\n",
        "        subsurface_decoder,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Progressive training loop\n",
        "    current_epoch = 0\n",
        "\n",
        "    for target_epoch in epochs:\n",
        "        epochs_to_train = target_epoch - current_epoch\n",
        "        if epochs_to_train <= 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"Training from epoch {current_epoch + 1} to {target_epoch}\")\n",
        "\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        sparse_encoder, _, subsurface_decoder, training_losses = train_model(\n",
        "            sparse_encoder, None, subsurface_decoder, train_dataloader,\n",
        "            use_sparse=use_sparse,\n",
        "            model_save_path=f\"model_sampling{sampling_percentage}_epochs{target_epoch}.pth\",\n",
        "            num_epochs=epochs_to_train,\n",
        "            use_secondary=False,\n",
        "            use_input_mask=use_input_mask,\n",
        "            device=device,\n",
        "            save_model=False,\n",
        "            visualize=False\n",
        "        )\n",
        "\n",
        "        training_end_time = time.time()\n",
        "        training_time = training_end_time - training_start_time\n",
        "        final_training_loss = training_losses[-1]['primary_loss']\n",
        "\n",
        "        # Evaluate on consistent test sets for this sampling percentage\n",
        "        test_metrics = {}\n",
        "        evaluation_times = {}\n",
        "\n",
        "        for name, dataloader in consistent_test_dataloaders[sampling_percentage].items():\n",
        "            # Restore validation data state\n",
        "            torch.set_rng_state(validation_states[sampling_percentage][name]['torch_rng'])\n",
        "            np.random.set_state(validation_states[sampling_percentage][name]['numpy_rng'])\n",
        "            random.setstate(validation_states[sampling_percentage][name]['random_rng'])\n",
        "\n",
        "            evaluation_start_time = time.time()\n",
        "\n",
        "            loss, variance, total_variance = evaluate_model(\n",
        "                sparse_encoder, subsurface_decoder,\n",
        "                dataloader, device=device,\n",
        "                use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "\n",
        "            evaluation_end_time = time.time()\n",
        "            evaluation_time = evaluation_end_time - evaluation_start_time\n",
        "\n",
        "            test_metrics[name] = {\n",
        "                'loss': loss,\n",
        "                'batch_variance': variance,\n",
        "                'total_variance': total_variance\n",
        "            }\n",
        "            evaluation_times[name] = evaluation_time\n",
        "\n",
        "        # Record results\n",
        "        results.append({\n",
        "            'sampling_percentage': sampling_percentage,\n",
        "            'epochs': target_epoch,\n",
        "            'training_loss': final_training_loss,\n",
        "            'training_time': training_time,\n",
        "            'evaluation_time_interpolation': evaluation_times['interpolation'],\n",
        "            'evaluation_time_extrapolation_close': evaluation_times['extrapolation_close'],\n",
        "            'evaluation_time_extrapolation_far': evaluation_times['extrapolation_far'],\n",
        "            'test_loss_interpolation': test_metrics['interpolation']['loss'],\n",
        "            'test_variance_interpolation': test_metrics['interpolation']['total_variance'],\n",
        "            'test_loss_extrapolation_close': test_metrics['extrapolation_close']['loss'],\n",
        "            'test_variance_extrapolation_close': test_metrics['extrapolation_close']['total_variance'],\n",
        "            'test_loss_extrapolation_far': test_metrics['extrapolation_far']['loss'],\n",
        "            'test_variance_extrapolation_far': test_metrics['extrapolation_far']['total_variance']\n",
        "        })\n",
        "\n",
        "        current_epoch = target_epoch\n",
        "\n",
        "        # Collect visualization samples\n",
        "        # Training data visualization\n",
        "        train_iter = iter(train_dataloader)\n",
        "        train_batch = next(train_iter)\n",
        "        train_input, train_output, train_mask, train_original = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, train_batch,\n",
        "            device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "        )\n",
        "        collected_images.append({\n",
        "            'title': f'Train Sampling: {sampling_percentage}%, Epochs: {target_epoch}',\n",
        "            'input_grid': train_input,\n",
        "            'output_grid': train_output,\n",
        "            'input_mask': train_mask,\n",
        "            'original_image': train_original\n",
        "        })\n",
        "\n",
        "        # Test data visualization using consistent validation data\n",
        "        for name, dataloader in consistent_test_dataloaders[sampling_percentage].items():\n",
        "            test_iter = iter(dataloader)\n",
        "            test_batch = next(test_iter)\n",
        "            test_input, test_output, test_mask, test_original = process_batch(\n",
        "                sparse_encoder, subsurface_decoder, test_batch,\n",
        "                device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "            collected_images.append({\n",
        "                'title': f'Test: {name}, Sampling: {sampling_percentage}%, Epochs: {target_epoch}',\n",
        "                'input_grid': test_input,\n",
        "                'output_grid': test_output,\n",
        "                'input_mask': test_mask,\n",
        "                'original_image': test_original\n",
        "            })\n",
        "\n",
        "# Convert results to DataFrame and create visualizations\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n",
        "\n",
        "# Create visualization plots (similar structure to previous version, but with sampling_percentage instead of data_size)\n",
        "plt.style.use('seaborn')\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
        "\n",
        "# Modified plotting code for sampling percentage analysis\n",
        "test_types = {\n",
        "    'test_loss_interpolation': 'Interpolation (3-50)',\n",
        "    'test_loss_extrapolation_close': 'Close Extrapolation (51-70)',\n",
        "    'test_loss_extrapolation_far': 'Far Extrapolation (70-90)'\n",
        "}\n",
        "\n",
        "# 1. Test Losses vs Sampling Percentage for Different Epochs\n",
        "ax1 = axes[0, 0]\n",
        "for test_type, label in test_types.items():\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax1.plot(epoch_data['sampling_percentage'], epoch_data[test_type],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax1.set_xlabel('Sampling Percentage')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.set_title('Test Losses vs Sampling Percentage\\n(Fixed Dataset Size)')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True)\n",
        "\n",
        "# 2. Test Losses vs Epochs for Different Sampling Percentages\n",
        "ax2 = axes[0, 1]\n",
        "for test_type, label in test_types.items():\n",
        "    for sampling_pct in sampling_percentages:\n",
        "        size_data = df_results[df_results['sampling_percentage'] == sampling_pct]\n",
        "        ax2.plot(size_data['epochs'], size_data[test_type],\n",
        "                 label=f'{label} ({sampling_pct}%)', marker='o', alpha=0.7)\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Test Loss')\n",
        "ax2.set_title('Test Losses vs Epochs\\n(By Sampling Percentage)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True)\n",
        "\n",
        "# 3. Heatmaps for each test type including Training Loss\n",
        "fig_heatmaps, axes_heatmaps = plt.subplots(1, 4, figsize=(25, 6))\n",
        "test_types_with_training = {\n",
        "    'training_loss': 'Training Loss',\n",
        "    **test_types\n",
        "}\n",
        "for idx, (test_type, label) in enumerate(test_types_with_training.items()):\n",
        "    pivot_table = df_results.pivot(index='sampling_percentage', columns='epochs', values=test_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_heatmaps[idx])\n",
        "    axes_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_heatmaps[idx].set_ylabel('Sampling Percentage')\n",
        "    axes_heatmaps[idx].set_xlabel('Epochs')\n",
        "fig_heatmaps.tight_layout()\n",
        "\n",
        "# 4. Comparison of test types\n",
        "ax4 = axes[1, 1]\n",
        "box_data = [df_results[test_type] for test_type in test_types.keys()]\n",
        "ax4.boxplot(box_data, labels=[label.replace('\\n', ' ') for label in test_types.values()])\n",
        "ax4.set_ylabel('Test Loss')\n",
        "ax4.set_title('Distribution of Test Losses by Type\\n(Across All Sampling Percentages)')\n",
        "ax4.grid(True)\n",
        "\n",
        "# 5. Loss Ratio Analysis\n",
        "ax3 = axes[1, 0]\n",
        "df_results['close_extrapolation_ratio'] = df_results['test_loss_extrapolation_close'] / df_results['test_loss_interpolation']\n",
        "df_results['far_extrapolation_ratio'] = df_results['test_loss_extrapolation_far'] / df_results['test_loss_interpolation']\n",
        "\n",
        "for ratio, label in [('close_extrapolation_ratio', 'Close Extrapolation / Interpolation'),\n",
        "                    ('far_extrapolation_ratio', 'Far Extrapolation / Interpolation')]:\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax3.plot(epoch_data['sampling_percentage'], epoch_data[ratio],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax3.axhline(y=1, color='r', linestyle='--', label='Baseline (Equal Performance)')\n",
        "ax3.set_xlabel('Sampling Percentage')\n",
        "ax3.set_ylabel('Loss Ratio')\n",
        "ax3.set_title('Extrapolation Performance Relative to Interpolation\\n(By Sampling Percentage)')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(True)\n",
        "\n",
        "# Heatmaps for variances of each test type\n",
        "fig_variance_heatmaps, axes_variance_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "variance_test_types = {\n",
        "    'test_variance_interpolation': 'Interpolation Variance',\n",
        "    'test_variance_extrapolation_close': 'Close Extrapolation Variance',\n",
        "    'test_variance_extrapolation_far': 'Far Extrapolation Variance'\n",
        "}\n",
        "for idx, (variance_type, label) in enumerate(variance_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='sampling_percentage', columns='epochs', values=variance_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_variance_heatmaps[idx])\n",
        "    axes_variance_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_variance_heatmaps[idx].set_ylabel('Sampling Percentage')\n",
        "    axes_variance_heatmaps[idx].set_xlabel('Epochs')\n",
        "fig_variance_heatmaps.tight_layout()\n",
        "\n",
        "# 7. Training Loss Heatmap\n",
        "ax7 = axes[2, 1]\n",
        "training_loss_pivot = df_results.pivot(index='sampling_percentage', columns='epochs', values='training_loss')\n",
        "sns.heatmap(training_loss_pivot, annot=True, fmt=\".6f\", cmap='viridis', ax=ax7)\n",
        "ax7.set_title('Training Loss Heatmap')\n",
        "ax7.set_ylabel('Sampling Percentage')\n",
        "ax7.set_xlabel('Epochs')\n",
        "\n",
        "# 8. Training Time Heatmap\n",
        "ax8 = axes[2, 0]\n",
        "training_time_pivot = df_results.pivot(index='sampling_percentage', columns='epochs', values='training_time')\n",
        "sns.heatmap(training_time_pivot, annot=True, fmt=\".2f\", cmap='Blues', ax=ax8)\n",
        "ax8.set_title('Training Time Heatmap')\n",
        "ax8.set_ylabel('Sampling Percentage')\n",
        "ax8.set_xlabel('Epochs')\n",
        "\n",
        "# 9. Evaluation Time Heatmaps for each test set\n",
        "fig_eval_time_heatmaps, axes_eval_time_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "evaluation_time_test_types = {\n",
        "    'evaluation_time_interpolation': 'Interpolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_close': 'Close Extrapolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_far': 'Far Extrapolation Evaluation Time'\n",
        "}\n",
        "for idx, (eval_time_type, label) in enumerate(evaluation_time_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='sampling_percentage', columns='epochs', values=eval_time_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap='Greens', ax=axes_eval_time_heatmaps[idx])\n",
        "    axes_eval_time_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_eval_time_heatmaps[idx].set_ylabel('Sampling Percentage')\n",
        "    axes_eval_time_heatmaps[idx].set_xlabel('Epochs')\n",
        "    fig_eval_time_heatmaps.tight_layout()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize collected images\n",
        "plot_collected_images(collected_images, images_per_row=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrxVZ9x44ytf"
      },
      "outputs": [],
      "source": [
        "plot_collected_images(collected_images, images_per_row=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Define sampling percentages and max epochs\n",
        "sampling_percentages = [1, 2, 3, 4, 5, 10, 15]  # Percentages of total points\n",
        "epochs = [1, 2, 5, 10, 20, 100, 150]\n",
        "fixed_dataset_size = 1000\n",
        "size = (32,64)\n",
        "\n",
        "def percentage_random_sampling(size, percentage):\n",
        "    mask = torch.zeros(1, *size)\n",
        "    height, width = size\n",
        "    total_points = height * width\n",
        "    target_points = int((percentage / 100.0) * total_points)\n",
        "\n",
        "    if percentage >= 100:\n",
        "        mask[:] = 1\n",
        "        return mask\n",
        "\n",
        "    if target_points == 0:\n",
        "        return mask\n",
        "\n",
        "    indices = torch.randperm(total_points)[:target_points]\n",
        "    y_indices = indices // width\n",
        "    x_indices = indices % width\n",
        "    mask[0, y_indices, x_indices] = 1\n",
        "\n",
        "    return mask\n",
        "\n",
        "# Initialize results list and device\n",
        "results = []\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create test generators\n",
        "interpolation_generator = lambda: torch.rand(torch.randint(3, 50, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_close_generator = lambda: torch.rand(torch.randint(51, 70, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_far_generator = lambda: torch.rand(torch.randint(70, 90, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "\n",
        "test_generators = {\n",
        "    'interpolation': interpolation_generator,\n",
        "    'extrapolation_close': extrapolation_close_generator,\n",
        "    'extrapolation_far': extrapolation_far_generator\n",
        "}\n",
        "\n",
        "# Create consistent validation datasets for each sampling percentage\n",
        "print(\"Creating consistent validation datasets...\")\n",
        "consistent_test_datasets = {}\n",
        "validation_states = {}\n",
        "\n",
        "for sampling_percentage in sampling_percentages:\n",
        "    consistent_test_datasets[sampling_percentage] = {}\n",
        "    validation_states[sampling_percentage] = {}\n",
        "\n",
        "    for name, gen in test_generators.items():\n",
        "        # Set seeds for reproducibility\n",
        "        torch.manual_seed(42 + sampling_percentage)\n",
        "        np.random.seed(42 + sampling_percentage)\n",
        "        random.seed(42 + sampling_percentage)\n",
        "\n",
        "        generator_obj = CategoricalSpatialGenerator(size, lambda: two_layer_generator(),\n",
        "                                                  num_categories=10, methods=['layered', 'vid'])\n",
        "\n",
        "        test_dataset = SpatialDataset(1000, generator_obj,\n",
        "                                    lambda size: percentage_random_sampling(size, sampling_percentage),\n",
        "                                    lambda x: x,\n",
        "                                    dynamic_secondary_mask=False,\n",
        "                                    x_channels=1,\n",
        "                                    secondary_channels=1,\n",
        "                                    primary_channels=1)\n",
        "\n",
        "        consistent_test_datasets[sampling_percentage][name] = test_dataset\n",
        "\n",
        "        # Store random states for this sampling percentage and test type\n",
        "        validation_states[sampling_percentage][name] = {\n",
        "            'torch_rng': torch.get_rng_state(),\n",
        "            'numpy_rng': np.random.get_state(),\n",
        "            'random_rng': random.getstate()\n",
        "        }\n",
        "\n",
        "consistent_test_dataloaders = {\n",
        "    sampling_percentage: {\n",
        "        name: DataLoader(dataset, batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n",
        "        for name, dataset in test_datasets.items()\n",
        "    }\n",
        "    for sampling_percentage, test_datasets in consistent_test_datasets.items()\n",
        "}\n",
        "\n",
        "collected_images = []\n",
        "use_sparse = True\n",
        "use_input_mask = False\n",
        "\n",
        "for sampling_percentage in sampling_percentages:\n",
        "    print(f\"\\nStarting training with sampling percentage: {sampling_percentage}%\")\n",
        "\n",
        "    # Create training dataset with current sampling percentage\n",
        "    generator = CategoricalSpatialGenerator(size, lambda: two_layer_generator(),\n",
        "                                          num_categories=10, methods=['layered', 'vid'])\n",
        "    train_dataset = SpatialDataset(fixed_dataset_size, generator,\n",
        "                                  lambda size: percentage_random_sampling(size, sampling_percentage),\n",
        "                                  lambda x: x,\n",
        "                                  dynamic_secondary_mask=False,\n",
        "                                  x_channels=1,\n",
        "                                  secondary_channels=1,\n",
        "                                  primary_channels=1)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
        "                                num_workers=0, pin_memory=True)\n",
        "\n",
        "    # Initialize the models\n",
        "    convnext = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]).to(device)\n",
        "    sparse_encoder = SparseEncoder(convnext, input_size=(32, 64)).to(device)\n",
        "    subsurface_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "    last_model_path = \"drive/MyDrive/Models/base_id_1000k.pth\"\n",
        "\n",
        "    # Load the model state\n",
        "    sparse_encoder, _ , subsurface_decoder, use_secondary, use_sparse, training_losses = load_model(\n",
        "        last_model_path,\n",
        "        sparse_encoder,\n",
        "        None,\n",
        "        subsurface_decoder,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Progressive training loop\n",
        "    current_epoch = 0\n",
        "\n",
        "    for target_epoch in epochs:\n",
        "        epochs_to_train = target_epoch - current_epoch\n",
        "        if epochs_to_train <= 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"Training from epoch {current_epoch + 1} to {target_epoch}\")\n",
        "\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        sparse_encoder, _, subsurface_decoder, training_losses = train_model(\n",
        "            sparse_encoder, None, subsurface_decoder, train_dataloader,\n",
        "            use_sparse=use_sparse,\n",
        "            model_save_path=f\"model_sampling{sampling_percentage}_epochs{target_epoch}.pth\",\n",
        "            num_epochs=epochs_to_train,\n",
        "            use_secondary=False,\n",
        "            use_input_mask=use_input_mask,\n",
        "            device=device,\n",
        "            save_model=False,\n",
        "            visualize=False\n",
        "        )\n",
        "\n",
        "        training_end_time = time.time()\n",
        "        training_time = training_end_time - training_start_time\n",
        "        final_training_loss = training_losses[-1]['primary_loss']\n",
        "\n",
        "        # Evaluate on consistent test sets for this sampling percentage\n",
        "        test_metrics = {}\n",
        "        evaluation_times = {}\n",
        "\n",
        "        for name, dataloader in consistent_test_dataloaders[sampling_percentage].items():\n",
        "            # Restore validation data state\n",
        "            torch.set_rng_state(validation_states[sampling_percentage][name]['torch_rng'])\n",
        "            np.random.set_state(validation_states[sampling_percentage][name]['numpy_rng'])\n",
        "            random.setstate(validation_states[sampling_percentage][name]['random_rng'])\n",
        "\n",
        "            evaluation_start_time = time.time()\n",
        "\n",
        "            loss, variance, total_variance = evaluate_model(\n",
        "                sparse_encoder, subsurface_decoder,\n",
        "                dataloader, device=device,\n",
        "                use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "\n",
        "            evaluation_end_time = time.time()\n",
        "            evaluation_time = evaluation_end_time - evaluation_start_time\n",
        "\n",
        "            test_metrics[name] = {\n",
        "                'loss': loss,\n",
        "                'batch_variance': variance,\n",
        "                'total_variance': total_variance\n",
        "            }\n",
        "            evaluation_times[name] = evaluation_time\n",
        "\n",
        "        # Record results\n",
        "        results.append({\n",
        "            'sampling_percentage': sampling_percentage,\n",
        "            'epochs': target_epoch,\n",
        "            'training_loss': final_training_loss,\n",
        "            'training_time': training_time,\n",
        "            'evaluation_time_interpolation': evaluation_times['interpolation'],\n",
        "            'evaluation_time_extrapolation_close': evaluation_times['extrapolation_close'],\n",
        "            'evaluation_time_extrapolation_far': evaluation_times['extrapolation_far'],\n",
        "            'test_loss_interpolation': test_metrics['interpolation']['loss'],\n",
        "            'test_variance_interpolation': test_metrics['interpolation']['total_variance'],\n",
        "            'test_loss_extrapolation_close': test_metrics['extrapolation_close']['loss'],\n",
        "            'test_variance_extrapolation_close': test_metrics['extrapolation_close']['total_variance'],\n",
        "            'test_loss_extrapolation_far': test_metrics['extrapolation_far']['loss'],\n",
        "            'test_variance_extrapolation_far': test_metrics['extrapolation_far']['total_variance']\n",
        "        })\n",
        "\n",
        "        current_epoch = target_epoch\n",
        "\n",
        "        # Collect visualization samples\n",
        "        # Training data visualization\n",
        "        train_iter = iter(train_dataloader)\n",
        "        train_batch = next(train_iter)\n",
        "        train_input, train_output, train_mask, train_original = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, train_batch,\n",
        "            device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "        )\n",
        "        collected_images.append({\n",
        "            'title': f'Train Sampling: {sampling_percentage}%, Epochs: {target_epoch}',\n",
        "            'input_grid': train_input,\n",
        "            'output_grid': train_output,\n",
        "            'input_mask': train_mask,\n",
        "            'original_image': train_original\n",
        "        })\n",
        "\n",
        "        # Test data visualization using consistent validation data\n",
        "        for name, dataloader in consistent_test_dataloaders[sampling_percentage].items():\n",
        "            test_iter = iter(dataloader)\n",
        "            test_batch = next(test_iter)\n",
        "            test_input, test_output, test_mask, test_original = process_batch(\n",
        "                sparse_encoder, subsurface_decoder, test_batch,\n",
        "                device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "            collected_images.append({\n",
        "                'title': f'Test: {name}, Sampling: {sampling_percentage}%, Epochs: {target_epoch}',\n",
        "                'input_grid': test_input,\n",
        "                'output_grid': test_output,\n",
        "                'input_mask': test_mask,\n",
        "                'original_image': test_original\n",
        "            })\n",
        "\n",
        "# Convert results to DataFrame and create visualizations\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n",
        "\n",
        "# Create visualization plots (similar structure to previous version, but with sampling_percentage instead of data_size)\n",
        "plt.style.use('seaborn')\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
        "\n",
        "# Modified plotting code for sampling percentage analysis\n",
        "test_types = {\n",
        "    'test_loss_interpolation': 'Interpolation (3-50)',\n",
        "    'test_loss_extrapolation_close': 'Close Extrapolation (51-70)',\n",
        "    'test_loss_extrapolation_far': 'Far Extrapolation (70-90)'\n",
        "}\n",
        "\n",
        "# 1. Test Losses vs Sampling Percentage for Different Epochs\n",
        "ax1 = axes[0, 0]\n",
        "for test_type, label in test_types.items():\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax1.plot(epoch_data['sampling_percentage'], epoch_data[test_type],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax1.set_xlabel('Sampling Percentage')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.set_title('Test Losses vs Sampling Percentage\\n(Fixed Dataset Size)')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True)\n",
        "\n",
        "# 2. Test Losses vs Epochs for Different Sampling Percentages\n",
        "ax2 = axes[0, 1]\n",
        "for test_type, label in test_types.items():\n",
        "    for sampling_pct in sampling_percentages:\n",
        "        size_data = df_results[df_results['sampling_percentage'] == sampling_pct]\n",
        "        ax2.plot(size_data['epochs'], size_data[test_type],\n",
        "                 label=f'{label} ({sampling_pct}%)', marker='o', alpha=0.7)\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Test Loss')\n",
        "ax2.set_title('Test Losses vs Epochs\\n(By Sampling Percentage)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True)\n",
        "\n",
        "# 3. Heatmaps for each test type including Training Loss\n",
        "fig_heatmaps, axes_heatmaps = plt.subplots(1, 4, figsize=(25, 6))\n",
        "test_types_with_training = {\n",
        "    'training_loss': 'Training Loss',\n",
        "    **test_types\n",
        "}\n",
        "for idx, (test_type, label) in enumerate(test_types_with_training.items()):\n",
        "    pivot_table = df_results.pivot(index='sampling_percentage', columns='epochs', values=test_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_heatmaps[idx])\n",
        "    axes_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_heatmaps[idx].set_ylabel('Sampling Percentage')\n",
        "    axes_heatmaps[idx].set_xlabel('Epochs')\n",
        "fig_heatmaps.tight_layout()\n",
        "\n",
        "# 4. Comparison of test types\n",
        "ax4 = axes[1, 1]\n",
        "box_data = [df_results[test_type] for test_type in test_types.keys()]\n",
        "ax4.boxplot(box_data, labels=[label.replace('\\n', ' ') for label in test_types.values()])\n",
        "ax4.set_ylabel('Test Loss')\n",
        "ax4.set_title('Distribution of Test Losses by Type\\n(Across All Sampling Percentages)')\n",
        "ax4.grid(True)\n",
        "\n",
        "# 5. Loss Ratio Analysis\n",
        "ax3 = axes[1, 0]\n",
        "df_results['close_extrapolation_ratio'] = df_results['test_loss_extrapolation_close'] / df_results['test_loss_interpolation']\n",
        "df_results['far_extrapolation_ratio'] = df_results['test_loss_extrapolation_far'] / df_results['test_loss_interpolation']\n",
        "\n",
        "for ratio, label in [('close_extrapolation_ratio', 'Close Extrapolation / Interpolation'),\n",
        "                    ('far_extrapolation_ratio', 'Far Extrapolation / Interpolation')]:\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax3.plot(epoch_data['sampling_percentage'], epoch_data[ratio],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax3.axhline(y=1, color='r', linestyle='--', label='Baseline (Equal Performance)')\n",
        "ax3.set_xlabel('Sampling Percentage')\n",
        "ax3.set_ylabel('Loss Ratio')\n",
        "ax3.set_title('Extrapolation Performance Relative to Interpolation\\n(By Sampling Percentage)')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(True)\n",
        "\n",
        "# Heatmaps for variances of each test type\n",
        "fig_variance_heatmaps, axes_variance_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "variance_test_types = {\n",
        "    'test_variance_interpolation': 'Interpolation Variance',\n",
        "    'test_variance_extrapolation_close': 'Close Extrapolation Variance',\n",
        "    'test_variance_extrapolation_far': 'Far Extrapolation Variance'\n",
        "}\n",
        "for idx, (variance_type, label) in enumerate(variance_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='sampling_percentage', columns='epochs', values=variance_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_variance_heatmaps[idx])\n",
        "    axes_variance_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_variance_heatmaps[idx].set_ylabel('Sampling Percentage')\n",
        "    axes_variance_heatmaps[idx].set_xlabel('Epochs')\n",
        "fig_variance_heatmaps.tight_layout()\n",
        "\n",
        "# 7. Training Loss Heatmap\n",
        "ax7 = axes[2, 1]\n",
        "training_loss_pivot = df_results.pivot(index='sampling_percentage', columns='epochs', values='training_loss')\n",
        "sns.heatmap(training_loss_pivot, annot=True, fmt=\".6f\", cmap='viridis', ax=ax7)\n",
        "ax7.set_title('Training Loss Heatmap')\n",
        "ax7.set_ylabel('Sampling Percentage')\n",
        "ax7.set_xlabel('Epochs')\n",
        "\n",
        "# 8. Training Time Heatmap\n",
        "ax8 = axes[2, 0]\n",
        "training_time_pivot = df_results.pivot(index='sampling_percentage', columns='epochs', values='training_time')\n",
        "sns.heatmap(training_time_pivot, annot=True, fmt=\".2f\", cmap='Blues', ax=ax8)\n",
        "ax8.set_title('Training Time Heatmap')\n",
        "ax8.set_ylabel('Sampling Percentage')\n",
        "ax8.set_xlabel('Epochs')\n",
        "\n",
        "# 9. Evaluation Time Heatmaps for each test set\n",
        "fig_eval_time_heatmaps, axes_eval_time_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "evaluation_time_test_types = {\n",
        "    'evaluation_time_interpolation': 'Interpolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_close': 'Close Extrapolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_far': 'Far Extrapolation Evaluation Time'\n",
        "}\n",
        "for idx, (eval_time_type, label) in enumerate(evaluation_time_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='sampling_percentage', columns='epochs', values=eval_time_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap='Greens', ax=axes_eval_time_heatmaps[idx])\n",
        "    axes_eval_time_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_eval_time_heatmaps[idx].set_ylabel('Sampling Percentage')\n",
        "    axes_eval_time_heatmaps[idx].set_xlabel('Epochs')\n",
        "    fig_eval_time_heatmaps.tight_layout()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize collected images\n",
        "plot_collected_images(collected_images, images_per_row=4)"
      ],
      "metadata": {
        "id": "q1aGwuOr_mbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_collected_images(collected_images, images_per_row=4)"
      ],
      "metadata": {
        "id": "qyvVTxg5_uw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uve6LV1Osp5s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Define sampling percentages and max epochs\n",
        "sampling_percentages = [1, 2, 3, 4, 5, 10, 15]  # Percentages of total points\n",
        "epochs = [1, 5, 10, 20, 40, 80, 160]\n",
        "fixed_dataset_size = 1000  # Keep dataset size constant\n",
        "size = (32,64)\n",
        "\n",
        "def percentage_random_sampling(size, percentage):\n",
        "    mask = torch.zeros(1, *size)\n",
        "    height, width = size\n",
        "    total_points = height * width\n",
        "    target_points = int((percentage / 100.0) * total_points)\n",
        "\n",
        "    if percentage >= 100:\n",
        "        mask[:] = 1\n",
        "        return mask\n",
        "\n",
        "    if target_points == 0:\n",
        "        return mask\n",
        "\n",
        "    indices = torch.randperm(total_points)[:target_points]\n",
        "    y_indices = indices // width\n",
        "    x_indices = indices % width\n",
        "    mask[0, y_indices, x_indices] = 1\n",
        "\n",
        "    return mask\n",
        "\n",
        "# Initialize results list and device\n",
        "results = []\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create test generators\n",
        "interpolation_generator = lambda: torch.rand(torch.randint(3, 50, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_close_generator = lambda: torch.rand(torch.randint(51, 70, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "extrapolation_far_generator = lambda: torch.rand(torch.randint(70, 90, (1,)).item(), 3) * torch.tensor([64, 64, 1])\n",
        "\n",
        "test_generators = {\n",
        "    'interpolation': interpolation_generator,\n",
        "    'extrapolation_close': extrapolation_close_generator,\n",
        "    'extrapolation_far': extrapolation_far_generator\n",
        "}\n",
        "\n",
        "# Create consistent validation datasets for each sampling percentage\n",
        "print(\"Creating consistent validation datasets...\")\n",
        "consistent_test_datasets = {}\n",
        "validation_states = {}\n",
        "\n",
        "for sampling_percentage in sampling_percentages:\n",
        "    consistent_test_datasets[sampling_percentage] = {}\n",
        "    validation_states[sampling_percentage] = {}\n",
        "\n",
        "    for name, gen in test_generators.items():\n",
        "        # Set seeds for reproducibility\n",
        "        torch.manual_seed(42 + sampling_percentage)\n",
        "        np.random.seed(42 + sampling_percentage)\n",
        "        random.seed(42 + sampling_percentage)\n",
        "\n",
        "        generator_obj = CategoricalSpatialGenerator(size, lambda: two_layer_generator(),\n",
        "                                                  num_categories=10, methods=['layered', 'vid'])\n",
        "\n",
        "        test_dataset = SpatialDataset(1000, generator_obj,\n",
        "                                    lambda size: percentage_random_sampling(size, sampling_percentage),\n",
        "                                    lambda x: x,\n",
        "                                    dynamic_secondary_mask=True,\n",
        "                                    x_channels=1,\n",
        "                                    secondary_channels=1,\n",
        "                                    primary_channels=1)\n",
        "\n",
        "        consistent_test_datasets[sampling_percentage][name] = test_dataset\n",
        "\n",
        "        # Store random states for this sampling percentage and test type\n",
        "        validation_states[sampling_percentage][name] = {\n",
        "            'torch_rng': torch.get_rng_state(),\n",
        "            'numpy_rng': np.random.get_state(),\n",
        "            'random_rng': random.getstate()\n",
        "        }\n",
        "\n",
        "consistent_test_dataloaders = {\n",
        "    sampling_percentage: {\n",
        "        name: DataLoader(dataset, batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n",
        "        for name, dataset in test_datasets.items()\n",
        "    }\n",
        "    for sampling_percentage, test_datasets in consistent_test_datasets.items()\n",
        "}\n",
        "\n",
        "collected_images = []\n",
        "use_sparse = True\n",
        "use_input_mask = False\n",
        "\n",
        "for sampling_percentage in sampling_percentages:\n",
        "    print(f\"\\nStarting training with sampling percentage: {sampling_percentage}%\")\n",
        "\n",
        "    # Create training dataset with current sampling percentage\n",
        "    generator = CategoricalSpatialGenerator(size, lambda: two_layer_generator(),\n",
        "                                          num_categories=10, methods=['layered', 'vid'])\n",
        "    train_dataset = SpatialDataset(fixed_dataset_size, generator,\n",
        "                                  lambda size: percentage_random_sampling(size, sampling_percentage),\n",
        "                                  lambda x: x,\n",
        "                                  dynamic_secondary_mask=True,\n",
        "                                  x_channels=1,\n",
        "                                  secondary_channels=1,\n",
        "                                  primary_channels=1)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
        "                                num_workers=0, pin_memory=True)\n",
        "\n",
        "    # Initialize the models\n",
        "    convnext = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]).to(device)\n",
        "    sparse_encoder = SparseEncoder(convnext, input_size=(32, 64)).to(device)\n",
        "    subsurface_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "\n",
        "    # Progressive training loop\n",
        "    current_epoch = 0\n",
        "\n",
        "    for target_epoch in epochs:\n",
        "        epochs_to_train = target_epoch - current_epoch\n",
        "        if epochs_to_train <= 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"Training from epoch {current_epoch + 1} to {target_epoch}\")\n",
        "\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        sparse_encoder, _, subsurface_decoder, training_losses = train_model(\n",
        "            sparse_encoder, None, subsurface_decoder, train_dataloader,\n",
        "            use_sparse=use_sparse,\n",
        "            model_save_path=f\"model_sampling{sampling_percentage}_epochs{target_epoch}.pth\",\n",
        "            num_epochs=epochs_to_train,\n",
        "            use_secondary=False,\n",
        "            use_input_mask=use_input_mask,\n",
        "            device=device,\n",
        "            save_model=False,\n",
        "            visualize=True\n",
        "        )\n",
        "\n",
        "        training_end_time = time.time()\n",
        "        training_time = training_end_time - training_start_time\n",
        "        final_training_loss = training_losses[-1]['primary_loss']\n",
        "\n",
        "        # Evaluate on consistent test sets for this sampling percentage\n",
        "        test_metrics = {}\n",
        "        evaluation_times = {}\n",
        "\n",
        "        for name, dataloader in consistent_test_dataloaders[sampling_percentage].items():\n",
        "            # Restore validation data state\n",
        "            torch.set_rng_state(validation_states[sampling_percentage][name]['torch_rng'])\n",
        "            np.random.set_state(validation_states[sampling_percentage][name]['numpy_rng'])\n",
        "            random.setstate(validation_states[sampling_percentage][name]['random_rng'])\n",
        "\n",
        "            evaluation_start_time = time.time()\n",
        "\n",
        "            loss, variance, total_variance = evaluate_model(\n",
        "                sparse_encoder, subsurface_decoder,\n",
        "                dataloader, device=device,\n",
        "                use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "\n",
        "            evaluation_end_time = time.time()\n",
        "            evaluation_time = evaluation_end_time - evaluation_start_time\n",
        "\n",
        "            test_metrics[name] = {\n",
        "                'loss': loss,\n",
        "                'batch_variance': variance,\n",
        "                'total_variance': total_variance\n",
        "            }\n",
        "            evaluation_times[name] = evaluation_time\n",
        "\n",
        "        # Record results\n",
        "        results.append({\n",
        "            'sampling_percentage': sampling_percentage,\n",
        "            'epochs': target_epoch,\n",
        "            'training_loss': final_training_loss,\n",
        "            'training_time': training_time,\n",
        "            'evaluation_time_interpolation': evaluation_times['interpolation'],\n",
        "            'evaluation_time_extrapolation_close': evaluation_times['extrapolation_close'],\n",
        "            'evaluation_time_extrapolation_far': evaluation_times['extrapolation_far'],\n",
        "            'test_loss_interpolation': test_metrics['interpolation']['loss'],\n",
        "            'test_variance_interpolation': test_metrics['interpolation']['total_variance'],\n",
        "            'test_loss_extrapolation_close': test_metrics['extrapolation_close']['loss'],\n",
        "            'test_variance_extrapolation_close': test_metrics['extrapolation_close']['total_variance'],\n",
        "            'test_loss_extrapolation_far': test_metrics['extrapolation_far']['loss'],\n",
        "            'test_variance_extrapolation_far': test_metrics['extrapolation_far']['total_variance']\n",
        "        })\n",
        "\n",
        "        current_epoch = target_epoch\n",
        "\n",
        "        # Collect visualization samples\n",
        "        # Training data visualization\n",
        "        train_iter = iter(train_dataloader)\n",
        "        train_batch = next(train_iter)\n",
        "        train_input, train_output, train_mask = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, train_batch,\n",
        "            device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "        )\n",
        "        collected_images.append({\n",
        "            'title': f'Train Sampling: {sampling_percentage}%, Epochs: {target_epoch}',\n",
        "            'input_grid': train_input,\n",
        "            'output_grid': train_output,\n",
        "            'input_mask': train_mask\n",
        "        })\n",
        "\n",
        "        # Test data visualization using consistent validation data\n",
        "        for name, dataloader in consistent_test_dataloaders[sampling_percentage].items():\n",
        "            test_iter = iter(dataloader)\n",
        "            test_batch = next(test_iter)\n",
        "            test_input, test_output, test_mask = process_batch(\n",
        "                sparse_encoder, subsurface_decoder, test_batch,\n",
        "                device=device, use_sparse=use_sparse, use_input_mask=use_input_mask\n",
        "            )\n",
        "            collected_images.append({\n",
        "                'title': f'Test: {name}, Sampling: {sampling_percentage}%, Epochs: {target_epoch}',\n",
        "                'input_grid': test_input,\n",
        "                'output_grid': test_output,\n",
        "                'input_mask': test_mask\n",
        "            })\n",
        "\n",
        "# Convert results to DataFrame and create visualizations\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n",
        "\n",
        "# Visualization code remains the same...\n",
        "\n",
        "# Create visualization plots (similar structure to previous version, but with sampling_percentage instead of data_size)\n",
        "plt.style.use('seaborn')\n",
        "fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
        "\n",
        "# Modified plotting code for sampling percentage analysis\n",
        "test_types = {\n",
        "    'test_loss_interpolation': 'Interpolation (3-50)',\n",
        "    'test_loss_extrapolation_close': 'Close Extrapolation (51-70)',\n",
        "    'test_loss_extrapolation_far': 'Far Extrapolation (70-90)'\n",
        "}\n",
        "\n",
        "# 1. Test Losses vs Sampling Percentage for Different Epochs\n",
        "ax1 = axes[0, 0]\n",
        "for test_type, label in test_types.items():\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax1.plot(epoch_data['sampling_percentage'], epoch_data[test_type],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax1.set_xlabel('Sampling Percentage')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.set_title('Test Losses vs Sampling Percentage\\n(Fixed Dataset Size)')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True)\n",
        "\n",
        "# 2. Test Losses vs Epochs for Different Sampling Percentages\n",
        "ax2 = axes[0, 1]\n",
        "for test_type, label in test_types.items():\n",
        "    for sampling_pct in sampling_percentages:\n",
        "        size_data = df_results[df_results['sampling_percentage'] == sampling_pct]\n",
        "        ax2.plot(size_data['epochs'], size_data[test_type],\n",
        "                 label=f'{label} ({sampling_pct}%)', marker='o', alpha=0.7)\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Test Loss')\n",
        "ax2.set_title('Test Losses vs Epochs\\n(By Sampling Percentage)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True)\n",
        "\n",
        "# 3. Heatmaps for each test type including Training Loss\n",
        "fig_heatmaps, axes_heatmaps = plt.subplots(1, 4, figsize=(25, 6))\n",
        "test_types_with_training = {\n",
        "    'training_loss': 'Training Loss',\n",
        "    **test_types\n",
        "}\n",
        "for idx, (test_type, label) in enumerate(test_types_with_training.items()):\n",
        "    pivot_table = df_results.pivot(index='sampling_percentage', columns='epochs', values=test_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_heatmaps[idx])\n",
        "    axes_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_heatmaps[idx].set_ylabel('Sampling Percentage')\n",
        "    axes_heatmaps[idx].set_xlabel('Epochs')\n",
        "fig_heatmaps.tight_layout()\n",
        "\n",
        "# 4. Comparison of test types\n",
        "ax4 = axes[1, 1]\n",
        "box_data = [df_results[test_type] for test_type in test_types.keys()]\n",
        "ax4.boxplot(box_data, labels=[label.replace('\\n', ' ') for label in test_types.values()])\n",
        "ax4.set_ylabel('Test Loss')\n",
        "ax4.set_title('Distribution of Test Losses by Type\\n(Across All Sampling Percentages)')\n",
        "ax4.grid(True)\n",
        "\n",
        "# 5. Loss Ratio Analysis\n",
        "ax3 = axes[1, 0]\n",
        "df_results['close_extrapolation_ratio'] = df_results['test_loss_extrapolation_close'] / df_results['test_loss_interpolation']\n",
        "df_results['far_extrapolation_ratio'] = df_results['test_loss_extrapolation_far'] / df_results['test_loss_interpolation']\n",
        "\n",
        "for ratio, label in [('close_extrapolation_ratio', 'Close Extrapolation / Interpolation'),\n",
        "                    ('far_extrapolation_ratio', 'Far Extrapolation / Interpolation')]:\n",
        "    for epoch in epochs:\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        ax3.plot(epoch_data['sampling_percentage'], epoch_data[ratio],\n",
        "                 label=f'{label} (Epochs {epoch})', marker='o', alpha=0.7)\n",
        "ax3.axhline(y=1, color='r', linestyle='--', label='Baseline (Equal Performance)')\n",
        "ax3.set_xlabel('Sampling Percentage')\n",
        "ax3.set_ylabel('Loss Ratio')\n",
        "ax3.set_title('Extrapolation Performance Relative to Interpolation\\n(By Sampling Percentage)')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(True)\n",
        "\n",
        "# Heatmaps for variances of each test type\n",
        "fig_variance_heatmaps, axes_variance_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "variance_test_types = {\n",
        "    'test_variance_interpolation': 'Interpolation Variance',\n",
        "    'test_variance_extrapolation_close': 'Close Extrapolation Variance',\n",
        "    'test_variance_extrapolation_far': 'Far Extrapolation Variance'\n",
        "}\n",
        "for idx, (variance_type, label) in enumerate(variance_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='sampling_percentage', columns='epochs', values=variance_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".6f\", cmap='viridis', ax=axes_variance_heatmaps[idx])\n",
        "    axes_variance_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_variance_heatmaps[idx].set_ylabel('Sampling Percentage')\n",
        "    axes_variance_heatmaps[idx].set_xlabel('Epochs')\n",
        "fig_variance_heatmaps.tight_layout()\n",
        "\n",
        "# 7. Training Loss Heatmap\n",
        "ax7 = axes[2, 1]\n",
        "training_loss_pivot = df_results.pivot(index='sampling_percentage', columns='epochs', values='training_loss')\n",
        "sns.heatmap(training_loss_pivot, annot=True, fmt=\".6f\", cmap='viridis', ax=ax7)\n",
        "ax7.set_title('Training Loss Heatmap')\n",
        "ax7.set_ylabel('Sampling Percentage')\n",
        "ax7.set_xlabel('Epochs')\n",
        "\n",
        "# 8. Training Time Heatmap\n",
        "ax8 = axes[2, 0]\n",
        "training_time_pivot = df_results.pivot(index='sampling_percentage', columns='epochs', values='training_time')\n",
        "sns.heatmap(training_time_pivot, annot=True, fmt=\".2f\", cmap='Blues', ax=ax8)\n",
        "ax8.set_title('Training Time Heatmap')\n",
        "ax8.set_ylabel('Sampling Percentage')\n",
        "ax8.set_xlabel('Epochs')\n",
        "\n",
        "# 9. Evaluation Time Heatmaps for each test set\n",
        "fig_eval_time_heatmaps, axes_eval_time_heatmaps = plt.subplots(1, 3, figsize=(20, 6))\n",
        "evaluation_time_test_types = {\n",
        "    'evaluation_time_interpolation': 'Interpolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_close': 'Close Extrapolation Evaluation Time',\n",
        "    'evaluation_time_extrapolation_far': 'Far Extrapolation Evaluation Time'\n",
        "}\n",
        "for idx, (eval_time_type, label) in enumerate(evaluation_time_test_types.items()):\n",
        "    pivot_table = df_results.pivot(index='sampling_percentage', columns='epochs', values=eval_time_type)\n",
        "    sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap='Greens', ax=axes_eval_time_heatmaps[idx])\n",
        "    axes_eval_time_heatmaps[idx].set_title(f'{label}\\nHeatmap')\n",
        "    axes_eval_time_heatmaps[idx].set_ylabel('Sampling Percentage')\n",
        "    axes_eval_time_heatmaps[idx].set_xlabel('Epochs')\n",
        "    fig_eval_time_heatmaps.tight_layout()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize collected images\n",
        "plot_collected_images(collected_images, images_per_row=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secodnary Variable"
      ],
      "metadata": {
        "id": "DldXC5PbzWJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_model(sparse_encoder, sample_decoder, parameter_decoder, dataloader, num_epochs=10, learning_rate=1e-4, device=\"cuda\"):\n",
        "    sparse_encoder.train()\n",
        "    sample_decoder.train()\n",
        "    parameter_decoder.train()\n",
        "\n",
        "    optimizer = optim.AdamW(list(sparse_encoder.parameters()) +\n",
        "                           list(sample_decoder.parameters()) +\n",
        "                           list(parameter_decoder.parameters()),\n",
        "                           lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "    training_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_parameter_loss = 0\n",
        "        total_sample_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            x, param_grid, param_mask, response_grid, response_mask = batch\n",
        "            batch_x = x.to(device)\n",
        "            batch_param_grid = param_grid.to(device)\n",
        "            batch_param_mask = param_mask.to(device)\n",
        "            batch_response_grid = response_grid.to(device).float()\n",
        "            batch_response_mask = response_mask.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            global _cur_active\n",
        "            _cur_active = batch_response_mask\n",
        "\n",
        "            features = sparse_encoder(batch_response_grid * batch_response_mask)\n",
        "            sample_output = sample_decoder(features[::-1])\n",
        "            parameter_output = parameter_decoder(features[::-1])\n",
        "\n",
        "            sample_loss = criterion(sample_output, batch_response_grid)\n",
        "            parameter_loss = criterion(parameter_output, batch_x)\n",
        "\n",
        "            total_sample_loss += sample_loss.item()\n",
        "            total_parameter_loss += parameter_loss.item()\n",
        "\n",
        "            loss = sample_loss + parameter_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_sample_loss = total_sample_loss / num_batches\n",
        "        avg_parameter_loss = total_parameter_loss / num_batches\n",
        "\n",
        "        training_losses.append({\n",
        "            'epoch': epoch + 1,\n",
        "            'sample_loss': avg_sample_loss,\n",
        "            'parameter_loss': avg_parameter_loss,\n",
        "            'total_loss': avg_sample_loss + avg_parameter_loss\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Sample Loss: {avg_sample_loss:.10f}, Average Parameter Loss: {avg_parameter_loss:.10f}\")\n",
        "\n",
        "    return sparse_encoder, sample_decoder, parameter_decoder, training_losses\n",
        "\n",
        "# Test the pipeline\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def evaluate_model(sparse_encoder, subsurface_decoder, dataloader, device=\"cuda\", use_sparse=False, use_secondary=False, use_input_mask=True, imputation_decoder=None):\n",
        "    sparse_encoder.to(device)\n",
        "    subsurface_decoder.to(device)\n",
        "    sparse_encoder.eval()\n",
        "    subsurface_decoder.eval()\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    total_loss = 0\n",
        "    total_variance = 0\n",
        "    num_batches = 0\n",
        "    all_outputs = []\n",
        "\n",
        "    if use_secondary and imputation_decoder is not None:\n",
        "        imputation_decoder.to(device)\n",
        "        imputation_decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            x, param_grid, param_mask, response_grid, response_mask = batch\n",
        "            batch_x = x.to(device).float()  # Convert to float32\n",
        "            batch_param_grid = param_grid.to(device).float()\n",
        "            batch_param_mask = param_mask.to(device).float()\n",
        "            batch_response_grid = response_grid.to(device).float()\n",
        "            batch_response_mask = response_mask.to(device).float()\n",
        "\n",
        "            global _cur_active\n",
        "\n",
        "            if use_sparse:\n",
        "                if use_input_mask:\n",
        "                    _cur_active = batch_param_mask\n",
        "                else:\n",
        "                    _cur_active = batch_response_mask\n",
        "            else:\n",
        "                _cur_active = torch.ones_like(batch_param_mask).to(device)\n",
        "\n",
        "            if use_secondary:\n",
        "                model_input = batch_response_grid * _cur_active\n",
        "            else:\n",
        "                model_input = batch_x * _cur_active\n",
        "\n",
        "            features = sparse_encoder(model_input)\n",
        "            primary_output = subsurface_decoder(features[::-1])\n",
        "\n",
        "            if use_secondary and imputation_decoder is not None:\n",
        "                secondary_output = imputation_decoder(features[::-1])\n",
        "\n",
        "            all_outputs.append(primary_output.cpu())\n",
        "\n",
        "            loss = criterion(primary_output, batch_x)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            batch_variance = torch.var(primary_output).item()\n",
        "            total_variance += batch_variance\n",
        "\n",
        "            num_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_variance = total_variance / num_batches\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs, dim=0)\n",
        "    total_prediction_variance = torch.var(all_outputs).item()\n",
        "\n",
        "    return avg_loss, avg_variance, total_prediction_variance\n",
        "\n",
        "def process_batch(sparse_encoder, subsurface_decoder, batch, device=\"cuda\", use_secondary=False, use_sparse=False, use_input_mask=True, imputation_decoder=None):\n",
        "    sparse_encoder.eval()\n",
        "    subsurface_decoder.eval()\n",
        "    if use_secondary and imputation_decoder is not None:\n",
        "        imputation_decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        x, param_grid, param_mask, response_grid, response_mask = batch\n",
        "        # Ensure all tensors are float32\n",
        "        batch_x = x.to(device).float()\n",
        "        batch_param_grid = param_grid.to(device).float()\n",
        "        batch_param_mask = param_mask.to(device).float()\n",
        "        batch_response_grid = response_grid.to(device).float()\n",
        "        batch_response_mask = response_mask.to(device).float()\n",
        "\n",
        "        global _cur_active\n",
        "\n",
        "        if use_sparse:\n",
        "            if use_input_mask:\n",
        "                _cur_active = batch_param_mask\n",
        "            else:\n",
        "                _cur_active = batch_response_mask\n",
        "        else:\n",
        "            _cur_active = torch.ones_like(batch_param_mask).to(device).float()\n",
        "\n",
        "        if use_secondary:\n",
        "            model_input = batch_response_grid * _cur_active\n",
        "        else:\n",
        "            model_input = batch_x * _cur_active\n",
        "\n",
        "        # Convert model parameters to float32\n",
        "        sparse_encoder = sparse_encoder.float()\n",
        "        subsurface_decoder = subsurface_decoder.float()\n",
        "        if imputation_decoder is not None:\n",
        "            imputation_decoder = imputation_decoder.float()\n",
        "\n",
        "        features = sparse_encoder(model_input)\n",
        "        primary_output = subsurface_decoder(features[::-1])\n",
        "\n",
        "        if use_secondary and imputation_decoder is not None:\n",
        "            secondary_output = imputation_decoder(features[::-1])\n",
        "            return model_input.cpu(), primary_output.cpu(), secondary_output.cpu(), _cur_active.cpu(), batch_x.cpu()\n",
        "        else:\n",
        "            return model_input.cpu(), primary_output.cpu(), None, _cur_active.cpu(), batch_x.cpu()\n",
        "\n",
        "def plot_collected_images(collected_images, images_per_row=2, max_images=10):\n",
        "    \"\"\"\n",
        "    Plot collected images with a limit on the number of images shown.\n",
        "    Includes original input visualization.\n",
        "    \"\"\"\n",
        "    # Limit the number of images to prevent matplotlib size issues\n",
        "    collected_images = collected_images[:max_images]\n",
        "    num_images = len(collected_images)\n",
        "\n",
        "    has_originals = any('original_image' in data for data in collected_images)\n",
        "    has_imputation = any('imputation_output' in data for data in collected_images)\n",
        "    cols_per_item = 2  # Start with 2 for input and output\n",
        "    if has_originals:\n",
        "        cols_per_item += 1\n",
        "    if has_imputation:\n",
        "        cols_per_item += 1\n",
        "\n",
        "    images_per_row = min(images_per_row, num_images)\n",
        "    num_rows = (num_images + images_per_row - 1) // images_per_row\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, images_per_row * cols_per_item,\n",
        "                            figsize=(5 * images_per_row * cols_per_item, 5 * num_rows))\n",
        "    if num_rows == 1 and images_per_row == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.reshape(num_rows, images_per_row * cols_per_item)\n",
        "\n",
        "    for idx, data in enumerate(collected_images):\n",
        "        row_idx = idx // images_per_row\n",
        "        col_start = (idx % images_per_row) * cols_per_item\n",
        "\n",
        "        try:\n",
        "            input_grid = data['original_secondary'][0].squeeze().cpu().numpy()\n",
        "            output_grid = data['output_grid'][0].squeeze().cpu().numpy()\n",
        "            input_mask = data['input_mask'][0].squeeze().cpu().numpy()\n",
        "            title = data['title']\n",
        "\n",
        "            col_idx = col_start\n",
        "\n",
        "            # Plot original input\n",
        "            ax_input = axes[row_idx, col_idx]\n",
        "            im_input = ax_input.imshow(input_grid, cmap='viridis', interpolation='nearest')\n",
        "            ax_input.set_title(f\"{title}\\n(Original Input)\")\n",
        "            plt.colorbar(im_input, ax=ax_input)\n",
        "            ax_input.axis('off')\n",
        "            col_idx += 1\n",
        "\n",
        "            # Plot original image if available\n",
        "            if has_originals:\n",
        "                ax_orig = axes[row_idx, col_idx]\n",
        "                if 'original_image' in data:\n",
        "                    original = data['original_image'][0].squeeze().cpu().numpy()\n",
        "                    im_orig = ax_orig.imshow(original, cmap='viridis', interpolation='nearest')\n",
        "                    ax_orig.set_title(f\"{title}\\n(Original)\")\n",
        "                    plt.colorbar(im_orig, ax=ax_orig)\n",
        "                else:\n",
        "                    ax_orig.text(0.5, 0.5, 'No original image',\n",
        "                               ha='center', va='center', transform=ax_orig.transAxes)\n",
        "                ax_orig.axis('off')\n",
        "                col_idx += 1\n",
        "\n",
        "            # Plot subsurface prediction\n",
        "            ax = axes[row_idx, col_idx]\n",
        "            im = ax.imshow(output_grid, cmap='viridis', interpolation='nearest')\n",
        "            ax.set_title(f\"{title}\\n(Subsurface Prediction)\")\n",
        "            ax.axis('off')\n",
        "            plt.colorbar(im, ax=ax)\n",
        "            col_idx += 1\n",
        "\n",
        "            # Plot imputation output with points on top\n",
        "            if has_imputation and 'imputation_output' in data:\n",
        "                imputation_output = data['imputation_output'][0].squeeze().cpu().numpy()\n",
        "                ax_imp = axes[row_idx, col_idx]\n",
        "                im_imp = ax_imp.imshow(imputation_output, cmap='viridis', interpolation='nearest')\n",
        "\n",
        "                # Add points on top of imputation output\n",
        "                mask_indices = np.argwhere(input_mask > 0)\n",
        "                if len(mask_indices) > 0:\n",
        "                    mask_values = input_grid[tuple(mask_indices.T)]\n",
        "                    scatter = ax_imp.scatter(mask_indices[:, 1],\n",
        "                                          mask_indices[:, 0],\n",
        "                                          c=mask_values,\n",
        "                                          cmap='viridis',\n",
        "                                          edgecolors='black',\n",
        "                                          s=50)\n",
        "\n",
        "                ax_imp.set_title(f\"{title}\\n(Imputation Output)\")\n",
        "                ax_imp.axis('off')\n",
        "                plt.colorbar(im_imp, ax=ax_imp)\n",
        "\n",
        "        except Exception as e:\n",
        "            current_ax = axes[row_idx, col_idx]\n",
        "            current_ax.text(0.5, 0.5, f'Error processing image {idx}\\n{str(e)}',\n",
        "                          ha='center', va='center', transform=current_ax.transAxes, color='red')\n",
        "            current_ax.axis('off')\n",
        "\n",
        "    # Remove empty subplots\n",
        "    for idx in range(len(collected_images) * cols_per_item, num_rows * images_per_row * cols_per_item):\n",
        "        row_idx = idx // (images_per_row * cols_per_item)\n",
        "        col_idx = idx % (images_per_row * cols_per_item)\n",
        "        if row_idx < axes.shape[0] and col_idx < axes.shape[1]:\n",
        "            fig.delaxes(axes[row_idx, col_idx])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Create a fixed validation sample to use across all epochs\n",
        "def create_fixed_validation_sample(dataset, num_samples=1):\n",
        "    \"\"\"\n",
        "    Create fixed validation samples with consistent sampling points.\n",
        "    \"\"\"\n",
        "    fixed_samples = []\n",
        "\n",
        "    # Set fixed seed temporarily\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        x, param_grid, param_mask, response_grid, response_mask = dataset[0]\n",
        "\n",
        "        # Handle both tensor and numpy array cases\n",
        "        fixed_samples.append({\n",
        "            'x': torch.as_tensor(x) if isinstance(x, np.ndarray) else x.clone(),\n",
        "            'param_grid': torch.as_tensor(param_grid) if isinstance(param_grid, np.ndarray) else param_grid.clone(),\n",
        "            'param_mask': torch.as_tensor(param_mask) if isinstance(param_mask, np.ndarray) else param_mask.clone(),\n",
        "            'response_grid': torch.as_tensor(response_grid) if isinstance(response_grid, np.ndarray) else response_grid.clone(),\n",
        "            'response_mask': torch.as_tensor(response_mask) if isinstance(response_mask, np.ndarray) else response_mask.clone()\n",
        "        })\n",
        "\n",
        "    # Reset random seeds\n",
        "    torch.manual_seed(int(time.time()))\n",
        "    np.random.seed(None)\n",
        "    random.seed(None)\n",
        "\n",
        "    return fixed_samples\n",
        "\n",
        "def process_fixed_validation_sample(sparse_encoder, subsurface_decoder, sample_data,\n",
        "                                  device=\"cuda\", use_secondary=False, use_sparse=False,\n",
        "                                  use_input_mask=True, imputation_decoder=None):\n",
        "    \"\"\"\n",
        "    Process a single fixed validation sample through the model.\n",
        "    \"\"\"\n",
        "    sparse_encoder.eval()\n",
        "    subsurface_decoder.eval()\n",
        "    if use_secondary and imputation_decoder is not None:\n",
        "        imputation_decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Prepare batch (add batch dimension)\n",
        "        batch_x = sample_data['x'].unsqueeze(0).to(device).float()\n",
        "        batch_param_grid = sample_data['param_grid'].unsqueeze(0).to(device).float()\n",
        "        batch_param_mask = sample_data['param_mask'].unsqueeze(0).to(device).float()\n",
        "        batch_response_grid = sample_data['response_grid'].unsqueeze(0).to(device).float()\n",
        "        batch_response_mask = sample_data['response_mask'].unsqueeze(0).to(device).float()\n",
        "\n",
        "        global _cur_active\n",
        "\n",
        "        if use_sparse:\n",
        "            if use_input_mask:\n",
        "                _cur_active = batch_param_mask\n",
        "            else:\n",
        "                _cur_active = batch_response_mask\n",
        "        else:\n",
        "            _cur_active = torch.ones_like(batch_param_mask).to(device).float()\n",
        "\n",
        "        if use_secondary:\n",
        "            model_input = batch_response_grid * _cur_active\n",
        "        else:\n",
        "            model_input = batch_x * _cur_active\n",
        "\n",
        "        features = sparse_encoder(model_input)\n",
        "        primary_output = subsurface_decoder(features[::-1])\n",
        "\n",
        "        if use_secondary and imputation_decoder is not None:\n",
        "            secondary_output = imputation_decoder(features[::-1])\n",
        "            return (model_input.cpu(), primary_output.cpu(), secondary_output.cpu(),\n",
        "                   _cur_active.cpu(), batch_x.cpu(), batch_response_grid.cpu())\n",
        "        else:\n",
        "            return (model_input.cpu(), primary_output.cpu(), None,\n",
        "                   _cur_active.cpu(), batch_x.cpu(), batch_response_grid.cpu())\n"
      ],
      "metadata": {
        "id": "g5_Lp0G4z1ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_comprehensive_heatmaps(results_df):\n",
        "    \"\"\"\n",
        "    Create comprehensive heatmap visualizations for primary and secondary variables.\n",
        "    \"\"\"\n",
        "    # Create a figure with 2x2 subplots for the heatmaps\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
        "\n",
        "    # Primary Variable Training Loss Heatmap\n",
        "    primary_train_pivot = results_df.pivot(\n",
        "        index='sampling_percentage',\n",
        "        columns='epochs',\n",
        "        values='primary_train_loss'\n",
        "    )\n",
        "    sns.heatmap(\n",
        "        primary_train_pivot,\n",
        "        annot=True,\n",
        "        fmt=\".6f\",\n",
        "        cmap='viridis',\n",
        "        ax=axes[0, 0],\n",
        "        cbar_kws={'label': 'Loss Value'}\n",
        "    )\n",
        "    axes[0, 0].set_title('Primary Variable Training Loss')\n",
        "    axes[0, 0].set_ylabel('Sampling Percentage')\n",
        "    axes[0, 0].set_xlabel('Epochs')\n",
        "\n",
        "    # Primary Variable Validation Loss Heatmap\n",
        "    primary_val_pivot = results_df.pivot(\n",
        "        index='sampling_percentage',\n",
        "        columns='epochs',\n",
        "        values='primary_val_loss'\n",
        "    )\n",
        "    sns.heatmap(\n",
        "        primary_val_pivot,\n",
        "        annot=True,\n",
        "        fmt=\".6f\",\n",
        "        cmap='viridis',\n",
        "        ax=axes[0, 1],\n",
        "        cbar_kws={'label': 'Loss Value'}\n",
        "    )\n",
        "    axes[0, 1].set_title('Primary Variable Validation Loss')\n",
        "    axes[0, 1].set_ylabel('Sampling Percentage')\n",
        "    axes[0, 1].set_xlabel('Epochs')\n",
        "\n",
        "    # Secondary Variable Training Loss Heatmap\n",
        "    secondary_train_pivot = results_df.pivot(\n",
        "        index='sampling_percentage',\n",
        "        columns='epochs',\n",
        "        values='secondary_train_loss'\n",
        "    )\n",
        "    sns.heatmap(\n",
        "        secondary_train_pivot,\n",
        "        annot=True,\n",
        "        fmt=\".6f\",\n",
        "        cmap='viridis',\n",
        "        ax=axes[1, 0],\n",
        "        cbar_kws={'label': 'Loss Value'}\n",
        "    )\n",
        "    axes[1, 0].set_title('Secondary Variable Training Loss')\n",
        "    axes[1, 0].set_ylabel('Sampling Percentage')\n",
        "    axes[1, 0].set_xlabel('Epochs')\n",
        "\n",
        "    # Secondary Variable Validation Loss Heatmap\n",
        "    secondary_val_pivot = results_df.pivot(\n",
        "        index='sampling_percentage',\n",
        "        columns='epochs',\n",
        "        values='secondary_val_loss'\n",
        "    )\n",
        "    sns.heatmap(\n",
        "        secondary_val_pivot,\n",
        "        annot=True,\n",
        "        fmt=\".6f\",\n",
        "        cmap='viridis',\n",
        "        ax=axes[1, 1],\n",
        "        cbar_kws={'label': 'Loss Value'}\n",
        "    )\n",
        "    axes[1, 1].set_title('Secondary Variable Validation Loss')\n",
        "    axes[1, 1].set_ylabel('Sampling Percentage')\n",
        "    axes[1, 1].set_xlabel('Epochs')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Modify the training loop to collect separate losses\n",
        "def evaluate_with_separate_losses(sparse_encoder, subsurface_decoder, dataloader,\n",
        "                                device=\"cuda\", use_sparse=False, use_input_mask=True,\n",
        "                                imputation_decoder=None):\n",
        "    sparse_encoder.eval()\n",
        "    subsurface_decoder.eval()\n",
        "    if imputation_decoder is not None:\n",
        "        imputation_decoder.eval()\n",
        "\n",
        "    primary_criterion = nn.MSELoss()\n",
        "    secondary_criterion = nn.MSELoss()\n",
        "    total_primary_loss = 0\n",
        "    total_secondary_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            x, param_grid, param_mask, response_grid, response_mask = batch\n",
        "            batch_x = x.to(device).float()\n",
        "            batch_response_grid = response_grid.to(device).float()\n",
        "            batch_response_mask = response_mask.to(device).float()\n",
        "\n",
        "            global _cur_active\n",
        "            _cur_active = batch_response_mask if use_sparse else torch.ones_like(batch_response_mask).to(device)\n",
        "\n",
        "            features = sparse_encoder(batch_response_grid * _cur_active)\n",
        "            primary_output = subsurface_decoder(features[::-1])\n",
        "            secondary_output = imputation_decoder(features[::-1]) if imputation_decoder else None\n",
        "\n",
        "            # Calculate primary loss\n",
        "            primary_loss = primary_criterion(primary_output, batch_x)\n",
        "            total_primary_loss += primary_loss.item()\n",
        "\n",
        "            # Calculate secondary loss if applicable\n",
        "            if secondary_output is not None:\n",
        "                secondary_loss = secondary_criterion(secondary_output, batch_response_grid)\n",
        "                total_secondary_loss += secondary_loss.item()\n",
        "\n",
        "            num_batches += 1\n",
        "\n",
        "    avg_primary_loss = total_primary_loss / num_batches\n",
        "    avg_secondary_loss = total_secondary_loss / num_batches if imputation_decoder else 0\n",
        "\n",
        "    return avg_primary_loss, avg_secondary_loss\n"
      ],
      "metadata": {
        "id": "pjz3kqoICy2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Ensure that 'size', 'generator', and 'response_grid_fn' are defined\n",
        "size = (32, 64)\n",
        "\n",
        "def response_grid_fn(x):\n",
        "    return x\n",
        "\n",
        "# Define your generator\n",
        "generator = CategoricalSpatialGenerator(\n",
        "    size,\n",
        "    lambda: two_layer_generator(),\n",
        "    num_categories=10,\n",
        "    methods=['layered', 'vid']\n",
        ")\n",
        "\n",
        "# Adjusted drilling_sampling_custom to accept sampling_percentage\n",
        "def get_drilling_sampling_custom(sampling_percentage):\n",
        "    def drilling_sampling_custom(size, min_drillholes=5, max_drillholes=15, min_samples=3, max_samples=20):\n",
        "        mask = torch.zeros(1, *size)\n",
        "        height, width = size\n",
        "        total_points = height * width\n",
        "        target_samples = int((random.uniform(50, 90) / 100.0) * total_points)\n",
        "        num_samples = max(min_samples, target_samples)\n",
        "\n",
        "        num_drillholes = sampling_percentage\n",
        "        samples_per_drillhole = num_samples // num_drillholes if num_drillholes > 0 else num_samples\n",
        "\n",
        "        for _ in range(num_drillholes):\n",
        "            x = random.randint(0, width - 1)\n",
        "            num_samples_drillhole = random.randint(min_samples, max_samples)\n",
        "            num_samples_drillhole = min(samples_per_drillhole, num_samples_drillhole)\n",
        "            y_positions = random.sample(range(height), min(num_samples_drillhole, height))\n",
        "            for y in y_positions:\n",
        "                mask[0, y, x] = 1\n",
        "\n",
        "\n",
        "        return mask\n",
        "    return drilling_sampling_custom\n",
        "\n",
        "# Sampling percentages and epochs\n",
        "sampling_percentages = [1, 2, 3, 5, 10, 20, 40, 60]\n",
        "epochs = [1, 5, 10, 20, 40, 80, 160, 320]\n",
        "fixed_dataset_size = 1000\n",
        "\n",
        "# Initialize results list and device\n",
        "results = []\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create the datasets once, and we'll update the sampling_fn dynamically\n",
        "train_dataset = SpatialDataset(\n",
        "    num_generations=0,\n",
        "    generator=generator,\n",
        "    sampling_fn=None,  # We'll set this dynamically\n",
        "    secondary_grid_fn=response_grid_fn,\n",
        "    data_folder=\"drive/MyDrive/data_res/study_case_1\",\n",
        "    dynamic_secondary_mask=True,\n",
        "    x_channels=1,            # Input channels\n",
        "    secondary_channels=0,    # Channels for the secondary grid\n",
        "    primary_channels=1       # Channels for the primary grid\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_dataset = SpatialDataset(\n",
        "    num_generations=0,\n",
        "    generator=generator,\n",
        "    sampling_fn=None,  # We'll set this dynamically\n",
        "    secondary_grid_fn=response_grid_fn,\n",
        "    data_folder=\"drive/MyDrive/data_res/study_case_1_test\",\n",
        "    dynamic_secondary_mask=True,\n",
        "    x_channels=1,\n",
        "    secondary_channels=0,\n",
        "    primary_channels=1\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "collected_images = []\n",
        "use_sparse = True\n",
        "use_input_mask = False\n",
        "results = []\n",
        "\n",
        "for sampling_percentage in sampling_percentages:\n",
        "    print(f\"\\nStarting training with sampling percentage: {sampling_percentage}%\")\n",
        "\n",
        "    # Set the sampling function for the current sampling_percentage\n",
        "    sampling_fn = get_drilling_sampling_custom(sampling_percentage)\n",
        "\n",
        "    # Update the sampling_fn in the datasets\n",
        "    train_dataset.sampling_fn = sampling_fn\n",
        "    test_dataset.sampling_fn = sampling_fn\n",
        "\n",
        "    # Create fixed validation samples for this sampling percentage\n",
        "    fixed_validation_samples = create_fixed_validation_sample(test_dataset, num_samples=5)\n",
        "\n",
        "    # Initialize models\n",
        "    convnext = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]).to(device)\n",
        "    sparse_encoder = SparseEncoder(convnext, input_size=size).to(device)\n",
        "    subsurface_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "    imputation_decoder = Decoder(up_sample_ratio=32, out_chans=1, width=768, sbn=False).to(device)\n",
        "    last_model_path = \"drive/MyDrive/Models/base_id_1000k.pth\"\n",
        "\n",
        "    # Load the model state\n",
        "    sparse_encoder, _ , imputation_decoder, use_secondary, use_sparse, training_losses = load_model(\n",
        "        last_model_path,\n",
        "        sparse_encoder,\n",
        "        None,\n",
        "        imputation_decoder,\n",
        "        device=device\n",
        "    )\n",
        "    # Progressive training loop\n",
        "    current_epoch = 0\n",
        "\n",
        "    for target_epoch in epochs:\n",
        "        epochs_to_train = target_epoch - current_epoch\n",
        "        if epochs_to_train <= 0:\n",
        "            continue\n",
        "\n",
        "        print(f\"Training from epoch {current_epoch + 1} to {target_epoch}\")\n",
        "\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        # Train the model\n",
        "\n",
        "        sparse_encoder, imputation_decoder, subsurface_decoder, training_losses = train_model(\n",
        "            sparse_encoder,\n",
        "            imputation_decoder,\n",
        "            subsurface_decoder,\n",
        "            train_dataloader,\n",
        "            num_epochs=epochs_to_train,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        training_end_time = time.time()\n",
        "        training_time = training_end_time - training_start_time\n",
        "        final_training_loss = training_losses[-1]['total_loss']\n",
        "\n",
        "        # Evaluate the model\n",
        "        primary_train_loss, secondary_train_loss = evaluate_with_separate_losses(\n",
        "            sparse_encoder, subsurface_decoder, train_dataloader,\n",
        "            device=device, use_sparse=use_sparse, use_input_mask=use_input_mask,\n",
        "            imputation_decoder=imputation_decoder\n",
        "        )\n",
        "\n",
        "        # Evaluate validation losses\n",
        "        primary_val_loss, secondary_val_loss = evaluate_with_separate_losses(\n",
        "            sparse_encoder, subsurface_decoder, test_dataloader,\n",
        "            device=device, use_sparse=use_sparse, use_input_mask=use_input_mask,\n",
        "            imputation_decoder=imputation_decoder\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            'sampling_percentage': sampling_percentage,\n",
        "            'epochs': target_epoch,\n",
        "            'primary_train_loss': primary_train_loss,\n",
        "            'primary_val_loss': primary_val_loss,\n",
        "            'secondary_train_loss': secondary_train_loss,\n",
        "            'secondary_val_loss': secondary_val_loss,\n",
        "            'training_time': training_time\n",
        "        })\n",
        "\n",
        "\n",
        "        # Process fixed validation samples\n",
        "        for idx, fixed_sample in enumerate(fixed_validation_samples):\n",
        "            val_input, val_output, val_imputation_output, val_mask, val_original, val_secondary = process_fixed_validation_sample(\n",
        "                sparse_encoder, subsurface_decoder, fixed_sample,\n",
        "                device=device, use_sparse=use_sparse, use_input_mask=use_input_mask,\n",
        "                use_secondary=True, imputation_decoder=imputation_decoder\n",
        "            )\n",
        "\n",
        "            collected_images.append({\n",
        "                'title': f'Validation {idx+1} - {sampling_percentage}%, Epoch {target_epoch}',\n",
        "                'input_grid': val_input,\n",
        "                'output_grid': val_output,\n",
        "                'imputation_output': val_imputation_output,\n",
        "                'input_mask': val_mask,\n",
        "                'original_image': val_original,\n",
        "                'original_secondary': val_secondary\n",
        "            })\n",
        "\n",
        "        current_epoch = target_epoch\n",
        "\n",
        "        # Training data visualization\n",
        "        train_iter = iter(train_dataloader)\n",
        "        train_batch = next(train_iter)\n",
        "        train_input, train_output, train_imputation_output, train_mask, train_original = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, train_batch,\n",
        "            device=device, use_sparse=use_sparse, use_input_mask=use_input_mask,\n",
        "            use_secondary=True, imputation_decoder=imputation_decoder\n",
        "        )\n",
        "\n",
        "        # Test data visualization\n",
        "        test_iter = iter(test_dataloader)\n",
        "        test_batch = next(test_iter)\n",
        "        test_input, test_output, test_imputation_output, test_mask, test_original = process_batch(\n",
        "            sparse_encoder, subsurface_decoder, test_batch,\n",
        "            device=device, use_sparse=use_sparse, use_input_mask=use_input_mask,\n",
        "            use_secondary=True, imputation_decoder=imputation_decoder\n",
        "        )\n",
        "\n",
        "    # Save the model after training with this sampling percentage\n",
        "    torch.save({\n",
        "        'sparse_encoder_state_dict': sparse_encoder.state_dict(),\n",
        "        'imputation_decoder_state_dict': imputation_decoder.state_dict(),\n",
        "        'subsurface_decoder_state_dict': subsurface_decoder.state_dict(),\n",
        "        'training_losses': training_losses,\n",
        "    }, f\"model_sampling{sampling_percentage}.pth\")\n",
        "\n",
        "# Convert results to DataFrame and create visualizations\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n",
        "\n"
      ],
      "metadata": {
        "id": "6R59WzFtzYI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def create_loss_visualizations(df_results, save_path=None):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualizations for training results\n",
        "\n",
        "    Parameters:\n",
        "    df_results (pd.DataFrame): DataFrame containing training results with columns:\n",
        "        - sampling_percentage\n",
        "        - epochs\n",
        "        - primary_train_loss\n",
        "        - primary_val_loss\n",
        "        - secondary_train_loss\n",
        "        - secondary_val_loss\n",
        "        - training_time\n",
        "    save_path (str, optional): Path to save the figures\n",
        "    \"\"\"\n",
        "    # Set the style\n",
        "    plt.style.use('default')\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "    # Create main figure for loss plots\n",
        "    fig, axes = plt.subplots(3, 2, figsize=(20, 24))\n",
        "\n",
        "    # 1. Primary Loss vs Sampling Percentage for Different Epochs\n",
        "    for epoch in df_results['epochs'].unique():\n",
        "        epoch_data = df_results[df_results['epochs'] == epoch]\n",
        "        axes[0, 0].plot(epoch_data['sampling_percentage'],\n",
        "                       epoch_data['primary_val_loss'],\n",
        "                       label=f'Epochs {epoch}',\n",
        "                       marker='o',\n",
        "                       alpha=0.7)\n",
        "\n",
        "    axes[0, 0].set_xlabel('Sampling Percentage (%)')\n",
        "    axes[0, 0].set_ylabel('Validation Loss')\n",
        "    axes[0, 0].set_title('Primary Variable Validation Loss vs Sampling Percentage')\n",
        "    axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[0, 0].set_xscale('log')\n",
        "\n",
        "    # 2. Secondary Loss vs Epochs for Different Sampling Percentages\n",
        "    for pct in df_results['sampling_percentage'].unique():\n",
        "        pct_data = df_results[df_results['sampling_percentage'] == pct]\n",
        "        axes[0, 1].plot(pct_data['epochs'],\n",
        "                       pct_data['secondary_val_loss'],\n",
        "                       label=f'{pct}%',\n",
        "                       marker='o',\n",
        "                       alpha=0.7)\n",
        "\n",
        "    axes[0, 1].set_xlabel('Epochs')\n",
        "    axes[0, 1].set_ylabel('Validation Loss')\n",
        "    axes[0, 1].set_title('Secondary Variable Validation Loss vs Epochs')\n",
        "    axes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[0, 1].set_xscale('log')\n",
        "\n",
        "    # 3. Training vs Validation Loss Comparison\n",
        "    axes[1, 0].scatter(df_results['primary_train_loss'],\n",
        "                      df_results['primary_val_loss'],\n",
        "                      alpha=0.6,\n",
        "                      c=df_results['sampling_percentage'],\n",
        "                      cmap='viridis')\n",
        "\n",
        "    lims = [\n",
        "        np.min([axes[1, 0].get_xlim(), axes[1, 0].get_ylim()]),\n",
        "        np.max([axes[1, 0].get_xlim(), axes[1, 0].get_ylim()])\n",
        "    ]\n",
        "    axes[1, 0].plot(lims, lims, 'k--', alpha=0.5)\n",
        "    axes[1, 0].set_xlabel('Training Loss')\n",
        "    axes[1, 0].set_ylabel('Validation Loss')\n",
        "    axes[1, 0].set_title('Training vs Validation Loss')\n",
        "\n",
        "    # 4. Training Time Analysis\n",
        "    sns.boxplot(data=df_results,\n",
        "                x='sampling_percentage',\n",
        "                y='training_time',\n",
        "                ax=axes[1, 1])\n",
        "    axes[1, 1].set_xlabel('Sampling Percentage (%)')\n",
        "    axes[1, 1].set_ylabel('Training Time (seconds)')\n",
        "    axes[1, 1].set_title('Training Time Distribution')\n",
        "\n",
        "    # 5. Loss Heatmaps\n",
        "    loss_pivot = df_results.pivot(index='sampling_percentage',\n",
        "                                columns='epochs',\n",
        "                                values='primary_val_loss')\n",
        "    sns.heatmap(loss_pivot,\n",
        "                annot=True,\n",
        "                fmt='.2e',\n",
        "                cmap='viridis',\n",
        "                ax=axes[2, 0],\n",
        "                cbar_kws={'label': 'Validation Loss'})\n",
        "    axes[2, 0].set_title('Primary Variable Validation Loss Heatmap')\n",
        "    axes[2, 0].set_ylabel('Sampling Percentage (%)')\n",
        "    axes[2, 0].set_xlabel('Epochs')\n",
        "\n",
        "    # 6. Secondary Loss Heatmap\n",
        "    secondary_pivot = df_results.pivot(index='sampling_percentage',\n",
        "                                     columns='epochs',\n",
        "                                     values='secondary_val_loss')\n",
        "    sns.heatmap(secondary_pivot,\n",
        "                annot=True,\n",
        "                fmt='.2e',\n",
        "                cmap='viridis',\n",
        "                ax=axes[2, 1],\n",
        "                cbar_kws={'label': 'Validation Loss'})\n",
        "    axes[2, 1].set_title('Secondary Variable Validation Loss Heatmap')\n",
        "    axes[2, 1].set_ylabel('Sampling Percentage (%)')\n",
        "    axes[2, 1].set_xlabel('Epochs')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_training_metrics_summary(df_results):\n",
        "    \"\"\"\n",
        "    Create a summary dashboard of key training metrics\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Calculate efficiency metrics\n",
        "    df_results['loss_improvement'] = df_results.groupby('sampling_percentage')['primary_val_loss'].transform(\n",
        "        lambda x: (x.iloc[0] - x) / x.iloc[0]\n",
        "    )\n",
        "\n",
        "    df_results['time_efficiency'] = df_results['loss_improvement'] / df_results['training_time']\n",
        "\n",
        "    # Create summary plot\n",
        "    sns.scatterplot(data=df_results,\n",
        "                   x='sampling_percentage',\n",
        "                   y='time_efficiency',\n",
        "                   size='epochs',\n",
        "                   hue='primary_val_loss',\n",
        "                   palette='viridis')\n",
        "\n",
        "    plt.xscale('log')\n",
        "    plt.xlabel('Sampling Percentage (%)')\n",
        "    plt.ylabel('Efficiency (Loss Improvement / Training Time)')\n",
        "    plt.title('Training Efficiency Analysis')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def print_summary_statistics(df_results):\n",
        "    \"\"\"\n",
        "    Print summary statistics of the training results\n",
        "    \"\"\"\n",
        "    print(\"\\nSummary Statistics:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Best performing configuration\n",
        "    best_idx = df_results['primary_val_loss'].idxmin()\n",
        "    best_config = df_results.loc[best_idx]\n",
        "\n",
        "    print(f\"Best Configuration:\")\n",
        "    print(f\"Sampling Percentage: {best_config['sampling_percentage']}%\")\n",
        "    print(f\"Epochs: {best_config['epochs']}\")\n",
        "    print(f\"Validation Loss: {best_config['primary_val_loss']:.6f}\")\n",
        "    print(f\"Training Time: {best_config['training_time']:.2f} seconds\")\n",
        "\n",
        "    # Efficiency analysis\n",
        "    print(\"\\nEfficiency Analysis:\")\n",
        "    df_results['efficiency'] = df_results['primary_val_loss'] * df_results['training_time']\n",
        "    most_efficient_idx = df_results['efficiency'].idxmin()\n",
        "    efficient_config = df_results.loc[most_efficient_idx]\n",
        "\n",
        "    print(f\"Most Efficient Configuration:\")\n",
        "    print(f\"Sampling Percentage: {efficient_config['sampling_percentage']}%\")\n",
        "    print(f\"Epochs: {efficient_config['epochs']}\")\n",
        "    print(f\"Validation Loss: {efficient_config['primary_val_loss']:.6f}\")\n",
        "    print(f\"Training Time: {efficient_config['training_time']:.2f} seconds\")"
      ],
      "metadata": {
        "id": "GoQli8wS5YHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(results)\n",
        "plot_comprehensive_heatmaps(df_results)"
      ],
      "metadata": {
        "id": "8x1DV9GLDEw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the visualizations\n",
        "create_loss_visualizations(df_results, save_path='training_results.png')\n",
        "\n",
        "# Get efficiency analysis\n",
        "plot_training_metrics_summary(df_results)\n",
        "\n",
        "# Print summary statistics\n",
        "print_summary_statistics(df_results)"
      ],
      "metadata": {
        "id": "qeMpl_LR5i22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_loss_data_arrays(df_results, epochs, sampling_percentages):\n",
        "    \"\"\"\n",
        "    Create 2D arrays for heatmap visualization from DataFrame results\n",
        "\n",
        "    Parameters:\n",
        "    df_results (pd.DataFrame): DataFrame containing the results\n",
        "    epochs (list): List of epoch values\n",
        "    sampling_percentages (list): List of sampling percentage values\n",
        "\n",
        "    Returns:\n",
        "    tuple: Four 2D numpy arrays for primary/secondary train/test losses\n",
        "    \"\"\"\n",
        "    # Initialize empty arrays\n",
        "    primary_test_loss_data = np.zeros((len(sampling_percentages), len(epochs)))\n",
        "    primary_train_loss_data = np.zeros((len(sampling_percentages), len(epochs)))\n",
        "    secondary_test_loss_data = np.zeros((len(sampling_percentages), len(epochs)))\n",
        "    secondary_train_loss_data = np.zeros((len(sampling_percentages), len(epochs)))\n",
        "\n",
        "    # Fill the arrays\n",
        "    for i, samp in enumerate(sampling_percentages):\n",
        "        for j, ep in enumerate(epochs):\n",
        "            # Get the row matching current sampling percentage and epoch\n",
        "            mask = (df_results['sampling_percentage'] == samp) & (df_results['epochs'] == ep)\n",
        "            if not df_results[mask].empty:\n",
        "                row = df_results[mask].iloc[0]\n",
        "                primary_test_loss_data[i, j] = row['primary_val_loss']\n",
        "                primary_train_loss_data[i, j] = row['primary_train_loss']\n",
        "                secondary_test_loss_data[i, j] = row['secondary_val_loss']\n",
        "                secondary_train_loss_data[i, j] = row['secondary_train_loss']\n",
        "\n",
        "    # Create formatted string representations\n",
        "    def format_array(arr):\n",
        "        return np.array2string(arr,\n",
        "                             formatter={'float_kind': lambda x: \"%.6f\" % x},\n",
        "                             separator=',\\n ',\n",
        "                             prefix='[',\n",
        "                             suffix=']')\n",
        "\n",
        "    print(\"primary_test_loss_data = \", format_array(primary_test_loss_data))\n",
        "    print(\"\\nprimary_train_loss_data = \", format_array(primary_train_loss_data))\n",
        "    print(\"\\nsecondary_test_loss_data = \", format_array(secondary_test_loss_data))\n",
        "    print(\"\\nsecondary_train_loss_data = \", format_array(secondary_train_loss_data))\n",
        "\n",
        "    return (primary_test_loss_data, primary_train_loss_data,\n",
        "            secondary_test_loss_data, secondary_train_loss_data)\n",
        "\n",
        "# Example usage:\n",
        "epochs = [1, 5, 10, 20, 40, 80, 160, 320]\n",
        "sampling_percentages = [1, 2, 3, 5, 10, 20, 40, 60]\n",
        "\n",
        "# Create the arrays\n",
        "loss_arrays = create_loss_data_arrays(df_results, epochs, sampling_percentages)\n",
        "\n",
        "# You can then access individual arrays:\n",
        "primary_test_loss_data = loss_arrays[0]\n",
        "primary_train_loss_data = loss_arrays[1]\n",
        "secondary_test_loss_data = loss_arrays[2]\n",
        "secondary_train_loss_data = loss_arrays[3]"
      ],
      "metadata": {
        "id": "XVM2cjRB5PEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_collected_images(collected_images, images_per_row=5)"
      ],
      "metadata": {
        "id": "52QakcxObc7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_collected_images(collected_images, images_per_row=2, max_images=None):\n",
        "    \"\"\"\n",
        "    Plot collected images with configurable limits and better progress tracking.\n",
        "\n",
        "    Args:\n",
        "        collected_images: List of dictionaries containing image data\n",
        "        images_per_row: Number of images to display per row\n",
        "        max_images: Maximum number of images to display (None for all images)\n",
        "    \"\"\"\n",
        "    # Print diagnostic information\n",
        "    print(f\"Total images in collection: {len(collected_images)}\")\n",
        "    print(\"\\nAvailable sampling percentages:\")\n",
        "    percentages = set(int(data['title'].split('%')[0].split()[-1])\n",
        "                     for data in collected_images\n",
        "                     if '%' in data['title'])\n",
        "    print(sorted(percentages))\n",
        "\n",
        "    # Don't limit if max_images is None\n",
        "    if max_images is not None:\n",
        "        collected_images = collected_images[:max_images]\n",
        "\n",
        "    num_images = len(collected_images)\n",
        "    print(f\"\\nProcessing {num_images} images\")\n",
        "\n",
        "    has_originals = any('original_image' in data for data in collected_images)\n",
        "    has_imputation = any('imputation_output' in data for data in collected_images)\n",
        "    cols_per_item = 2  # Start with 2 for input and output\n",
        "    if has_originals:\n",
        "        cols_per_item += 1\n",
        "    if has_imputation:\n",
        "        cols_per_item += 1\n",
        "\n",
        "    images_per_row = min(images_per_row, num_images)\n",
        "    num_rows = (num_images + images_per_row - 1) // images_per_row\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, images_per_row * cols_per_item,\n",
        "                            figsize=(5 * images_per_row * cols_per_item, 5 * num_rows))\n",
        "\n",
        "    # Handle single row/column cases\n",
        "    if num_rows == 1 and images_per_row == 1:\n",
        "        axes = np.array([axes])\n",
        "    if len(axes.shape) == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    print(\"\\nProcessing individual images:\")\n",
        "    for idx, data in enumerate(collected_images):\n",
        "        print(f\"Processing image {idx + 1}/{num_images}: {data['title']}\")\n",
        "\n",
        "        row_idx = idx // images_per_row\n",
        "        col_start = (idx % images_per_row) * cols_per_item\n",
        "\n",
        "        try:\n",
        "            if 'original_secondary' not in data:\n",
        "                print(f\"Warning: Missing original_secondary for image {idx}\")\n",
        "                continue\n",
        "\n",
        "            input_grid = data['original_secondary'][0].squeeze().cpu().numpy()\n",
        "            output_grid = data['output_grid'][0].squeeze().cpu().numpy()\n",
        "            input_mask = data['input_mask'][0].squeeze().cpu().numpy()\n",
        "            title = data['title']\n",
        "\n",
        "            col_idx = col_start\n",
        "\n",
        "            # Plot original input\n",
        "            ax_input = axes[row_idx, col_idx]\n",
        "            im_input = ax_input.imshow(input_grid, cmap='viridis', interpolation='nearest')\n",
        "            ax_input.set_title(f\"{title}\\n(Original Input)\")\n",
        "            plt.colorbar(im_input, ax=ax_input)\n",
        "            ax_input.axis('off')\n",
        "            col_idx += 1\n",
        "\n",
        "            # Plot original image if available\n",
        "            if has_originals:\n",
        "                ax_orig = axes[row_idx, col_idx]\n",
        "                if 'original_image' in data:\n",
        "                    original = data['original_image'][0].squeeze().cpu().numpy()\n",
        "                    im_orig = ax_orig.imshow(original, cmap='viridis', interpolation='nearest')\n",
        "                    ax_orig.set_title(f\"{title}\\n(Original)\")\n",
        "                    plt.colorbar(im_orig, ax=ax_orig)\n",
        "                else:\n",
        "                    ax_orig.text(0.5, 0.5, 'No original image',\n",
        "                               ha='center', va='center', transform=ax_orig.transAxes)\n",
        "                ax_orig.axis('off')\n",
        "                col_idx += 1\n",
        "\n",
        "            # Plot subsurface prediction\n",
        "            ax = axes[row_idx, col_idx]\n",
        "            im = ax.imshow(output_grid, cmap='viridis', interpolation='nearest')\n",
        "            ax.set_title(f\"{title}\\n(Subsurface Prediction)\")\n",
        "            ax.axis('off')\n",
        "            plt.colorbar(im, ax=ax)\n",
        "            col_idx += 1\n",
        "\n",
        "            # Plot imputation output with points on top\n",
        "            if has_imputation and 'imputation_output' in data:\n",
        "                imputation_output = data['imputation_output'][0].squeeze().cpu().numpy()\n",
        "                ax_imp = axes[row_idx, col_idx]\n",
        "                im_imp = ax_imp.imshow(imputation_output, cmap='viridis', interpolation='nearest')\n",
        "\n",
        "                # Add points on top of imputation output\n",
        "                mask_indices = np.argwhere(input_mask > 0)\n",
        "                if len(mask_indices) > 0:\n",
        "                    mask_values = input_grid[tuple(mask_indices.T)]\n",
        "                    scatter = ax_imp.scatter(mask_indices[:, 1],\n",
        "                                          mask_indices[:, 0],\n",
        "                                          c=mask_values,\n",
        "                                          cmap='viridis',\n",
        "                                          edgecolors='black',\n",
        "                                          s=50)\n",
        "\n",
        "                ax_imp.set_title(f\"{title}\\n(Imputation Output)\")\n",
        "                ax_imp.axis('off')\n",
        "                plt.colorbar(im_imp, ax=ax_imp)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {idx}: {str(e)}\")\n",
        "            current_ax = axes[row_idx, col_idx]\n",
        "            current_ax.text(0.5, 0.5, f'Error processing image {idx}\\n{str(e)}',\n",
        "                          ha='center', va='center', transform=current_ax.transAxes, color='red')\n",
        "            current_ax.axis('off')\n",
        "\n",
        "    # Remove empty subplots\n",
        "    for idx in range(len(collected_images) * cols_per_item, num_rows * images_per_row * cols_per_item):\n",
        "        row_idx = idx // (images_per_row * cols_per_item)\n",
        "        col_idx = idx % (images_per_row * cols_per_item)\n",
        "        if row_idx < axes.shape[0] and col_idx < axes.shape[1]:\n",
        "            fig.delaxes(axes[row_idx, col_idx])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bVuoK5OFAePu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_collected_images(collected_images, images_per_row=5)"
      ],
      "metadata": {
        "id": "Tjo1jti35zvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_collected_images(collected_images, images_per_row=5)\n"
      ],
      "metadata": {
        "id": "NTo1HZsCB-VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TSBp3FbnAFRf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DoF0nOoy8GaK",
        "cf9TO118wmIs",
        "93jStMkQweb2"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}